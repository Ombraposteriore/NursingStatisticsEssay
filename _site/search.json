[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "症状网络分析入门",
    "section": "",
    "text": "作者：北游（执笔） stephan 花开 紫菀 十月（辅助）\n团队：护理统计随笔\n发布日期：2024-10-8\n\n前言\n在当今的医疗领域，随着大数据和网络科学的发展，症状网络（下图）建模与分析正逐渐成为理解复杂健康问题的关键工具。越来越多的研究者有这方面的需求。\n从去年我在护理统计随笔公众号分享第一篇症状网络分析推文开始，就不断有关注我们公众号的粉丝朋友私信我，说希望以后可以开设相关课程或者分享更多的入门版文章。我查询了不少国内的网站和论坛，发现现有的症状网络相关资料确实不算多，视频更是寥寥无几，系统、免费的文档资料尚不多见。令人惊喜的是，网络分析领域有大量的文献可以学习。\n不过，由于彼时有其他事情需要忙，所以分享的进程就耽搁了。值此国庆佳节，我便抽空将所学的以及所见所闻的内容记录下来，简单地将其整理成篇，凑成这么一本简陋的不算\"书\"的电子材料，献给所有有缘读到这些文字的朋友！\n姑且把这份电子版材料当成书吧，严格来讲肯定不算的。\n\n\n\n\n\n\n特别感谢护理统计随笔的粉丝朋友对我们的支持，谢谢！\n\n\n\n适用对象\n主要适用于护理专业的研究者和学生，医学、心理学领域也可以略作参考。\n\n\n本书特点\n\n开源免费：一份关于症状网络分析的完整的入门级资料。\n实用性强：实战为主，也会涉及到一些理论层面的知识。\n提供代码：所有代码可以便捷复制。\n\n\n\n提醒\n虽然已多次对这些内容（尤其是实操部分）进行测试，但执笔人毕竟水平有限，且编写仓促，难免会有一些文字性甚至内容上的错误，所以本材料仅供学习和参考。\n事先约定：本书参考了部分文献和材料，统一以参考文献形式著录在最后一节。另外，本书借助了gpt4.0等AI工具完成了部分工作，约占全部内容的15%。\n\n欢迎大家以各种方式批评、指正，包括但不限于公众号、微信、微信群。\n\n\n\n联系方式\n我们开通了微信公众号、微信视频号、小红书、bilibili等平台。\n虽取名护理统计随笔，但团队成员长期追踪护理研究领域前沿方法和技术，除了症状网络分析之外，还有更多更好用的热门研究方法和技巧，各类研究方向均有所涉及，麻雀虽小，五脏俱全，欢迎关注。\n1、微信公众号：\n\n\n\n\n\n2、微信视频号：\n\n\n\n\n\n3、个人微信：\n\n\n\n\n\n4、小红书：护理统计随笔（点击链接可以直达）\n5、b站（bilibili）：护理统计随笔（点击链接可以直达）"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "《症状网络分析入门》网站。"
  },
  {
    "objectID": "基础知识.html",
    "href": "基础知识.html",
    "title": "症状网络",
    "section": "",
    "text": "1 症状管理与症状科学\n症状管理是如今护理研究领域的热点之一，随着研究的深入，研究者对症状管理的关注点从既往的单一症状（symptom）、症状群（symptom cluster），逐渐转移到了症状网络层面。一些学者在此基础上提出了症状科学的概念，并进行了完善和补充。\n症状科学是一种新兴的方法，深入探索复杂症状及症状网络、表型特征、生物标志物，以及患者结局背后的生物学、病理生理学和／或基因组学的机制，可以帮助医护工作者更好地了解患者症状的相互作用机制，从而更好地制定更精准的干预。有关症状科学更为全面、准确的阐述，可以看看复旦大学胡雁教授的文章《症状科学的发展及研究趋势》。\n需要注意的是，症状网络分析只是症状科学研究的第一个环节。\n\n\n2 症状网络\n通俗理解症状网络，就是利用一种被称为网络分析的技术对诸多症状的关系（或者交互作用）进行计算并可视化。它通过计算一系列指标，让我们了解这些症状的成对关系，寻找核心症状，以便于后续对核心症状进行精准管理和控制。\n症状网络听起来有些”高大上”，但实则也只是网络分析在症状科学中的一种应用，这就意味着，症状网络并不局限于对症状进行分析，任何你感兴趣的研究变量（甚至量表条目），其实都可以将其加入网络，只不过是研究领域有所差异，比如症状网络倾向于分析症状（生理、心理），其他的可能是分析一些社会属性（社会网络分析）。\n所以说，如果你想要对症状网络有个更本质的了解，还需要从网络分析的相关知识学起，而不是拘泥于”症状”本身。\n\n\n3 网络分析基础\n\n\n3.1 网络结构\n节点（node）、边（edge）是最基础的网络结构。\n节点就是我们想要分析的变量，也可以是量表的条目，代入症状科学研究场景，每一个节点代表了每一种”症状”。\n边是两个节点之间的关系，连线越粗，关系越密切；颜色表示方向，一般是红色表示负向关系，蓝色表示正向关系，当然这个颜色是可以自己调节的。边分为有向和无向两种，下面就是一张用人格问卷数据拟合的横向网络图，其中的节点是人格问卷的条目，由于是横断面研究数据，所以这里的连线（边）是没有方向的。\n有的网络图还会有一个代表每个节点的可预测性的环，这个我们会在实战中进行演示。\n\n\n\n\n\n\n\n3.2 网络估计方法\n网络估计算法常根据数据的类型来选择，连续变量采用高斯图模型（GMM），二分类变量采用Ising 模型，不同数据类型混合的话采用混合图模型（MGM）。\n高斯图模型是最常见的图模型，是一种连续的概率图模型，要求数据服从多元正态分布，高斯图的称呼比较多且不统一，看文献时要根据实际情况去判断。\nIsing 模型本质是logistic回归，我看了些资料，发现其只能处理二分类变量，如果是多分类变量，则要使用mgm去估计。\n还有个需要注意的地方，就是我们需要指定数据的输入，即估计相关网络，还是偏相关网络。两者的区别可以通过百度查看，相关就是字面意思，偏相关是指控制了其他变量之后，两个变量之间的关系，在一些场景下，用后者可能更好，尤其是想要做因果推断的时候。\n个人认为，不同类型的网络的最大区别点就在于这个输入数据上面，比如大部分论文作者或者博主推荐使用的网络分析可视化函数（qgraph），是可以接受多种类型数据的。可以这么说，玩懂了这个输入数据，常用的网络分析方法差不多可以通吃了。\n\n\n3.3 相关指标\n做症状网络研究或者其他领域的网络分析，除了想要了解不同节点之间的关系之外，通常想要计算出哪些节点的影响力最大或者最重要。\n一些常用的算法会将比较重要的节点或者关联比较密切的节点对放在网络比较中心的位置，但不同算法下节点的位置可能有不同的含义，不能仅仅根据图的位置来判断重要的节点，所以需要结合一些特异性指标来判断，例如节点指标（中心性）、网络层面指标，以及准确性、稳定性、差异性分析等。\n3.3.1 节点指标\n节点指标包括中心性、预期影响系数、可预测性等。\n①中心性指标可以用于量化节点的重要程度，数值越大代表节点在整个网络中的重要性越高，包括强度（strength）、紧密性（closeness） 、 中介（betweenness）三种。\n强度中心性：与一个节点相连所有边的权重之和，是最重要的中心性指标。\n紧密中心性：一个节点到达网络中所有其他节点的最短路径的平均长度的倒数，这个用得不多。\n中介中心性：一个节点在网络中所有最短路径中出现的频率，这个用得不多。\n②预期影响系数：是一种类似强度中心性的量化节点影响力的指标，同时考虑正负相关，这个用得多。\n③可预测性：节点受其他节点影响的程度，本质是回归分析中的R2，这个用得多。\n3.3.2 准确性、稳定性、差异性分析\n仅一次网络估计是很难说得到的网络是否科学的，所以需要通过bootstrap（自助重抽样）方法对其进行准确性、稳定性检验，根据研究目的可能还会对各节点和边进行差异性分析。\n①准确性分析通常是针对边（edge）的，通过计算95%的CI来判断其准确性，当然这里不是通过是否包含0来判断，而是根据其CI是”宽”还是”窄”来判断。bootstrap法分为参数bootstrap或者非参数bootstrap，顾名思义，前者是对估计出来的参数进行重抽样，后者是对原数据进行重抽样。在网络分析中，通常选择非参数bootstrap。\n②稳定性分析是针对中心性的，有点类似于我们做临床研究时的敏感性分析，这里通常会采用剔除法评估中心性指标的稳定性，包括case剔除以及node剔除。通常不会选择节点剔除，因为我们不知道哪个节点是重要的。case剔除就是减少样本量，通过不断重复计算中心性，然后估计相关稳定性系数（CS系数）来评估稳定程度。一般要求CS&gt;0.5。\n③差异性分析：得到一份准确、稳定的网络之后，我们可能对一些核心节点（症状）、边进行比较，同样的是采用bootstrap法，通过重抽样构建指标的置信区间（与0比较）进行判断。\n值得注意的是，不同的网络也是可以比较的，比如要分析性别对某个症状网络的影响，除了把它当做协变量纳入之外，还可以尝试分别构建男性网络和女性网络，然后采用统计检验的方法进行比较（NCT）。NCT分别检验了3种假设：结构不变性、强度不变性和边不变性。这个同样会在后续的内容中进行实战演示。\n3.3.3 网络层面指标\n包括网络密度（density）和连通性（Connectivity）。\n①网络密度代表了网络中实际存在的连接（边）与所有可能的连接（边）之间的比例。网络密度可以被视为网络的”紧密程度”或”联结程度”的指标。范围是0-1，单一使用的作用一般不大。\n②网络连通性描述了网络中节点之间的相互连接程度，在症状网络中，高连通性意味着症状彼此容易影响。\n\n\n3.4 症状网络常见分类\n分类是需要参照物的，当考虑的角度不同时，可能会有多种不同的分类方法。所以症状网络的类型说不准的。\n按照复旦大学朱政教授研究团队的分类：症状网络可以分为同期网络、动态网络、个体化网络（根据数据类型）。其提到同期网络用于横断面研究，但其实向量自回归模型也可以分解出同期网络模型来。动态网络定义也过于宽泛。\n我个人推荐根据研究设计和算法来分：横断面网络、纵向网络；纵向网络可能还可以细分为交叉滞后网络模型、时变网络模型，等等。这些模型采取的算法与前面提到的可能有些差异，会分散在实战中进行解释。\n\n\n4 小结与建议\n症状网络对我们从生理学机制解读疾病症状、开展精准护理很有帮助，有助于理解多因多果，发展很快，从横向发展到了纵向。症状网络分析的本质是网络分析，通常涉及到数据类型、统计方法、相关指标的选择和计算。\n学习建议：如果你有网络模型相关的进阶需求，症状网络的教程不多，强烈建议从网络分析相关技术入手。"
  },
  {
    "objectID": "基础知识.html#症状网络",
    "href": "基础知识.html#症状网络",
    "title": "症状网络",
    "section": "",
    "text": "症状科学研究经久不衰，从最开始的单个症状研究，到后面的症状群研究，再到现在的症状网络研究，反映着现代学者对症状管理研究的逐渐深入。"
  },
  {
    "objectID": "横断面网络.html",
    "href": "横断面网络.html",
    "title": "横断面网络",
    "section": "",
    "text": "从这节开始，将分段演示如何采用R软件进行各种网络分析建模，主要内容请见右上角的目录。\n为避免出现版本兼容性问题，大家可以先看看我使用的编程环境（见文末）。\n\n1 导入工具包\n依次导入下面六个包，第一个和第六个包是辅助包，提供了一些不错的工具；第二个是本期分析主要使用的包，第三个包提供了一些本次会用到的数据，第四个第五个是非常关键的包，包括但不限于用于计算稳定性和可预测性。\n如果你还没安装，请先执行被注释掉的”install.packages”语句。\n\n\n2 整理数据\n这里使用的是bfi人格问卷数据，这份数据是R语言内置的公开数据集。具体细节请使用?psych::bfi查询。\n网络分析比较吃硬件资源，所以这次我们仅选取少量数据进行分析：500x15，即500人，15个条目。\n\nmd = bfi[1:500,1:15] \nstr(md)\n\n'data.frame':   500 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 4 2 ...\n $ A2: int  4 4 4 4 3 6 5 3 3 5 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 6 ...\n $ A4: int  4 2 4 5 4 6 3 5 3 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 3 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 6 ...\n $ C2: int  3 4 5 4 4 6 4 2 6 5 ...\n $ C3: int  3 4 4 3 5 6 4 4 3 6 ...\n $ C4: int  4 3 2 5 3 1 2 2 4 2 ...\n $ C5: int  4 4 5 5 2 3 3 4 5 1 ...\n $ E1: int  3 1 2 5 2 2 4 3 5 2 ...\n $ E2: int  3 1 4 3 2 1 3 6 3 2 ...\n $ E3: int  3 6 4 4 5 6 4 4 NA 4 ...\n $ E4: int  4 4 4 4 4 5 5 2 4 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 3 5 ...\n\nhead(md)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6\n\n\n由于横断面网络分析不能有缺失值，所以来个简单处理：剔除有缺失值的行。\n\nmd=na.omit(md)\nstr(md)\n\n'data.frame':   468 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 2 4 ...\n $ A2: int  4 4 4 4 3 6 5 3 5 4 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 5 ...\n $ A4: int  4 2 4 5 4 6 3 5 6 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 5 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 4 ...\n $ C2: int  3 4 5 4 4 6 4 2 5 3 ...\n $ C3: int  3 4 4 3 5 6 4 4 6 5 ...\n $ C4: int  4 3 2 5 3 1 2 2 2 3 ...\n $ C5: int  4 4 5 5 2 3 3 4 1 2 ...\n $ E1: int  3 1 2 5 2 2 4 3 2 1 ...\n $ E2: int  3 1 4 3 2 1 3 6 2 3 ...\n $ E3: int  3 6 4 4 5 6 4 4 4 2 ...\n $ E4: int  4 4 4 4 4 5 5 2 5 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 5 4 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:32] 9 63 66 72 90 107 112 130 133 168 ...\n  ..- attr(*, \"names\")= chr [1:32] \"61630\" \"61754\" \"61759\" \"61772\" ...\n\n\n\n\n3 可视化网络模型\n一般有如下几个步骤：计算相关或者偏相关矩阵；分配组（可以是症状群，可以不用）；建模并可视化。\n\n# 计算相关矩阵\nCorMat=cor_auto(md)\n\nVariables detected as ordinal: A1; A2; A3; A4; A5; C1; C2; C3; C4; C5; E1; E2; E3; E4; E5\n\n# 模拟分组向量，具体请根据自己的研究来\ngroups=c(rep('A',5),rep('C',5),rep('E',5))\n\n# 默认参数建模\nq = qgraph(CorMat,#相关矩阵\n           layout = \"spring\",#图形布局算法\n           groups=groups, #分组信息\n           details = TRUE, #显示细节\n           theme='colorblind'#主题\n           ) \n\n\n\n\n也可以不分组，看看效果。\n\nq1 = qgraph(CorMat,#相关矩阵\n           layout = \"spring\",#图形布局算法\n           details = TRUE, #显示细节\n           theme='colorblind'#主题\n           ) \n\n\n\n\n你觉得图形不好看，自己根据函数的帮助文档自己调整参数。\n\n\n4 另一种建模方法\n发现了吗？横断面网络模型（同期网络）的建模和可视化是非常简单的，我一般喜欢用bootnet建模，当然了，由于设置的算法不同，这两者所得网络是有区别的，择其一即可。\n这里我们使用强大的bootnet包，等下我们做稳定性、准确性分析都会用到它。\n建模一行代码搞定，用默认参数问题不大。\n\n# Estimate network\n# 这里输入的是原始数据，采用EBICglasso算法计算输入矩阵\nNetwork = estimateNetwork(md, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\n# plot network\nplot(Network, layout = 'spring')\n\n\n\n\n\n\n5 计算中心性指标\n计算第一个网络模型的中心性指标，很轻松。\n\ncentrality(q)\n\n$OutDegree\n      A1       A2       A3       A4       A5       C1       C2       C3 \n1.736067 4.136744 4.185174 3.459108 4.588298 3.147499 3.386425 2.647192 \n      C4       C5       E1       E2       E3       E4       E5 \n3.196841 3.106400 3.266836 4.002216 3.672419 4.181569 4.352452 \n\n$InDegree\n      A1       A2       A3       A4       A5       C1       C2       C3 \n1.736067 4.136744 4.185174 3.459108 4.588298 3.147499 3.386425 2.647192 \n      C4       C5       E1       E2       E3       E4       E5 \n3.196841 3.106400 3.266836 4.002216 3.672419 4.181569 4.352452 \n\n$Closeness\n        A1         A2         A3         A4         A5         C1         C2 \n0.01208905 0.01777845 0.01795918 0.01719543 0.01914391 0.01475588 0.01595325 \n        C3         C4         C5         E1         E2         E3         E4 \n0.01410542 0.01470529 0.01454764 0.01626079 0.01859869 0.01815438 0.01818626 \n        E5 \n0.02126792 \n\n$Betweenness\nA1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 \n 0 18  0  2  2  0  4  0  0  0  0  2  0  2 42 \n\n$InExpectedInfluence\n        A1         A2         A3         A4         A5         C1         C2 \n-1.0911530  1.6851506  1.9382873  1.6382411  1.9301633  0.8583539  1.4462001 \n        C3         C4         C5         E1         E2         E3         E4 \n 1.1753135 -1.2361655 -1.3086316 -1.6998553 -1.9861568  1.5919209  1.5421715 \n        E5 \n 1.4202353 \n\n$OutExpectedInfluence\n        A1         A2         A3         A4         A5         C1         C2 \n-1.0911530  1.6851506  1.9382873  1.6382411  1.9301633  0.8583539  1.4462001 \n        C3         C4         C5         E1         E2         E3         E4 \n 1.1753135 -1.2361655 -1.3086316 -1.6998553 -1.9861568  1.5919209  1.5421715 \n        E5 \n 1.4202353 \n\n$ShortestPathLengths\n         A1       A2       A3       A4       A5       C1       C2       C3\nA1 0.000000 2.192380 3.519328 4.767491 4.025087 7.422075 8.220801 7.501337\nA2 2.192380 0.000000 1.821282 2.575111 2.114002 5.229695 6.028421 5.308957\nA3 3.519328 1.821282 0.000000 2.729549 1.723567 5.757156 5.666207 5.070742\nA4 4.767491 2.575111 2.729549 0.000000 2.514570 5.766440 3.539533 5.569323\nA5 4.025087 2.114002 1.723567 2.514570 0.000000 6.398416 5.521765 6.701127\nC1 7.422075 5.229695 5.757156 5.766440 6.398416 0.000000 2.226907 2.892613\nC2 8.220801 6.028421 5.666207 3.539533 5.521765 2.226907 0.000000 2.236184\nC3 7.501337 5.308957 5.070742 5.569323 6.701127 2.892613 2.236184 0.000000\nC4 7.325279 6.213435 6.957908 5.724084 6.002827 2.455908 2.184551 3.045985\nC5 8.878911 6.859716 6.005458 4.284605 4.853824 3.886195 3.328085 2.940947\nE1 6.292386 4.100005 4.166015 5.008539 3.107798 6.214881 5.338229 6.517591\nE2 6.476632 4.284251 3.228590 4.074237 2.484376 4.568518 4.887529 6.066891\nE3 5.225746 3.033365 2.739891 4.427392 2.241199 5.879803 5.003151 6.182513\nE4 5.051349 2.858969 2.619437 2.938715 1.825769 5.394177 5.701641 6.881003\nE5 5.820650 3.628270 3.676697 4.235405 2.721615 3.676801 2.800149 3.979511\n         C4       C5       E1       E2       E3       E4       E5\nA1 7.325279 8.878911 6.292386 6.476632 5.225746 5.051349 5.820650\nA2 6.213435 6.859716 4.100005 4.284251 3.033365 2.858969 3.628270\nA3 6.957908 6.005458 4.166015 3.228590 2.739891 2.619437 3.676697\nA4 5.724084 4.284605 5.008539 4.074237 4.427392 2.938715 4.235405\nA5 6.002827 4.853824 3.107798 2.484376 2.241199 1.825769 2.721615\nC1 2.455908 3.886195 6.214881 4.568518 5.879803 5.394177 3.676801\nC2 2.184551 3.328085 5.338229 4.887529 5.003151 5.701641 2.800149\nC3 3.045985 2.940947 6.517591 6.066891 6.182513 6.881003 3.979511\nC4 0.000000 1.956734 5.819291 5.368590 5.484213 6.182702 3.281211\nC5 1.956734 0.000000 6.006993 4.300280 5.671915 6.297076 3.468913\nE1 5.819291 6.006993 0.000000 1.768919 2.549088 2.069824 2.538080\nE2 5.368590 4.300280 1.768919 0.000000 2.174253 1.996796 2.087379\nE3 5.484213 5.671915 2.549088 2.174253 0.000000 2.267609 2.203002\nE4 6.182702 6.297076 2.069824 1.996796 2.267609 0.000000 2.901491\nE5 3.281211 3.468913 2.538080 2.087379 2.203002 2.901491 0.000000\n\n$ShortestPaths\n   A1   A2   A3   A4   A5   C1   C2   C3   C4   C5   E1   E2   E3   E4   E5  \nA1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA2 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA3 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA4 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA5 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC2 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC3 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC4 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC5 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE2 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE3 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE4 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE5 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\n\n\n强度中心性报告了OutDegree与InDegree，但由于是横断面网络模型，所以它们是一样的，在有向图模型中，它们就会有差异了。\n可视化中心性指标：\n\ncentralityPlot(q, include=c(\"Strength\",\n                            'ExpectedInfluence',\n                            'Closeness',\n                            \"Betweenness\"))\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n由于没有进行标准化处理，所以有些指标的x轴刻度范围有些大。可以加一个scale参数进行控制。\n\ncentralityPlot(q, include=c(\"Strength\",\n                            'ExpectedInfluence',\n                            'Closeness',\n                            \"Betweenness\"),\n                            scale = \"z-scores\")\n\nNote: z-scores are shown on x-axis rather than raw centrality indices.\n\n\n\n\n\n\n\n6 桥梁节点分析\n在网络分析中，桥梁节点（Bridge Node）是指那些在不同社区或群组之间起到连接作用的节点。它们在网络中扮演着沟通不同群体的关键角色。桥梁节点的概念有助于识别那些在网络中可能对信息流通和群体间联系至关重要的节点。\n桥梁节点（桥梁症状）的识别通常涉及到计算所谓的”桥梁中心性”（Bridge Centrality），这是一种网络分析中用来识别节点在不同社区或群体间重要性的指标，同样包括3种：桥梁强度、桥梁紧密度、桥梁中介性。桥梁中心性可以通过不同的方法来计算，这里就不展开描述了。\n桥梁中心性的计算用代码很容易搞定：\n\nbridge(CorMat, communities= groups, directed=FALSE)\n\n$`Bridge Strength`\n       A1        A2        A3        A4        A5        C1        C2        C3 \n0.6192786 2.2701858 2.4054126 2.1786558 2.8889458 1.6882345 1.7319479 1.1859660 \n       C4        C5        E1        E2        E3        E4        E5 \n1.4925433 1.6975235 1.4320906 1.9970992 1.9252748 2.4119903 2.6808076 \n\n$`Bridge Betweenness`\nA1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 \n28  0  0  0  0  0  1  0 24  0  0  1  0  0 39 \n\n$`Bridge Closeness`\n        A1         A2         A3         A4         A5         C1         C2 \n0.06040055 0.06449706 0.06464877 0.06334587 0.06633877 0.07740360 0.08148539 \n        C3         C4         C5         E1         E2         E3         E4 \n0.07593488 0.04662243 0.04377595 0.03678090 0.03806534 0.09428918 0.09357638 \n        E5 \n0.10564254 \n\n$`Bridge Expected Influence (1-step)`\n         A1          A2          A3          A4          A5          C1 \n 0.02563498  0.73084283  0.72681593  0.61394087  0.72769426  0.72809473 \n         C2          C3          C4          C5          E1          E2 \n 1.30818928  1.05074235 -0.55397879 -0.92186642 -0.99574380 -1.11167378 \n         E3          E4          E5 \n 1.54922696  1.74046318  1.49472703 \n\n$`Bridge Expected Influence (2-step)`\n       A1        A2        A3        A4        A5        C1        C2        C3 \n-1.003904  2.697975  2.833111  2.472744  2.982608  4.686390  5.172403  4.114575 \n       C4        C5        E1        E2        E3        E4        E5 \n-4.503411 -4.723141 -5.295025 -6.277542  6.184953  6.796393  6.512929 \n\n$communities\n [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"C\" \"C\" \"C\" \"C\" \"C\" \"E\" \"E\" \"E\" \"E\" \"E\"\n\n\n不但给出了3个桥梁中心性指标，还给出了预期影响（一步法、两步法都有）。可视化也是很容易的：\n\n#可视化桥梁症状网络\nb = bridge(CorMat, communities= groups, directed=F) \nplot(b, \n     include=c(\"Bridge Expected Influence (2-step)\", \"Bridge Strength\", \"Bridge Closeness\"), #选择要呈现的指标\n     theme_bw=F, \n     raw0 = T, \n     signed=T,\n     zscore=T,     #标准化\n     order=\"value\"  #排序\n     ) \n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\nVectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\nVectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n\n\n\n看到一些研究者在文献中推荐用桥梁强度最大的节点作为桥梁节点，但也有文献认为应使用第80百分位数的桥梁强度/预期影响截止值选择桥梁症状。这里演示下如何用桥梁强度查询符合条件的节点。\n\nchoose_set = b$`Bridge Strength`&gt;quantile(b$`Bridge Strength`,\n                             probs = 0.8,\n                             na.rm = T)\nnode_name = b$`Bridge Strength`[choose_set]\nnode_name\n\n      A5       E4       E5 \n2.888946 2.411990 2.680808 \n\n\n可以看到，15个症状节点里面，有3个症状符合条件。如果你需要对其进行可视化，可以先标记出来，然后将其传入qgraph函数的groups参数。\n\n\n7 计算可预测性\n有些学者不推荐在同期/横断面网络分析中计算可预测性，但个人认为这是个不错的指标，相当于做了很多次回归分析，可以分析其他变量对节点的影响。计算方法其实很简单，这里演示下如何进行计算并对其进行可视化。\n用mgm包建模：\n\n# mgm需要输入矩阵形式的数据，所以先做转换\nmat_data = as.matrix(md)\n\n# 建模，参数调整的细节请看帮助文档，在后续的混合建模中也会讲到\npre_mod = mgm(data = mat_data,\n                   type = rep('g',15),\n                   level = rep(1,15),\n                   lambdaSel = \"CV\",\n                   ruleReg = \"AND\", \n                   # pbar = T, \n                   overparameterize = F, \n                   signInfo = F)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |-----                                                                 |   7%\n  |                                                                            \n  |---------                                                             |  13%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |-------------------                                                   |  27%\n  |                                                                            \n  |-----------------------                                               |  33%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |---------------------------------                                     |  47%\n  |                                                                            \n  |-------------------------------------                                 |  53%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |-----------------------------------------------                       |  67%\n  |                                                                            \n  |---------------------------------------------------                   |  73%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |-------------------------------------------------------------         |  87%\n  |                                                                            \n  |-----------------------------------------------------------------     |  93%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\n\n\n速度是很快的，建模后通过预测函数提取可预测性值：\n\npred_mgm = predict(object = pre_mod, \n                    data = mat_data,\n                    errorCon = c(\"R2\"))\npred_mgm$errors\n\n   Variable    R2\n1        A1 0.197\n2        A2 0.403\n3        A3 0.376\n4        A4 0.227\n5        A5 0.444\n6        C1 0.244\n7        C2 0.355\n8        C3 0.266\n9        C4 0.349\n10       C5 0.286\n11       E1 0.334\n12       E2 0.424\n13       E3 0.323\n14       E4 0.404\n15       E5 0.357\n\n\n有兴趣的话，你也可以对这个值进行排序。由于本节内容很多，就不展示具体操作了。\n接下来，建立网络模型并绘制带有可预测性值的网络图：\n\nNetwork2 = estimateNetwork(mat_data, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\nplot(Network2,\n     layout = \"spring\",\n     pie=pred_mgm$errors[,2]\n     )\n\n\n\n\n\n\n8 精确性、稳定性、差异性分析\nok，接下来就该进行精确性、稳定性以及差异性分析了，由于涉及到重抽样，这个步骤需要花费一些时间，具体看你的电脑配置，演示时会尽量减少抽样次数。\n我们继续用bootnet包进行分析：\n\nbaseboot = bootnet(md, \n                  default = \"EBICglasso\", \n                  threshold = FALSE,\n                  type=\"nonparametric\", #选择非参数自举法\n                  nCores = 8, #8线程，根据自己电脑配置来\n                  statistics=\"all\",\n                  nBoots=500 \n) \n\nEstimating sample network...\n\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\n\nBootstrapping...\n\n\nComputing statistics...\n\n\n\n注意：nBoots默认为1000，为提高速度，这里减少了次数，真实研究至少1000次以上。\n\n绘制边缘权重精确性分析图：\n\nplot(baseboot, labels=FALSE, order=\"sample\") #默认绘制的统计量是edge\n\n\n\n\n这个置信区间（阴影部分）还是有些宽的。绘制边缘权重差异性分析图：\n\nplot(baseboot,\n     statistics='edge',\n     plot = \"difference\", \n     onlyNonZero = T, \n     order = \"sample\")\n\nExpected significance level given number of bootstrap samples is approximately: 0.05\n\n\n\n\n\n你是否会困惑：怎么看这幅图？答案是看黑格子数，黑色方格表示的是有两条边之间有显著差异，由于上面已经写了排序的代码，所以直接看y轴就可以了，越高的位置表示此edge与越多的其余edge有显著差异。这个例子，C4-C5与和E1-E2的边缘权重与其他有显著差别。\n同样，可以检验不同节点中心性之间的差异：\n\nplot(baseboot, statistics=\"Strength\", plot=\"difference\",order = \"mean\")\n\nExpected significance level given number of bootstrap samples is approximately: 0.05\n\n\n\n\n\n解释方法同前。上面是图形展示，当然是可以直接计算数值的，这里就不展示了，有需求的话，可以通过护理统计随笔公众号或者微信留言，会考虑通过更新的方式进行补充。\n中心性指标的稳定性也是可以通过bootnet进行计算：\n\n# 采用剔除案例法\ncaseboot = bootnet(md, \n                   nBoots = 500, \n                   nCores = 12, \n                   threshold = FALSE, \n                   default = \"EBICglasso\", \n                   type=\"case\", \n                   statistics=\"all\",\n                   verbose = F)\n\n\n注意：nBoots默认为1000，为提高速度，这里减少了次数，真实研究至少1000次以上。\n\n计算相关稳定性系数CS：\n\ncorStability(caseboot) \n\n=== Correlation Stability Analysis === \n\nSampling levels tested:\n   nPerson Drop%  n\n1      117  75.0 42\n2      153  67.3 55\n3      190  59.4 38\n4      226  51.7 55\n5      263  43.8 61\n6      299  36.1 53\n7      335  28.4 45\n8      372  20.5 48\n9      408  12.8 60\n10     445   4.9 43\n\nMaximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:\n\nbetweenness: 0.128 \n  - For more accuracy, run bootnet(..., caseMin = 0.049, caseMax = 0.205) \n\ncloseness: 0.284 \n  - For more accuracy, run bootnet(..., caseMin = 0.205, caseMax = 0.361) \n\ndistance: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nedge: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\neigenvector: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nexpectedInfluence: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nhybrid: 0.438 \n  - For more accuracy, run bootnet(..., caseMin = 0.361, caseMax = 0.517) \n\nlength: 0 \n  - For more accuracy, run bootnet(..., caseMin = 0, caseMax = 0.049) \n\nrspbc: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nstrength: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nAccuracy can also be increased by increasing both 'nBoots' and 'caseN'.\n\n\n绘图:\n\nplot(caseboot, statistics=\"all\")\n\n\n\n\n选几个指标来绘图：\n\nplot(caseboot, statistics = c(\"Strength\",\"Closeness\",\n                             \"expectedInfluence\"))\n\n\n\n\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] networktools_1.5.1 mgm_1.2-14         bootnet_1.6        ggplot2_3.5.0     \n[5] psych_2.3.9        qgraph_1.9.8       psychTools_2.4.3  \n\nloaded via a namespace (and not attached):\n  [1] mnormt_2.1.1         pbapply_1.7-2        polynom_1.4-1       \n  [4] gridExtra_2.3        fdrtool_1.2.17       rlang_1.1.3         \n  [7] magrittr_2.0.3       e1071_1.7-13         compiler_4.3.2      \n [10] gdata_3.0.0          IsingSampler_0.2.3   png_0.1-8           \n [13] vctrs_0.6.4          reshape2_1.4.4       quadprog_1.5-8      \n [16] stringr_1.5.1        pkgconfig_2.0.3      shape_1.4.6         \n [19] fastmap_1.1.1        backports_1.4.1      labeling_0.4.3      \n [22] pbivnorm_0.6.0       utf8_1.2.4           rmarkdown_2.25      \n [25] NetworkToolbox_1.4.2 heplots_1.6.0        nloptr_2.0.3        \n [28] purrr_1.0.2          xfun_0.41            glmnet_4.1-8        \n [31] jomo_2.7-6           jsonlite_1.8.7       pan_1.9             \n [34] jpeg_0.1-10          broom_1.0.5          parallel_4.3.2      \n [37] lavaan_0.6-17        cluster_2.1.4        R6_2.5.1            \n [40] stringi_1.8.1        RColorBrewer_1.1-3   smacof_2.1-5        \n [43] car_3.1-2            boot_1.3-28.1        rpart_4.1.21        \n [46] Rcpp_1.0.11          iterators_1.0.14     knitr_1.45          \n [49] snow_0.4-4           base64enc_0.1-3      R.utils_2.12.3      \n [52] weights_1.0.4        Matrix_1.6-5         nnls_1.5            \n [55] splines_4.3.2        nnet_7.3-19          igraph_2.0.1.1      \n [58] tidyselect_1.2.0     rstudioapi_0.16.0    abind_1.4-5         \n [61] yaml_2.3.7           doParallel_1.0.17    codetools_0.2-19    \n [64] lattice_0.21-9       tibble_3.2.1         plyr_1.8.9          \n [67] withr_2.5.2          evaluate_0.23        foreign_0.8-85      \n [70] survival_3.5-7       proxy_0.4-27         pillar_1.9.0        \n [73] carData_3.0-5        mice_3.16.0          checkmate_2.3.0     \n [76] foreach_1.5.2        rtf_0.4-14.1         stats4_4.3.2        \n [79] IsingFit_0.4         ellipse_0.5.0        generics_0.1.3      \n [82] candisc_0.8-6        munsell_0.5.0        scales_1.3.0        \n [85] minqa_1.2.6          gtools_3.9.5         class_7.3-22        \n [88] glue_1.6.2           Hmisc_5.1-1          tools_4.3.2         \n [91] data.table_1.15.4    lme4_1.1-35.1        mvtnorm_1.2-3       \n [94] rgl_1.2.1            grid_4.3.2           plotrix_3.8-4       \n [97] tidyr_1.3.1          colorspace_2.1-0     nlme_3.1-163        \n[100] htmlTable_2.4.2      eigenmodel_1.11      Formula_1.2-5       \n[103] cli_3.6.2            fansi_1.0.5          dplyr_1.1.4         \n[106] corpcor_1.6.10       glasso_1.11          gtable_0.3.4        \n[109] R.methodsS3_1.8.2    digest_0.6.33        wordcloud_2.6       \n[112] farver_2.1.1         htmlwidgets_1.6.2    htmltools_0.5.7     \n[115] R.oo_1.25.0          lifecycle_1.0.4      mitml_0.4-5         \n[118] MASS_7.3-60"
  },
  {
    "objectID": "横断面网络.html#导入工具包",
    "href": "横断面网络.html#导入工具包",
    "title": "横断面网络",
    "section": "1 导入工具包",
    "text": "1 导入工具包\n依次导入下面三个包，第一个包是辅助包，提供了一些不错的工具；第二个是本期分析主要使用的包，第三个包提供了一些本次会用到的数据。如果你还没安装，请先执行被注释掉的\"install.packages\"语句。\n\n2 整理数据\n这里使用的是bfi人格问卷数据，这份数据是R语言内置的公开数据集。具体细节请使用?psych::bfi查询。\n网络分析比较吃硬件资源，所以这次我们仅选取少量数据进行分析：500x15，即500人，15个条目。\n\nmd = bfi[1:500,1:15] \nstr(md)\n\n'data.frame':   500 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 4 2 ...\n $ A2: int  4 4 4 4 3 6 5 3 3 5 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 6 ...\n $ A4: int  4 2 4 5 4 6 3 5 3 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 3 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 6 ...\n $ C2: int  3 4 5 4 4 6 4 2 6 5 ...\n $ C3: int  3 4 4 3 5 6 4 4 3 6 ...\n $ C4: int  4 3 2 5 3 1 2 2 4 2 ...\n $ C5: int  4 4 5 5 2 3 3 4 5 1 ...\n $ E1: int  3 1 2 5 2 2 4 3 5 2 ...\n $ E2: int  3 1 4 3 2 1 3 6 3 2 ...\n $ E3: int  3 6 4 4 5 6 4 4 NA 4 ...\n $ E4: int  4 4 4 4 4 5 5 2 4 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 3 5 ...\n\nhead(md)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] psych_2.3.9      qgraph_1.9.8     psychTools_2.4.3\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    gtools_3.9.5      lattice_0.21-9   \n [5] jpeg_0.1-10       stringi_1.8.1     digest_0.6.33     magrittr_2.0.3   \n [9] evaluate_0.23     grid_4.3.2        fastmap_1.1.1     Matrix_1.6-5     \n[13] R.oo_1.25.0       plyr_1.8.9        jsonlite_1.8.7    nnet_7.3-19      \n[17] backports_1.4.1   Formula_1.2-5     gridExtra_2.3     fansi_1.0.5      \n[21] rtf_0.4-14.1      scales_1.3.0      pbapply_1.7-2     pbivnorm_0.6.0   \n[25] abind_1.4-5       mnormt_2.1.1      cli_3.6.2         rlang_1.1.3      \n[29] R.methodsS3_1.8.2 munsell_0.5.0     Hmisc_5.1-1       base64enc_0.1-3  \n[33] yaml_2.3.7        parallel_4.3.2    tools_4.3.2       reshape2_1.4.4   \n[37] checkmate_2.3.0   htmlTable_2.4.2   dplyr_1.1.4       colorspace_2.1-0 \n[41] corpcor_1.6.10    ggplot2_3.5.0     fdrtool_1.2.17    vctrs_0.6.4      \n[45] R6_2.5.1          png_0.1-8         rpart_4.1.21      stats4_4.3.2     \n[49] lifecycle_1.0.4   stringr_1.5.1     htmlwidgets_1.6.2 foreign_0.8-85   \n[53] cluster_2.1.4     glasso_1.11       pkgconfig_2.0.3   pillar_1.9.0     \n[57] gtable_0.3.4      glue_1.6.2        data.table_1.15.4 Rcpp_1.0.11      \n[61] xfun_0.41         tibble_3.2.1      tidyselect_1.2.0  rstudioapi_0.16.0\n[65] knitr_1.45        nlme_3.1-163      htmltools_0.5.7   igraph_2.0.1.1   \n[69] lavaan_0.6-17     rmarkdown_2.25    compiler_4.3.2    quadprog_1.5-8"
  },
  {
    "objectID": "横断面网络.html#running-code",
    "href": "横断面网络.html#running-code",
    "title": "横断面网络",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\n我的R语言环境\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] psych_2.3.9      qgraph_1.9.8     psychTools_2.4.3\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    gtools_3.9.5      lattice_0.21-9   \n [5] jpeg_0.1-10       stringi_1.8.1     digest_0.6.33     magrittr_2.0.3   \n [9] evaluate_0.23     grid_4.3.2        fastmap_1.1.1     Matrix_1.6-5     \n[13] R.oo_1.25.0       plyr_1.8.9        jsonlite_1.8.7    nnet_7.3-19      \n[17] backports_1.4.1   Formula_1.2-5     gridExtra_2.3     fansi_1.0.5      \n[21] rtf_0.4-14.1      scales_1.3.0      pbapply_1.7-2     pbivnorm_0.6.0   \n[25] abind_1.4-5       mnormt_2.1.1      cli_3.6.2         rlang_1.1.3      \n[29] R.methodsS3_1.8.2 munsell_0.5.0     Hmisc_5.1-1       base64enc_0.1-3  \n[33] yaml_2.3.7        parallel_4.3.2    tools_4.3.2       reshape2_1.4.4   \n[37] checkmate_2.3.0   htmlTable_2.4.2   dplyr_1.1.4       colorspace_2.1-0 \n[41] corpcor_1.6.10    ggplot2_3.5.0     fdrtool_1.2.17    vctrs_0.6.4      \n[45] R6_2.5.1          png_0.1-8         rpart_4.1.21      stats4_4.3.2     \n[49] lifecycle_1.0.4   stringr_1.5.1     htmlwidgets_1.6.2 foreign_0.8-85   \n[53] cluster_2.1.4     glasso_1.11       pkgconfig_2.0.3   pillar_1.9.0     \n[57] gtable_0.3.4      glue_1.6.2        data.table_1.15.4 Rcpp_1.0.11      \n[61] xfun_0.41         tibble_3.2.1      tidyselect_1.2.0  rstudioapi_0.16.0\n[65] knitr_1.45        nlme_3.1-163      htmltools_0.5.7   igraph_2.0.1.1   \n[69] lavaan_0.6-17     rmarkdown_2.25    compiler_4.3.2    quadprog_1.5-8"
  },
  {
    "objectID": "网络比较.html",
    "href": "网络比较.html",
    "title": "网络比较",
    "section": "",
    "text": "这节内容不多，介绍并演示如何采用R软件进行不同网络的比较，主要内容请见右上角的目录。\n为避免出现版本兼容性问题，大家可以先看看我使用的编程环境（见文末）。\n\n1 导入工具包\n分别需要以下R包，没有安装的请先安装，安装方法见上一节。\n\n\n2 整理数据\n这里使用的是bfi人格问卷数据，这份数据是R语言内置的公开数据集。具体细节请使用?psych::bfi查询。\n网络分析比较吃硬件资源，所以这次我们仅选取少量数据进行分析：500x15，即500人，15个条目。\n\nmd = bfi[1:500,1:15] \nstr(md)\n\n'data.frame':   500 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 4 2 ...\n $ A2: int  4 4 4 4 3 6 5 3 3 5 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 6 ...\n $ A4: int  4 2 4 5 4 6 3 5 3 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 3 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 6 ...\n $ C2: int  3 4 5 4 4 6 4 2 6 5 ...\n $ C3: int  3 4 4 3 5 6 4 4 3 6 ...\n $ C4: int  4 3 2 5 3 1 2 2 4 2 ...\n $ C5: int  4 4 5 5 2 3 3 4 5 1 ...\n $ E1: int  3 1 2 5 2 2 4 3 5 2 ...\n $ E2: int  3 1 4 3 2 1 3 6 3 2 ...\n $ E3: int  3 6 4 4 5 6 4 4 NA 4 ...\n $ E4: int  4 4 4 4 4 5 5 2 4 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 3 5 ...\n\nhead(md)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6\n\n\n由于横断面网络分析不能有缺失值，所以剔除有缺失值的行。\n\nmd=na.omit(md) \nstr(md)\n\n'data.frame':   468 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 2 4 ...\n $ A2: int  4 4 4 4 3 6 5 3 5 4 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 5 ...\n $ A4: int  4 2 4 5 4 6 3 5 6 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 5 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 4 ...\n $ C2: int  3 4 5 4 4 6 4 2 5 3 ...\n $ C3: int  3 4 4 3 5 6 4 4 6 5 ...\n $ C4: int  4 3 2 5 3 1 2 2 2 3 ...\n $ C5: int  4 4 5 5 2 3 3 4 1 2 ...\n $ E1: int  3 1 2 5 2 2 4 3 2 1 ...\n $ E2: int  3 1 4 3 2 1 3 6 2 3 ...\n $ E3: int  3 6 4 4 5 6 4 4 4 2 ...\n $ E4: int  4 4 4 4 4 5 5 2 5 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 5 4 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:32] 9 63 66 72 90 107 112 130 133 168 ...\n  ..- attr(*, \"names\")= chr [1:32] \"61630\" \"61754\" \"61759\" \"61772\" ...\n\n\n为这份选用的内置数据集添加一个分组变量sex（模拟）：\n\n#设置随机数种子\nset.seed(123) \n\n#模拟抽样\nmd$sex = sample(c(1, 2), size = 468, replace = TRUE)\n\n根据sex对数据进行分组：\n\nmale_data= as.matrix(md %&gt;% filter(sex == 1))[,-16]\nfemale_data= as.matrix(md %&gt;% filter(sex== 2))[,-16]\n\n\n\n3 建模并计算可预测性\n\n3.1 “男性”网络\n\nmale_pre_mod = mgm(data = male_data,\n              type = rep('g',15),\n              level = rep(1,15),\n              lambdaSel = \"CV\",\n              ruleReg = \"AND\",\n              # pbar = TRUE, \n              overparameterize = FALSE, \n              signInfo = FALSE)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |-----                                                                 |   7%\n  |                                                                            \n  |---------                                                             |  13%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |-------------------                                                   |  27%\n  |                                                                            \n  |-----------------------                                               |  33%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |---------------------------------                                     |  47%\n  |                                                                            \n  |-------------------------------------                                 |  53%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |-----------------------------------------------                       |  67%\n  |                                                                            \n  |---------------------------------------------------                   |  73%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |-------------------------------------------------------------         |  87%\n  |                                                                            \n  |-----------------------------------------------------------------     |  93%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\n\n\n计算可预测性值：\n\nmale_pred_mgm = predict(object = male_pre_mod , \n                   data = male_data,\n                   errorCon = c(\"R2\"))\n\n排序看看效果：\n\nmale_pred_mgm$errors %&gt;% arrange(desc(R2))\n\n   Variable    R2\n1        A5 0.479\n2        A3 0.449\n3        A2 0.412\n4        E2 0.406\n5        C2 0.385\n6        E4 0.382\n7        E5 0.360\n8        C4 0.355\n9        E1 0.329\n10       E3 0.316\n11       C5 0.290\n12       A4 0.266\n13       C3 0.252\n14       C1 0.237\n15       A1 0.221\n\n\n接下来，用bootnet包绘制带有可预测性值的网络图，先估计网络：\n\nNetwork_male = estimateNetwork(male_data, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\n\n再绘图，把male_pred_mgm$errors塞进去：\n\nplot(Network_male,layout = \"spring\",\n     pie=male_pred_mgm$errors[,2]\n)\n\n\n\n\n\n\n3.2 “女性”网络\n同样的做法：\n\n# 计算女性网络\nfemale_pre_mod = mgm(data = female_data,\n                   type = rep('g',15),\n                   level = rep(1,15),\n                   lambdaSel = \"CV\",\n                   ruleReg = \"AND\",\n                   # pbar = TRUE, \n                   overparameterize = FALSE, \n                   signInfo = FALSE)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |-----                                                                 |   7%\n  |                                                                            \n  |---------                                                             |  13%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |-------------------                                                   |  27%\n  |                                                                            \n  |-----------------------                                               |  33%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |---------------------------------                                     |  47%\n  |                                                                            \n  |-------------------------------------                                 |  53%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |-----------------------------------------------                       |  67%\n  |                                                                            \n  |---------------------------------------------------                   |  73%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |-------------------------------------------------------------         |  87%\n  |                                                                            \n  |-----------------------------------------------------------------     |  93%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\n\nfemale_pred_mgm = predict(object = female_pre_mod , \n                        data = female_data,\n                        errorCon = c(\"R2\"))\nfemale_pred_mgm$errors %&gt;% arrange(desc(R2))\n\n   Variable    R2\n1        E2 0.488\n2        A5 0.460\n3        E4 0.442\n4        A2 0.416\n5        E1 0.393\n6        E5 0.372\n7        C4 0.365\n8        C2 0.361\n9        A3 0.340\n10       C3 0.311\n11       C5 0.308\n12       E3 0.291\n13       C1 0.272\n14       A1 0.197\n15       A4 0.197\n\n# 可视化（带有可预测值的网络图）\nlibrary(bootnet)\nNetwork_female = estimateNetwork(female_data, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\nplot(Network_female,layout = \"spring\",\n     pie=female_pred_mgm$errors[,2]\n)\n\n\n\n\n\n\n\n4 网络比较\n\nnct_res=NCT(Network_male, \n              Network_female, \n              gamma=0.5,\n              it = 100, \n              test.edges=T,\n              test.centrality =T,\n              centrality = c(\"strength\",\"expectedInfluence\"),\n              p.adjust.methods = 'BH' #Bonferroni-Holm校正\n              ) \n\nNote: Input is a bootnetResult object, argument 'gamma' is ignored.\n\n\nNote: estimateNetwork object used - estimation method has possibly not been validated.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n\n\nWarning in EBICglassoCore(S = S, n = n, gamma = gamma, penalize.diagonal =\npenalize.diagonal, : A dense regularized network was selected (lambda &lt; 0.1 *\nlambda.max). Recent work indicates a possible drop in specificity. Interpret\nthe presence of the smallest edges with care. Setting threshold = TRUE will\nenforce higher specificity, at the cost of sensitivity.\n\n\n\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n注意：为节省时间，本例调小了 iteration，实际研究可以设为1000次，\n\n查看比较结果：\n\nsummary(nct_res)\n\n INDEPENDENT GROUPS GAUSSIAN NETWORK COMPARISON TEST \n\n P-VALUE CORRECTION: BH \n\n NETWORK INVARIANCE TEST \n Test statistic M: 0.1676208 \n p-value 0.7425743 \n\n GLOBAL STRENGTH INVARIANCE TEST \n Global strength per group:  5.562555 5.089144 \n Test statistic S:  0.4734111 \n p-value 0.5742574\n\n EDGE INVARIANCE TEST \n    Var1 Var2  p-value Test statistic E\n16    A1   A2 1.000000       0.10615517\n31    A1   A3 1.000000       0.01237609\n32    A2   A3 1.000000       0.01127489\n46    A1   A4 1.000000       0.00000000\n47    A2   A4 1.000000       0.08596382\n48    A3   A4 0.984888       0.11086448\n61    A1   A5 1.000000       0.00000000\n62    A2   A5 1.000000       0.00499569\n63    A3   A5 0.984888       0.11312876\n64    A4   A5 1.000000       0.06577270\n76    A1   C1 1.000000       0.00000000\n77    A2   C1 1.000000       0.01488558\n78    A3   C1 1.000000       0.01412830\n79    A4   C1 1.000000       0.00000000\n80    A5   C1 1.000000       0.00000000\n91    A1   C2 1.000000       0.00000000\n92    A2   C2 1.000000       0.00000000\n93    A3   C2 1.000000       0.00000000\n94    A4   C2 1.000000       0.04108561\n95    A5   C2 1.000000       0.00000000\n96    C1   C2 1.000000       0.07496657\n106   A1   C3 1.000000       0.00000000\n107   A2   C3 1.000000       0.02744867\n108   A3   C3 0.984888       0.08828290\n109   A4   C3 0.984888       0.02020913\n110   A5   C3 1.000000       0.00000000\n111   C1   C3 1.000000       0.05339232\n112   C2   C3 1.000000       0.02400531\n121   A1   C4 0.984888       0.10427325\n122   A2   C4 0.984888       0.00835040\n123   A3   C4 1.000000       0.00000000\n124   A4   C4 1.000000       0.00000000\n125   A5   C4 1.000000       0.00000000\n126   C1   C4 1.000000       0.04099892\n127   C2   C4 1.000000       0.04963448\n128   C3   C4 1.000000       0.07389777\n136   A1   C5 0.984888       0.02146873\n137   A2   C5 1.000000       0.00000000\n138   A3   C5 1.000000       0.00146984\n139   A4   C5 0.984888       0.09117639\n140   A5   C5 1.000000       0.00627621\n141   C1   C5 1.000000       0.01867252\n142   C2   C5 1.000000       0.00074883\n143   C3   C5 1.000000       0.07700686\n144   C4   C5 1.000000       0.10472963\n151   A1   E1 1.000000       0.00000000\n152   A2   E1 1.000000       0.02608205\n153   A3   E1 1.000000       0.00000000\n154   A4   E1 1.000000       0.00000000\n155   A5   E1 0.984888       0.09226009\n156   C1   E1 0.984888       0.01426443\n157   C2   E1 1.000000       0.00000000\n158   C3   E1 1.000000       0.00000000\n159   C4   E1 0.984888       0.05423056\n160   C5   E1 1.000000       0.00000000\n166   A1   E2 1.000000       0.00000000\n167   A2   E2 1.000000       0.00000000\n168   A3   E2 0.984888       0.05956537\n169   A4   E2 1.000000       0.01340442\n170   A5   E2 1.000000       0.06475690\n171   C1   E2 1.000000       0.02032345\n172   C2   E2 1.000000       0.00000000\n173   C3   E2 1.000000       0.00000000\n174   C4   E2 0.984888       0.01661791\n175   C5   E2 1.000000       0.02469459\n176   E1   E2 0.984888       0.16762076\n181   A1   E3 1.000000       0.00000000\n182   A2   E3 1.000000       0.10080111\n183   A3   E3 1.000000       0.05829463\n184   A4   E3 1.000000       0.00343567\n185   A5   E3 0.984888       0.10894307\n186   C1   E3 1.000000       0.00000000\n187   C2   E3 1.000000       0.00000000\n188   C3   E3 1.000000       0.00000000\n189   C4   E3 1.000000       0.00000000\n190   C5   E3 1.000000       0.00000000\n191   E1   E3 1.000000       0.03019699\n192   E2   E3 1.000000       0.12410464\n196   A1   E4 1.000000       0.00000000\n197   A2   E4 1.000000       0.01339703\n198   A3   E4 0.984888       0.09636629\n199   A4   E4 1.000000       0.02392767\n200   A5   E4 0.984888       0.11141297\n201   C1   E4 1.000000       0.06128627\n202   C2   E4 1.000000       0.00000000\n203   C3   E4 1.000000       0.00000000\n204   C4   E4 1.000000       0.00000000\n205   C5   E4 0.984888       0.01782709\n206   E1   E4 1.000000       0.08184600\n207   E2   E4 1.000000       0.10924500\n208   E3   E4 1.000000       0.06110927\n211   A1   E5 1.000000       0.02892689\n212   A2   E5 0.984888       0.07951405\n213   A3   E5 1.000000       0.00000000\n214   A4   E5 1.000000       0.02207959\n215   A5   E5 1.000000       0.05169003\n216   C1   E5 1.000000       0.05735957\n217   C2   E5 1.000000       0.04823892\n218   C3   E5 1.000000       0.06983841\n219   C4   E5 1.000000       0.01234043\n220   C5   E5 1.000000       0.02373487\n221   E1   E5 1.000000       0.00436893\n222   E2   E5 1.000000       0.09707638\n223   E3   E5 1.000000       0.04389252\n224   E4   E5 1.000000       0.00461165\n\n\n CENTRALITY INVARIANCE TEST \n Nodes tested: A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 \n Centralities tested: strength expectedInfluence\n Test statistics C: \n       strength expectedInfluence\nA1  0.036137609       0.273200114\nA2  0.072080703       0.215526141\nA3  0.225294525       0.127976286\nA4  0.217718255       0.008556629\nA5  0.062591855      -0.238889701\nC1 -0.080319204      -0.055796218\nC2  0.142201888       0.041435265\nC3 -0.029364145      -0.331173409\nC4  0.113917146      -0.256526846\nC5  0.092794640      -0.209927273\nE1 -0.001361695      -0.442340943\nE2  0.069795182      -0.388883349\nE3  0.108517464      -0.200085787\nE4 -0.075592078       0.014860103\nE5 -0.007589970      -0.282631195\n\n p-values: \n    strength expectedInfluence\nA1 0.9900990         0.6930693\nA2 0.9900990         0.8415842\nA3 0.8415842         0.9900990\nA4 0.8415842         0.9900990\nA5 0.9900990         0.8415842\nC1 0.9900990         0.9900990\nC2 0.9900990         0.9900990\nC3 0.9900990         0.8415842\nC4 0.9900990         0.8415842\nC5 0.9900990         0.8415842\nE1 0.9900990         0.6930693\nE2 0.9900990         0.6930693\nE3 0.9900990         0.8415842\nE4 0.9900990         0.9900990\nE5 0.9900990         0.8415842\n\n\nNETWORK INVARIANCE TEST是网络不变性检验，GLOBAL STRENGTH INVARIANCE TEST是全局强度不变性检验，EDGE INVARIANCE TEST是边缘不变性检验，CENTRALITY INVARIANCE TEST是中心性不变性检验。\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] psych_2.3.9                 dplyr_1.1.4                \n[3] mgm_1.2-14                  NetworkComparisonTest_2.2.2\n[5] bootnet_1.6                 ggplot2_3.5.0              \n\nloaded via a namespace (and not attached):\n  [1] mnormt_2.1.1         pbapply_1.7-2        polynom_1.4-1       \n  [4] gridExtra_2.3        fdrtool_1.2.17       rlang_1.1.3         \n  [7] magrittr_2.0.3       e1071_1.7-13         compiler_4.3.2      \n [10] gdata_3.0.0          IsingSampler_0.2.3   reshape2_1.4.4      \n [13] png_0.1-8            vctrs_0.6.4          quadprog_1.5-8      \n [16] stringr_1.5.1        pkgconfig_2.0.3      shape_1.4.6         \n [19] fastmap_1.1.1        backports_1.4.1      pbivnorm_0.6.0      \n [22] utf8_1.2.4           rmarkdown_2.25       NetworkToolbox_1.4.2\n [25] heplots_1.6.0        nloptr_2.0.3         purrr_1.0.2         \n [28] xfun_0.41            glmnet_4.1-8         jomo_2.7-6          \n [31] jsonlite_1.8.7       pan_1.9              jpeg_0.1-10         \n [34] lavaan_0.6-17        broom_1.0.5          parallel_4.3.2      \n [37] cluster_2.1.4        R6_2.5.1             stringi_1.8.1       \n [40] RColorBrewer_1.1-3   smacof_2.1-5         car_3.1-2           \n [43] boot_1.3-28.1        rpart_4.1.21         Rcpp_1.0.11         \n [46] iterators_1.0.14     knitr_1.45           snow_0.4-4          \n [49] base64enc_0.1-3      R.utils_2.12.3       weights_1.0.4       \n [52] Matrix_1.6-5         nnls_1.5             splines_4.3.2       \n [55] nnet_7.3-19          igraph_2.0.1.1       tidyselect_1.2.0    \n [58] rstudioapi_0.16.0    abind_1.4-5          yaml_2.3.7          \n [61] doParallel_1.0.17    codetools_0.2-19     qgraph_1.9.8        \n [64] plyr_1.8.9           lattice_0.21-9       tibble_3.2.1        \n [67] withr_2.5.2          evaluate_0.23        networktools_1.5.1  \n [70] foreign_0.8-85       survival_3.5-7       proxy_0.4-27        \n [73] pillar_1.9.0         carData_3.0-5        mice_3.16.0         \n [76] stats4_4.3.2         checkmate_2.3.0      foreach_1.5.2       \n [79] IsingFit_0.4         ellipse_0.5.0        generics_0.1.3      \n [82] munsell_0.5.0        candisc_0.8-6        scales_1.3.0        \n [85] minqa_1.2.6          gtools_3.9.5         class_7.3-22        \n [88] glue_1.6.2           Hmisc_5.1-1          tools_4.3.2         \n [91] data.table_1.15.4    lme4_1.1-35.1        mvtnorm_1.2-3       \n [94] rgl_1.2.1            grid_4.3.2           plotrix_3.8-4       \n [97] tidyr_1.3.1          colorspace_2.1-0     nlme_3.1-163        \n[100] htmlTable_2.4.2      eigenmodel_1.11      Formula_1.2-5       \n[103] cli_3.6.2            fansi_1.0.5          glasso_1.11         \n[106] corpcor_1.6.10       gtable_0.3.4         R.methodsS3_1.8.2   \n[109] digest_0.6.33        wordcloud_2.6        htmlwidgets_1.6.2   \n[112] htmltools_0.5.7      R.oo_1.25.0          lifecycle_1.0.4     \n[115] mitml_0.4-5          MASS_7.3-60"
  },
  {
    "objectID": "网络比较.html#quarto",
    "href": "网络比较.html#quarto",
    "title": "网络比较",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "网络比较.html#running-code",
    "href": "网络比较.html#running-code",
    "title": "网络比较",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "有调节的网络.html",
    "href": "有调节的网络.html",
    "title": "有调节的网络",
    "section": "",
    "text": "1 有调节的网络简介\n\n网络模型是分析多变量数据中依赖关系的强大工具，尤其在精神病学、心理学研究中越来越受欢迎。\n传统的网络模型，如高斯图形模型（GGM），假设变量对之间的相互作用是独立的，但这在心理学、症状科学研究中往往不现实。\n有学者提出了一种新的网络模型——有调节的网络模型（Moderated Network Models，MNMs），它通过引入调节变量来扩展传统的成对网络模型，提出了一种基于L1正则化的节点级回归方法来估计这种模型。\n模拟研究发现，MNM在检测调节效应方面优于基于分割样本的方法，如网络比较（NCT）和融合图形lasso（FGL）。\n\n调节效应（Moderation Effect）大家应该不陌生，其是统计学和社会科学研究中的一个重要概念，描述了一个变量（称为调节变量或调节因子）如何影响另外两个变量之间关系的方向（正向或负向）和强度（强或弱）的现象。换句话说，调节效应是指一个变量的存在改变了另外两个变量之间关系的模式。\n将调节效应扩展到网络模型，构建有调节的网络模型，可以为我们提供更深入、更细致的洞察，更好地理解变量间复杂的相互关系，具备一些作用和优势，比如：构建更真实的模型；发现潜在的调节变量；发现和确认哪些变量可能作为重要的调节变量，影响其他变量间的关系；提高预测准确性；个性化干预：解决研究间的不一致性；提高模型的解释力；探索变量的非线性关系。\n理论层面的内容不是短短的篇幅可以解释清楚的，大家不妨去读一读一篇名为《Moderated Network Models》的论文，很经典，论文里面有对有调节的网络模型的详细介绍，甚至还提供了完全可以复现的代码，以及对代码和结果的解释。\n\n\n\n\n\n\n\n2 如何构建有调节的网络\n为了避免版本兼容性问题，大家可以先跳转到文末看看我使用的R语言环境。\n\n2.1 mgm包\n本次我们会使用到一个叫做mgm的R包，前面计算可预测性值的时候是有用过的，这次我们同样会用它来构建一个有调节的网络模型。\n按照惯例，我们先导入包和数据，如果你还没有安装，请先安装。\n\n\n2.2 演示用的数据\n本次将采用一个叫做msq_p5的数据集来进行演示，此数据集内置于mgm包，包含5个变量、3896行，变量的大概含义：\n\nhostile - 主持敌意或敌对情绪的倾向。\nlonely - 感到孤独或被排斥的情绪。\nnervous - 感到紧张或不安的情绪。\nsleepy - 感到困倦或疲倦的情绪。\ndepressed - 感到沮丧或情绪低落的倾向。\n\n具体的含义和更多的细节请查询mgm包的帮助文档，数据具体如何并不重要，在此仅演示用法。\n\ndata(msq_p5) \ndim(msq_p5)\n\n[1] 3896    5\n\nstr(msq_p5)\n\n'data.frame':   3896 obs. of  5 variables:\n $ hostile  : num  -0.488 -0.488 -0.488 -0.488 -0.488 ...\n $ lonely   : num  0.728 -0.644 -0.644 0.728 -0.644 ...\n $ nervous  : num  1.002 -0.545 -0.545 2.548 -0.545 ...\n $ sleepy   : num  -0.233 -0.233 -1.186 -0.233 -0.233 ...\n $ depressed: num  -0.6 -0.6 -0.6 0.867 -0.6 ...\n\nhead(msq_p5)\n\n     hostile     lonely    nervous     sleepy  depressed\n1 -0.4879522  0.7280507  1.0018084 -0.2334325 -0.5998642\n2 -0.4879522 -0.6442210 -0.5445646 -0.2334325 -0.5998642\n3 -0.4879522 -0.6442210 -0.5445646 -1.1857391 -0.5998642\n4 -0.4879522  0.7280507  2.5481814 -0.2334325  0.8672236\n5 -0.4879522 -0.6442210 -0.5445646 -0.2334325 -0.5998642\n6 -0.4879522 -0.6442210 -0.5445646  0.7188742  0.8672236\n\n\n\n\n2.3 建模\n上一节没有详细说明mgm包和mgm函数，是准备在这里面进行介绍。\nmgm包的作用是Estimating Time-Varying k-order Mixed Graphical Models，也就是估计时变k阶混合图模型。更具体的，它通过弹性网正则化邻域回归估计时变混合图模型和混合VAR模型。其中的mgm函数就是用于建模的主函数，主要有下面几个参数（本期次用到的）：\n\ndata接收矩阵输入；\ntype指定变量类型（因为mgm是为混合图模型设计的，所以很可能会遇到混合类型的数据）；\nlevel指定变量的水平（如果是连续变量，水平默认=1）；\nambdaSel指定选择Lq正则化的调优方法：要么CV交叉验证，要么EBIC（Extended Bayesian Information Criterion）。\nruleReg用于指定组合来自邻域回归的估计值的规则，对于成对交互作用，两个估计值(一个来自A对B的回归，一个来自B对A的回归)必须在单个边缘参数中组合。ruleReg=“AND”要求所有估计值都不为零，以便将边缘设置为存在。ruleReg=“OR”要求至少有一个估计值不为零，以便将边缘设置为出现。\nmoderators接收一个整数向量，指定纳入模型的调节变量，这里我们不清楚哪个是潜在的调节变量，不妨探索性设置为每个节点。\nscale=T是默认的，用于标准化连续变量，做调节效应是得做这么一件事。\n\n\nmgm_mod = mgm(data = as.matrix(msq_p5), \n               type = rep(\"g\", 5), #指定变量类型，均为连续变量g\n               level = rep(1, 5),  #连续变量的水平默认=1\n               lambdaSel = \"EBIC\", #采用EBIC估计\n               lambdaGam = .5,  #lasso惩罚系数，也可换用'CV'\n               ruleReg = \"AND\", \n               moderators = 1:5,#因调节变量未知，探索性设置\n               scale = TRUE #标准化,均值为0、标准差为1 \n               )\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\nNote that the sign of parameter estimates is stored separately; see ?mgm\n\n\n\n\n2.4 估计效应值\n接下来，显示显著的效应项：\n\nmgm_mod$interactions$indicator\n\n[[1]]\n      [,1] [,2]\n [1,]    1    3\n [2,]    1    4\n [3,]    1    5\n [4,]    2    3\n [5,]    2    4\n [6,]    2    5\n [7,]    3    4\n [8,]    3    5\n [9,]    4    5\n\n[[2]]\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    1    2    4\n[3,]    1    3    4\n[4,]    3    4    5\n\n\n查看成对交互（边）：\n\nshowInteraction(object = mgm_mod, int = c(2,5))\n\nInteraction: 2-5 \nWeight:  0.4318148 \nSign:  1  (Positive)\n\n\n边2-5的权重是0.4318148，它的含义与我们在横断面网络中计算得到的边缘权重类似。还可以查看三向交互（3-way interaction，即调节效应）：\n\nshowInteraction(object = mgm_mod, int = c(3,4,5))\n\nInteraction: 3-4-5 \nWeight:  0.0564465 \nSign:  1  (Positive)\n\n\n节点3-4-5之间的权重是0.0564465，这个不好解释，可以再分开查询下3-5,4-5的效应。\n\nshowInteraction(object = mgm_mod, int = c(4,5))\n\nInteraction: 4-5 \nWeight:  0.1534387 \nSign:  1  (Positive)\n\n\n\nshowInteraction(object = mgm_mod, int = c(3,5))\n\nInteraction: 3-5 \nWeight:  0.1029161 \nSign:  1  (Positive)\n\n\n根据这两个成对效应指标，我们可以这样解释3-4-5之间的调节效应：\n当nervous（节点3） 为0时，sleepy （节点4）与depressed（节点5）的成对交互作用为0.153；当紧张增加1个单位时，成对交互作用增加约0.06（ 0.0564465 ）；当sleepy为0时，抑郁与紧张之间的成对交互作用约为0.103，当sleepy增加1个单位时，nervous和depressed的成对交互作用增加约0.06。\n\n\n2.5 可视化\nmgm提供了可视化有调节网络的函数：\n\n# 显示全部效应\nFactorGraph(object = mgm_mod,\n            edge.labels = TRUE,\n            labels = colnames(msq_p5))\n\n\n\n\n如果不想显示成对交互作用，也可以仅显示三向交互：\n\nFactorGraph(object = mgm_mod,\n            labels = colnames(msq_p5),\n            PairwiseAsEdge = TRUE,\n            edge.labels = FALSE)\n\n\n\n\n我们也可以用常规思路估计和可视化网络，思路是先提取矩阵(比如这里是mgm_mod\\(pairwise\\)wadj)，然后再传入qgraph函数。\n\nmgm_mod$pairwise$wadj\n\n           [,1]      [,2]       [,3]       [,4]      [,5]\n[1,] 0.00000000 0.0000000 0.11412907 0.06689801 0.2365030\n[2,] 0.00000000 0.0000000 0.11784001 0.07001690 0.4318148\n[3,] 0.11412907 0.1178400 0.00000000 0.05279325 0.1029161\n[4,] 0.06689801 0.0700169 0.05279325 0.00000000 0.1534387\n[5,] 0.23650303 0.4318148 0.10291606 0.15343868 0.0000000\n\n\n\nq = qgraph(mgm_mod$pairwise$wadj,#相关矩阵\n           layout = \"spring\",#图形布局算法\n           details = TRUE, #显示细节\n           theme='colorblind'#主题\n           ) \n\n\n\n\n如果调节变量是分类的，可以分别估计不同调节水平下的网络：思路是先分离，然后再估计网络。本例没有分类变量，所以就不演示了。\n还可以利用mgm自带的函数进行稳定性检验（edge），先抽样：\n\nres_obj = resample(object = mgm_mod, \n                    data = as.matrix(msq_p5),\n                    nB = 50,\n                   pbar=F) #为了方便，仅抽样少数次\n\n然后可以借助plotRes绘图：\n\nsuppressWarnings(\n  plotRes(object = res_obj, \n        labels = NULL, \n        axis.ticks = c(-.25, 0, .25, .5, .75))\n        )\n\n\n\n\n\n本次出现了”长的对象长度不是短的对象长度的整倍数”的警告信息，暂不知如何解决，欢迎指导或者纠正。get到解决方案后，我会对这块内容进行修订、补充。\n\n\n\n运行环境\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] qgraph_1.9.8 mgm_1.2-14  \n\nloaded via a namespace (and not attached):\n [1] shape_1.4.6       gtable_0.3.4      xfun_0.41         ggplot2_3.5.0    \n [5] htmlwidgets_1.6.2 psych_2.3.9       lattice_0.21-9    quadprog_1.5-8   \n [9] vctrs_0.6.4       tools_4.3.2       generics_0.1.3    stats4_4.3.2     \n[13] parallel_4.3.2    tibble_3.2.1      fansi_1.0.5       cluster_2.1.4    \n[17] pkgconfig_2.0.3   Matrix_1.6-5      data.table_1.15.4 checkmate_2.3.0  \n[21] lifecycle_1.0.4   compiler_4.3.2    stringr_1.5.1     munsell_0.5.0    \n[25] mnormt_2.1.1      codetools_0.2-19  htmltools_0.5.7   glasso_1.11      \n[29] glmnet_4.1-8      fdrtool_1.2.17    yaml_2.3.7        htmlTable_2.4.2  \n[33] Formula_1.2-5     pillar_1.9.0      iterators_1.0.14  Hmisc_5.1-1      \n[37] foreach_1.5.2     rpart_4.1.21      abind_1.4-5       nlme_3.1-163     \n[41] lavaan_0.6-17     gtools_3.9.5      tidyselect_1.2.0  digest_0.6.33    \n[45] stringi_1.8.1     dplyr_1.1.4       reshape2_1.4.4    splines_4.3.2    \n[49] fastmap_1.1.1     grid_4.3.2        colorspace_2.1-0  cli_3.6.2        \n[53] magrittr_2.0.3    base64enc_0.1-3   survival_3.5-7    utf8_1.2.4       \n[57] pbivnorm_0.6.0    foreign_0.8-85    corpcor_1.6.10    scales_1.3.0     \n[61] backports_1.4.1   rmarkdown_2.25    jpeg_0.1-10       igraph_2.0.1.1   \n[65] nnet_7.3-19       gridExtra_2.3     png_0.1-8         pbapply_1.7-2    \n[69] evaluate_0.23     knitr_1.45        rlang_1.1.3       Rcpp_1.0.11      \n[73] glue_1.6.2        rstudioapi_0.16.0 jsonlite_1.8.7    R6_2.5.1         \n[77] plyr_1.8.9"
  },
  {
    "objectID": "有调节的网络.html#quarto",
    "href": "有调节的网络.html#quarto",
    "title": "有调节的网络",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "有调节的网络.html#running-code",
    "href": "有调节的网络.html#running-code",
    "title": "有调节的网络",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "二分类变量的网络分析.html",
    "href": "二分类变量的网络分析.html",
    "title": "二分类变量的网络分析",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "二分类变量的网络分析.html#quarto",
    "href": "二分类变量的网络分析.html#quarto",
    "title": "二分类变量的网络分析",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "二分类变量的网络分析.html#running-code",
    "href": "二分类变量的网络分析.html#running-code",
    "title": "二分类变量的网络分析",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "交叉滞后网络.html",
    "href": "交叉滞后网络.html",
    "title": "交叉滞后网络",
    "section": "",
    "text": "网络分析是一种强大的手段，我们前面学习过的一些方法是基于横断面数据的，当数据类型从横断面数据扩展到纵向数据的时候，普通的网络分析方法就不再适用了。纵向数据可以理解为重复测量所得数据，分为面板数据、时间序列数据（N=1,N&gt;1）等多种类型。前者测量次数往往不会特别多（但样本数量大），后者则会比较多（样本数量可能小）。在此背景下，交叉滞后网络分析应运而生。\n交叉滞后网络分析（Cross-Lagged Network Analysis，简称 CLNA）是结合交叉滞后面板模型（Cross-Lagged Panel Model, CLPM）与网络分析的一种方法，用于研究多变量时间序列数据中变量之间的动态关系和相互影响。它能够揭示多个变量在不同时点上的因果关系以及它们在时间上的相互依赖性。\n说起来很复杂，但其实很简单，学习交叉滞后网络分析之前，我们先复习下 CLPM。"
  },
  {
    "objectID": "交叉滞后网络.html#quarto",
    "href": "交叉滞后网络.html#quarto",
    "title": "交叉滞后网络",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "交叉滞后网络.html#running-code",
    "href": "交叉滞后网络.html#running-code",
    "title": "交叉滞后网络",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "时间序列网络.html",
    "href": "时间序列网络.html",
    "title": "时间序列网络分析",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "时间序列网络.html#quarto",
    "href": "时间序列网络.html#quarto",
    "title": "时间序列网络分析",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "时间序列网络.html#running-code",
    "href": "时间序列网络.html#running-code",
    "title": "时间序列网络分析",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "混合变量的网络分析.html",
    "href": "混合变量的网络分析.html",
    "title": "混合变量的网络分析",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "混合变量的网络分析.html#quarto",
    "href": "混合变量的网络分析.html#quarto",
    "title": "混合变量的网络分析",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "混合变量的网络分析.html#running-code",
    "href": "混合变量的网络分析.html#running-code",
    "title": "混合变量的网络分析",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "时间网络分析.html",
    "href": "时间网络分析.html",
    "title": "时间网络分析",
    "section": "",
    "text": "首先，从测量次数角度，我们要注意区分几种数据类型：单一测量数据（每人一个测量）、面板数据（许多人测量了几次）、N = 1时间序列数据（一个人测量了多次）和N &gt; 1时间序列数据（几个人测量了多次）。\n\n\n\n时间网络分析（Temporal network analysis）是网络分析的最新进展之一，它将关系和时间维度结合到一个单一的分析框架中，即：时间网络，也称为时间序列网络、时变网络、动态网络或演化网络。\n时间网络分析是一种新颖而具有前景的方法，它比其他更常用的纵向建模技术[如交叉滞后面板模型(CLPM)，回归模型]具有优势。\n首先，时态网络分析中经常涉及到建立图形向量自回归(GVAR)模型，其允许估计考虑时间上个体内差异的有向网络，而CLPM没有分离个体内效应（within-person effects）和个体间效应（between-person effects），这可能导致变量之间因果关系的不正确结论。尽管后来发展起来的CLPM ——随机截距 CLPM可以将时间不变（time-invariant）、类似特质（trait-like）的个体间效应与个体内效应区分开来，但它需要更大的样本和更大的检验效能，特别是对于具有更多变量的更复杂的模型。\n{引用自WITH R NETWORK PSYCHOMETRICS=“” fig-align=“center”}\n其次，时间网络分析评估模型中每个变量的中心性，这可以识别网络中最重要的(或最有影响力的)节点。由于高度中心的节点影响网络中最多的变量，因此它们可能是干预的有用目标。\n\n\n\n时间网络分析还在发展之中，并不完善。对于N=1的时间序列网络分析，主要思想是通图形向量自回归模型（GVAR）进行处理；对于N&gt;1的时间序列，可能会更多地考虑多层VAR（mlVAR包实现了这种统计建模方法）。\n在VAR中，在连续的时间点之间使用线性回归来建模时间依赖关系，允许人们在控制了时间效应（同期效应）后，获得跨时间的关系（时间效应）和同一测量窗口中的关系的单独估计。VAR变体是这一部分的核心焦点是图形VAR（GVAR）模型，其中同时的效果被进一步建模为高斯图形模型。因此，GVAR模型返回两种网络结构：一个时间网络，这是一个时间关系的有向网络；一个同时网络，它是一个同时关系的无向网络。\n\n\n\n可以实现上述几种时间序列数据网络分析的R包有多种，目前来看并不统一，单是我在各类文献中看到的工具包就不少，比如，有用时间社会网络分析（tsna）的，有用多水平向量自回归(mlVAR包，Multi-Level Vector Autoregression)的，也有用时变向量自回归包（mgm包）以及psychonetrics包（面板GVAR模型）……\n虽然让人眼花缭乱，但底层逻辑是相似的，主要还是要看你的研究类型和目的。譬如，mlVAR会分离出以下三种网络：\n{引用自WITH R NETWORK PSYCHOMETRICS=“” fig-align=“center”}\n我在上述对应R包的名字上附上了具体文献或者代码仓库的超链接，你如果感兴趣的话，可以点进去看看这些文献对Temporal network analysis的具体实现方法。\n个人比较推荐使用mlVAR构建时间序列网络模型。\n\n\n\n\n\n为了避免版本兼容性问题，大家可以先跳转到文末看看我使用的R语言环境。\n先导入需要使用的程序包，没有安装的请先安装。\n本次我们用mlVAR包的mlVARsim函数模拟一份数据(实际是拟合也了一个时间网络模型)，为了减轻电脑的计算负担，设置受试者人数为50，节点数为8个，测量次数是30，阶数lag为1，其它都是默认设置。\n\nModel = mlVARsim(nPerson = 50,nNode = 8, nTime = 30, lag=1)\n\n查看数据：\n\nhead(Model$Data)\n\n         V1       V2        V3        V4        V5         V6         V7\n1 2.0335217 3.157925 -3.876432 -4.733132 -2.543258 -0.6276040  1.4945052\n2 2.2822126 3.732587 -4.179065 -1.685546 -2.404072  1.7619746 -0.1781815\n3 1.5409651 2.615361 -2.934132 -3.383525 -1.873246  2.5694409 -3.4722245\n4 0.6782198 3.847820 -1.470588 -5.984845 -2.705544  1.5355441 -0.9820712\n5 3.8371249 3.970785 -1.777491 -2.959565 -3.943941  0.5437959 -1.6252762\n6 3.0328899 1.786133 -1.560092 -1.860449 -2.511397  2.1500955  1.1310869\n         V8 ID\n1 -8.729056  1\n2 -7.772314  1\n3 -6.317016  1\n4 -6.868845  1\n5 -6.163121  1\n6 -5.477314  1\n\n\n查看节点名：\n\nModel$vars\n\n[1] \"V1\" \"V2\" \"V3\" \"V4\" \"V5\" \"V6\" \"V7\" \"V8\"\n\n\n查看受试者变量：\n\nModel$idvar\n\n[1] \"ID\"\n\n\n绘图：\n\nplot(Model)\n\n\n\n\n\n\n\n好戏开始：用mlVAR函数拟合时间网络模型！\n这里面的data、vars、idvar是必须写的，分别表示数据、要分析的变量名、代表受试者的变量。lags可以选用默认参数，estimator是估计器，具体的选项可以查看帮助文档，这里选择lmer；contemporaneous（同期网络）、temporal（时序网络）估计方法都采用”correlated”；nCores指定使用的cpu核心数，计算量不小，可以适当大一些。\n\nfit1 = mlVAR(data = Model$Data, \n            vars = Model$vars, \n            idvar = Model$idvar, \n            lags = 1, \n            estimator = \"lmer\",\n            temporal = \"correlated\",\n            contemporaneous = \"correlated\",\n            nCores = 8,\n            verbose =F\n )\n\n总结模型：\n\nsummary(fit1)\n\n\nmlVAR estimation completed. Input was:\n    - Variables: V1 V2 V3 V4 V5 V6 V7 V8 \n    - Lags: 1 \n    - Estimator: lmer \n    - Temporal: correlated\n\nInformation indices:\n var      aic      bic\n  V1 3199.817 3527.135\n  V2 2934.493 3261.810\n  V3 3112.823 3440.141\n  V4 2840.875 3168.193\n  V5 2705.464 3032.781\n  V6 2985.371 3312.689\n  V7 3090.526 3417.844\n  V8 2959.122 3286.440\n\n\nTemporal effects:\n from to lag  fixed    SE     P ran_SD\n   V1 V1   1  0.116 0.029 0.000  0.078\n   V1 V2   1  0.175 0.027 0.000  0.090\n   V1 V3   1 -0.515 0.041 0.000  0.216\n   V1 V4   1 -0.441 0.030 0.000  0.120\n   V1 V5   1  0.005 0.033 0.890  0.162\n   V1 V6   1  0.362 0.028 0.000  0.083\n   V1 V7   1  0.269 0.030 0.000  0.102\n   V1 V8   1  0.035 0.041 0.394  0.229\n   V2 V1   1  0.032 0.042 0.449  0.242\n   V2 V2   1  0.132 0.036 0.000  0.199\n   V2 V3   1  0.309 0.032 0.000  0.154\n   V2 V4   1  0.140 0.031 0.000  0.154\n   V2 V5   1  0.037 0.032 0.250  0.174\n   V2 V6   1 -0.384 0.039 0.000  0.229\n   V2 V7   1 -0.285 0.036 0.000  0.196\n   V2 V8   1  0.048 0.034 0.154  0.182\n   V3 V1   1  0.027 0.030 0.372  0.102\n   V3 V2   1  0.004 0.027 0.886  0.084\n   V3 V3   1  0.117 0.032 0.000  0.134\n   V3 V4   1  0.167 0.035 0.000  0.178\n   V3 V5   1 -0.265 0.025 0.000  0.082\n   V3 V6   1 -0.023 0.029 0.425  0.105\n   V3 V7   1 -0.038 0.027 0.159  0.064\n   V3 V8   1  0.332 0.029 0.000  0.109\n   V4 V1   1  0.050 0.036 0.168  0.180\n   V4 V2   1 -0.181 0.036 0.000  0.198\n   V4 V3   1 -0.022 0.039 0.573  0.208\n   V4 V4   1  0.255 0.039 0.000  0.224\n   V4 V5   1  0.184 0.038 0.000  0.219\n   V4 V6   1  0.161 0.038 0.000  0.208\n   V4 V7   1 -0.239 0.043 0.000  0.248\n   V4 V8   1  0.138 0.038 0.000  0.208\n   V5 V1   1 -0.022 0.029 0.448  0.106\n   V5 V2   1  0.392 0.026 0.000  0.077\n   V5 V3   1 -0.131 0.029 0.000  0.101\n   V5 V4   1 -0.024 0.026 0.351  0.088\n   V5 V5   1  0.055 0.028 0.049  0.122\n   V5 V6   1  0.027 0.030 0.369  0.129\n   V5 V7   1  0.043 0.031 0.162  0.134\n   V5 V8   1 -0.041 0.025 0.092  0.053\n   V6 V1   1 -0.023 0.033 0.492  0.141\n   V6 V2   1 -0.039 0.046 0.394  0.271\n   V6 V3   1  0.098 0.038 0.009  0.187\n   V6 V4   1 -0.066 0.034 0.055  0.170\n   V6 V5   1  0.167 0.040 0.000  0.227\n   V6 V6   1  0.009 0.040 0.820  0.212\n   V6 V7   1 -0.105 0.039 0.007  0.201\n   V6 V8   1 -0.018 0.039 0.639  0.211\n   V7 V1   1 -0.012 0.034 0.731  0.155\n   V7 V2   1 -0.016 0.027 0.554  0.092\n   V7 V3   1  0.019 0.035 0.582  0.168\n   V7 V4   1  0.251 0.029 0.000  0.119\n   V7 V5   1  0.183 0.026 0.000  0.097\n   V7 V6   1 -0.042 0.027 0.126  0.094\n   V7 V7   1  0.031 0.027 0.253  0.071\n   V7 V8   1  0.253 0.026 0.000  0.071\n   V8 V1   1 -0.072 0.042 0.087  0.226\n   V8 V2   1 -0.432 0.037 0.000  0.192\n   V8 V3   1  0.138 0.042 0.001  0.232\n   V8 V4   1 -0.027 0.040 0.493  0.219\n   V8 V5   1  0.219 0.038 0.000  0.216\n   V8 V6   1 -0.033 0.039 0.393  0.211\n   V8 V7   1  0.202 0.038 0.000  0.197\n   V8 V8   1  0.137 0.040 0.001  0.220\n\n\nContemporaneous effects (posthoc estimated):\n v1 v2 P 1-&gt;2 P 1&lt;-2   pcor ran_SD_pcor    cor ran_SD_cor\n V2 V1  0.000  0.000 -0.255       0.218 -0.237      0.243\n V3 V1  0.761  0.999 -0.006       0.171 -0.031      0.186\n V3 V2  0.351  0.302  0.042       0.184 -0.116      0.185\n V4 V1  0.000  0.000  0.224       0.169  0.263      0.232\n V4 V2  0.771  0.861  0.009       0.172 -0.039      0.218\n V4 V3  0.451  0.683 -0.022       0.141 -0.063      0.204\n V5 V1  0.013  0.002 -0.124       0.209 -0.060      0.236\n V5 V2  0.000  0.000  0.194       0.203  0.275      0.217\n V5 V3  0.000  0.000 -0.264       0.189 -0.335      0.219\n V5 V4  0.000  0.000  0.182       0.239  0.193      0.286\n V6 V1  0.000  0.000  0.177       0.084  0.060      0.172\n V6 V2  0.000  0.000  0.287       0.215  0.306      0.212\n V6 V3  0.000  0.000 -0.270       0.140 -0.321      0.146\n V6 V4  0.000  0.001 -0.147       0.165 -0.108      0.234\n V6 V5  0.038  0.005  0.089       0.131  0.214      0.188\n V7 V1  0.104  0.161  0.063       0.173  0.204      0.165\n V7 V2  0.610  0.653  0.020       0.171 -0.017      0.239\n V7 V3  0.738  0.273 -0.026       0.137 -0.059      0.206\n V7 V4  0.000  0.000  0.310       0.169  0.404      0.200\n V7 V5  0.847  0.588 -0.006       0.156  0.131      0.267\n V7 V6  0.008  0.013 -0.090       0.117 -0.078      0.157\n V8 V1  0.000  0.000  0.166       0.146  0.220      0.171\n V8 V2  0.406  0.858  0.023       0.189  0.047      0.284\n V8 V3  0.954  0.405 -0.015       0.142 -0.124      0.216\n V8 V4  0.586  0.979  0.010       0.123  0.230      0.206\n V8 V5  0.000  0.000  0.202       0.125  0.260      0.207\n V8 V6  0.311  0.312  0.039       0.153  0.075      0.227\n V8 V7  0.000  0.000  0.344       0.149  0.414      0.163\n\n\nBetween-subject effects:\n v1 v2 P 1-&gt;2 P 1&lt;-2   pcor    cor\n V2 V1  0.282  0.811  0.080  0.155\n V3 V1  0.038  0.067  0.240  0.251\n V3 V2  0.958  0.467 -0.042  0.047\n V4 V1  0.122  0.295  0.164  0.126\n V4 V2  0.707  0.322  0.091  0.172\n V4 V3  0.418  0.238 -0.131 -0.117\n V5 V1  0.264  0.142 -0.161 -0.047\n V5 V2  0.085  0.001  0.306  0.185\n V5 V3  0.276  0.252  0.142  0.155\n V5 V4  0.121  0.187 -0.187 -0.345\n V6 V1  0.003  0.001  0.370  0.317\n V6 V2  0.128  0.713  0.122  0.057\n V6 V3  0.312  0.756  0.044  0.161\n V6 V4  0.311  0.704 -0.091 -0.244\n V6 V5  0.240  0.120  0.172  0.304\n V7 V1  0.132  0.183 -0.179 -0.121\n V7 V2  0.396  0.486  0.100  0.083\n V7 V3  0.334  0.764  0.081 -0.038\n V7 V4  0.036  0.036  0.261  0.349\n V7 V5  0.177  0.072 -0.198 -0.280\n V7 V6  0.290  0.685 -0.039 -0.215\n V8 V1  0.312  0.134  0.148  0.139\n V8 V2  0.001  0.001  0.378  0.362\n V8 V3  0.326  0.624  0.090  0.027\n V8 V4  0.121  0.029  0.225  0.407\n V8 V5  0.127  0.399 -0.146 -0.239\n V8 V6  0.000  0.017 -0.340 -0.344\n V8 V7  0.902  0.974 -0.006  0.188\n\n\n上面给出了大量的信息。值得注意的是，mlVAR包会输出3种效应：Temporal effects、Contemporaneous effects、Between-subject effects，分别对应时序网络、同期网络和个体间网络。\n\nTemporal effects（时间效应）：这是指变量在时间上对自身或其它变量的影响，这些效应通常是通过滞后回归权重来估计的，可以捕捉变量随时间的动态关系 。时序网络中的边是指变量在上个时间点t-1对下个时间点t的各节点的预测能力（控制了上个时间点t-1上的其他变量之后）。\nContemporaneous effects（同期效应）：这是指在相同时间点上变量之间的关系，可以是简单的相关关系或偏相关关系。这些关系通常是通过模型残差的相互关系来估计的，可以揭示在同一时间点上变量之间的直接联系 。\nBetween-subject effects（个体间效应）：这是指在不同个体之间（平均水平层面的）变量关系的差异，可以是相关关系或偏相关关系。这些效应反映了不同个体在变量关系上的差异，有助于理解不同个体在心理过程上的差异 。\n\n\n\n\n我们可以分别绘制这些网络图：\n\n# 同期网络\ncontemporaneous = plot(fit1, type = \"temporal\", title = \"Estimated temporal relationships\", \n     rule = \"and\",layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n# 时序网络\ntemporal=plot(fit1, type = \"contemporaneous\", rule = \"and\",\n     title = \"Estimated contemporaneous relationships\", layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n# 受试者间网络  必须取名between，否则报错\nbetween = plot(fit1, type = \"between\", rule = \"or\",\n     title = \"Estimated between relationships\", layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n\n\n可以跟横断面网络一样，计算或者开展后续一些常用的指标和检验，比如中心性，桥梁症状。\n\n# 计算中心性\ncentrality(contemporaneous)  \n\n$OutDegree\n       V1        V2        V3        V4        V5        V6        V7        V8 \n1.7626296 1.1175046 0.7645637 0.9034969 0.5231023 0.3698123 0.6865014 0.9912068 \n\n$InDegree\n       V1        V2        V3        V4        V5        V6        V7        V8 \n0.0000000 1.1805817 1.1909310 0.9991603 1.0172301 0.9069345 1.1013387 0.7226413 \n\n$Closeness\n        V1         V2         V3         V4         V5         V6         V7 \n0.03696362 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 \n        V8 \n0.00000000 \n\n$Betweenness\nV1 V2 V3 V4 V5 V6 V7 V8 \n 0 11  6  0  1  0  2  6 \n\n$InExpectedInfluence\n         V1          V2          V3          V4          V5          V6 \n 0.00000000 -0.04617963 -0.10094765  0.11654432  0.48700373  0.13880776 \n         V7          V8 \n-0.15752989  0.72264128 \n\n$OutExpectedInfluence\n         V1          V2          V3          V4          V5          V6 \n-0.14918637 -0.22089092  0.23433731  0.06198312  0.26042372  0.16018255 \n         V7          V8 \n 0.68650135  0.12698916 \n\n$ShortestPathLengths\n    V1       V2        V3        V4       V5       V6       V7        V8\nV1   0 5.700019  1.943257  2.265991 5.715231 2.763749 3.711177  4.954201\nV2 Inf 0.000000  3.238940  7.165181 7.010914 2.603737 3.507118  6.249884\nV3 Inf 5.325176  0.000000  5.976258 3.771974 7.928913 7.950482  3.010944\nV4 Inf 5.516577  8.755517  0.000000 5.430191 6.209490 4.175626  7.270580\nV5 Inf 2.552564  5.791503  9.717744 0.000000 5.156301 6.059682  8.802448\nV6 Inf 8.558272 10.153397 13.525333 6.005709 0.000000 9.540629 13.164342\nV7 Inf 6.267130  9.506069  3.984703 5.477571 8.870867 0.000000  3.952898\nV8 Inf 2.314232  5.553172  8.924241 4.568496 4.917969 4.939537  0.000000\n\n$ShortestPaths\n   V1   V2   V3   V4   V5   V6   V7   V8  \nV1 NULL NULL NULL NULL NULL NULL NULL NULL\nV2 NULL NULL NULL NULL NULL NULL NULL NULL\nV3 NULL NULL NULL NULL NULL NULL NULL NULL\nV4 NULL NULL NULL NULL NULL NULL NULL NULL\nV5 NULL NULL NULL NULL NULL NULL NULL NULL\nV6 NULL NULL NULL NULL NULL NULL NULL NULL\nV7 NULL NULL NULL NULL NULL NULL NULL NULL\nV8 NULL NULL NULL NULL NULL NULL NULL NULL\n\n\n可以将其绘制出来，下面的代码依次绘制同期网络、时序网络和个体间网络。\n\ncentralityPlot(contemporaneous) \n\n\n\n\n\ncentralityPlot(temporal)\n\n\n\n\n\ncentralityPlot(between)\n\n\n\n\n完全可以对绘图函数的参数做些个性化调整，这里不多展示了。\n\n\n\n先人为对模拟数据的节点进行分组：\n\ngroups=c(rep('A',4),rep('B',2),rep('C',2))\n\n计算桥梁中心性指标：\n\nb = bridge(contemporaneous, communities= groups, directed=F)\nb\n\n$`Bridge Strength`\n       V1        V2        V3        V4        V5        V6        V7        V8 \n0.6312836 0.6691977 0.5972349 0.7222251 0.5231023 0.2033041 0.4335224 0.7887587 \n\n$`Bridge Betweenness`\nV1 V2 V3 V4 V5 V6 V7 V8 \n 5  1  1  5  0  1  2  3 \n\n$`Bridge Closeness`\n        V1         V2         V3         V4         V5         V6         V7 \n0.14014223 0.10893181 0.12090457 0.13274157 0.08197854 0.13031448 0.11021654 \n        V8 \n0.12678535 \n\n$`Bridge Expected Influence (1-step)`\n          V1           V2           V3           V4           V5           V6 \n 0.631283628 -0.669197749  0.067008531  0.243254960  0.260423716 -0.006325689 \n          V7           V8 \n 0.433522386 -0.075458952 \n\n$`Bridge Expected Influence (2-step)`\n         V1          V2          V3          V4          V5          V6 \n 0.51172975 -0.76244179  0.24764776  0.32814244  0.25875117  0.03340721 \n         V7          V8 \n 0.50311573  0.02808020 \n\n$communities\n[1] \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"\n\n\n简单绘图：\n\nplot(b, include=c(\"Bridge Expected Influence (2-step)\", \"Bridge Strength\", \"Bridge Closeness\"),\n     theme_bw=F, raw0 = T, signed=T) \n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n\n\n\n\n\n\n\n时间网络分析目前还不完善，上述流程并没有覆盖到之前我们做横断面网络的所有评估指标和检验方法，比如稳定性、精确性、差异性检验，我还没有找到合适的R包可以很方便地对其进行分析（估计得自己写重抽样代码）。\n此外，时间网络分析不同于CLPM网络分析，其对数据有一些要求，比如说测量次数多、满足多元正态分布、具备平稳性……\n你如果有一份生态瞬时数据或者密集追踪数据，且想要进行时间网络分析，建议在建模前检查下数据，包括正态性（不服从也可以做）、平稳性（KPSS平稳性检验，文献提到可以用R包tseries实现，要一个个做，所以代码有些复杂），等等。\n\n\n{r}\nsessionInfo()}"
  },
  {
    "objectID": "时间网络分析.html#概述",
    "href": "时间网络分析.html#概述",
    "title": "时间网络分析",
    "section": "",
    "text": "时间网络分析（Temporal network analysis）是网络分析的最新进展之一，它将关系和时间维度结合到一个单一的分析框架中，即：时间网络，也称为时变网络，动态网络或演化网络。\n时间网络分析是一种新颖而具有前景的方法，它比其他更常用的纵向建模技术[如交叉滞后面板模型(CLPM)，回归模型]具有优势。\n首先，时态网络分析中建立的图形向量自回归(GVAR)模型，允许估计考虑时间上个体内差异的有向网络，而CLPM没有分离个体内效应（within-person effects）和个体间效应（between-person effects），这可能导致变量之间因果关系的不正确结论。尽管后来发展起来的CLPM ——随机截距 CLPM可以将时间不变（time-invariant）、类似特质（trait-like）的个体间效应与个体内效应区分开来，但它需要更大的样本和更大的检验效能，特别是对于具有更多变量的更复杂的模型。\n其次，时间网络分析评估模型中每个变量的中心性，这可以识别网络中最重要的(或最有影响力的)节点。由于高度中心的节点影响网络中最多的变量，因此它们可能是干预的有用目标。\n时间网络分析比较适用于密集追踪数据，比如通过经验抽样法（ESM，指系统地、多次地收集个体在自然环境中的行为和感受数据）获取到的纵向数据，有一种说法是至少要对研究对象重复测量30次（有的说要20次或者40次）以上，这点与我们用CLPM方法做网络分析的差别很大。\n当前的时间网络分析还在发展之中，并不完善，实现方法（R包）也有多种，并不统一，单是我在各类文献中看到的方法就不下于4种，比如，有用时间社会网络分析框架（tsna）的：\n\n\n\n\n\n有用多水平向量自回归(mlVAR包，Multi-Level Vector Autoregression)的，也有用时变向量自回归方法（mgm包）以及GVAR的……\n总之，我个人实在看得眼花缭乱，也可能是我归纳总结错了，欢迎批评指正。我在对应的R包名字上附上了具体文献或者代码仓库的超链接，你如果感兴趣的话，可以点进去看看这些文献对Temporal network analysis的具体实现方法。\n\n\n看了一圈各大文献提供的代码，发现还是mlVAR包的实现方法比较简单，这里就以此为例做个演示，由于此方法本身还在发展和完善中，我也说不准这种方法是否就一定正确，或许有用，所以仅供参考。\n\n\n为了避免版本兼容性问题，大家可以先跳转到文末看看我使用的R语言环境。\n先导入需要使用的程序包，没有安装的请先安装。\n本次我们用mlVAR包的mlVARsim函数模拟一份数据(实际是拟合也了一个时间网络模型)，为了减轻电脑的计算负担，设置受试者人数为50，节点数为8个，测量次数是30，阶数lag为1，其它都是默认设置。\n\nModel = mlVARsim(nPerson = 50,nNode = 8, nTime = 30, lag=1)\n\n查看数据：\n\nhead(Model$Data)\n\n          V1         V2         V3       V4         V5         V6         V7\n1 -0.9991818  3.6766639  1.1474059 1.933311 -0.7368582 -1.2886865 1.76027184\n2  1.0342757 -2.3986130 -3.5731137 2.641970 -0.3509886  0.4289348 0.81562608\n3 -1.3551105  3.1708768  1.1493416 2.839299 -1.2194231 -3.5680933 0.69106630\n4  0.1705346 -3.6859760 -3.8770882 3.472966  1.0205909  1.0825550 0.12687654\n5 -2.3601798  3.7852977  1.8176324 1.900470 -1.5412814 -1.6741243 0.02033113\n6 -1.4522704 -0.2434876 -0.2978927 1.086088 -1.7994729  2.2373258 2.33759810\n        V8 ID\n1 2.682670  1\n2 1.061330  1\n3 2.568200  1\n4 1.049123  1\n5 3.393253  1\n6 3.101151  1\n\n\n查看节点名：\n\nModel$vars\n\n[1] \"V1\" \"V2\" \"V3\" \"V4\" \"V5\" \"V6\" \"V7\" \"V8\"\n\n\n查看受试者变量：\n\nModel$idvar\n\n[1] \"ID\"\n\n\n绘图：\n\nplot(Model)\n\n\n\n\n\n\n\n好戏开始：用mlVAR函数拟合时间网络模型！\n这里面的data、vars、idvar是必须写的，分别表示数据、要分析的变量名、代表受试者的变量。lags可以选用默认参数，estimator是估计器，具体的选项可以查看帮助文档，这里选择lmer；contemporaneous（同期网络）、temporal（时序网络）估计方法都采用”correlated”；nCores指定使用的cpu核心数，计算量不小，可以适当大一些。\n\nfit1 = mlVAR(data = Model$Data, \n            vars = Model$vars, \n            idvar = Model$idvar, \n            lags = 1, \n            estimator = \"lmer\",\n            temporal = \"correlated\",\n            contemporaneous = \"correlated\",\n            nCores = 8\n )\n\nEstimating temporal and between-subjects effects\n\n\nEstimating contemporaneous effects\n\n\nComputing random effects\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%\n\n\n总结模型：\n\nsummary(fit1)\n\n\nmlVAR estimation completed. Input was:\n    - Variables: V1 V2 V3 V4 V5 V6 V7 V8 \n    - Lags: 1 \n    - Estimator: lmer \n    - Temporal: correlated\n\nInformation indices:\n var      aic      bic\n  V1 3318.351 3645.668\n  V2 3011.601 3338.919\n  V3 3247.570 3574.888\n  V4 3094.821 3422.139\n  V5 3225.564 3552.882\n  V6 2932.468 3259.786\n  V7 3249.037 3576.355\n  V8 3320.248 3647.566\n\n\nTemporal effects:\n from to lag  fixed    SE     P ran_SD\n   V1 V1   1  0.116 0.039 0.003  0.197\n   V1 V2   1  0.332 0.026 0.000  0.073\n   V1 V3   1 -0.025 0.036 0.493  0.175\n   V1 V4   1  0.189 0.027 0.000  0.082\n   V1 V5   1 -0.090 0.030 0.002  0.105\n   V1 V6   1 -0.440 0.033 0.000  0.160\n   V1 V7   1 -0.034 0.027 0.200  0.038\n   V1 V8   1  0.180 0.028 0.000  0.042\n   V2 V1   1  0.147 0.041 0.000  0.207\n   V2 V2   1  0.082 0.040 0.041  0.221\n   V2 V3   1 -0.210 0.035 0.000  0.160\n   V2 V4   1  0.244 0.030 0.000  0.119\n   V2 V5   1  0.151 0.046 0.001  0.261\n   V2 V6   1  0.184 0.033 0.000  0.158\n   V2 V7   1 -0.017 0.047 0.710  0.269\n   V2 V8   1 -0.019 0.035 0.599  0.157\n   V3 V1   1  0.033 0.033 0.316  0.142\n   V3 V2   1  0.187 0.028 0.000  0.108\n   V3 V3   1  0.059 0.029 0.045  0.092\n   V3 V4   1  0.064 0.029 0.029  0.112\n   V3 V5   1 -0.119 0.027 0.000  0.066\n   V3 V6   1  0.386 0.024 0.000  0.033\n   V3 V7   1  0.035 0.035 0.311  0.158\n   V3 V8   1  0.006 0.034 0.850  0.145\n   V4 V1   1 -0.300 0.038 0.000  0.169\n   V4 V2   1 -0.350 0.032 0.000  0.131\n   V4 V3   1 -0.277 0.040 0.000  0.193\n   V4 V4   1  0.034 0.033 0.292  0.132\n   V4 V5   1 -0.027 0.036 0.453  0.164\n   V4 V6   1 -0.038 0.034 0.255  0.154\n   V4 V7   1 -0.320 0.040 0.000  0.196\n   V4 V8   1 -0.057 0.041 0.164  0.202\n   V5 V1   1  0.033 0.037 0.364  0.151\n   V5 V2   1  0.244 0.032 0.000  0.123\n   V5 V3   1 -0.026 0.032 0.415  0.095\n   V5 V4   1  0.010 0.032 0.755  0.120\n   V5 V5   1  0.121 0.038 0.001  0.177\n   V5 V6   1  0.031 0.030 0.292  0.097\n   V5 V7   1  0.046 0.030 0.125  0.064\n   V5 V8   1  0.262 0.035 0.000  0.120\n   V6 V1   1 -0.032 0.041 0.439  0.232\n   V6 V2   1  0.234 0.034 0.000  0.184\n   V6 V3   1 -0.179 0.045 0.000  0.267\n   V6 V4   1 -0.223 0.037 0.000  0.210\n   V6 V5   1 -0.205 0.029 0.000  0.126\n   V6 V6   1  0.020 0.028 0.475  0.131\n   V6 V7   1  0.122 0.042 0.004  0.249\n   V6 V8   1  0.002 0.032 0.958  0.146\n   V7 V1   1  0.040 0.031 0.202  0.109\n   V7 V2   1  0.006 0.029 0.838  0.108\n   V7 V3   1  0.016 0.030 0.591  0.100\n   V7 V4   1 -0.293 0.032 0.000  0.136\n   V7 V5   1  0.059 0.035 0.094  0.167\n   V7 V6   1 -0.226 0.033 0.000  0.157\n   V7 V7   1  0.079 0.029 0.007  0.089\n   V7 V8   1 -0.317 0.029 0.000  0.072\n   V8 V1   1 -0.006 0.035 0.852  0.162\n   V8 V2   1  0.261 0.028 0.000  0.107\n   V8 V3   1  0.023 0.030 0.451  0.111\n   V8 V4   1 -0.042 0.032 0.185  0.149\n   V8 V5   1  0.222 0.033 0.000  0.152\n   V8 V6   1 -0.185 0.026 0.000  0.091\n   V8 V7   1  0.407 0.033 0.000  0.144\n   V8 V8   1  0.109 0.033 0.001  0.136\n\n\nContemporaneous effects (posthoc estimated):\n v1 v2 P 1-&gt;2 P 1&lt;-2   pcor ran_SD_pcor    cor ran_SD_cor\n V2 V1  0.000  0.000 -0.200       0.096 -0.223      0.175\n V3 V1  0.997  0.888 -0.003       0.193 -0.236      0.230\n V3 V2  0.000  0.000  0.230       0.151  0.328      0.182\n V4 V1  0.831  0.999 -0.005       0.208  0.143      0.200\n V4 V2  0.617  0.488  0.022       0.132 -0.202      0.174\n V4 V3  0.065  0.058 -0.071       0.142 -0.249      0.213\n V5 V1  0.000  0.000  0.259       0.216  0.369      0.207\n V5 V2  0.047  0.110 -0.069       0.150 -0.253      0.164\n V5 V3  0.000  0.000 -0.202       0.155 -0.367      0.186\n V5 V4  0.000  0.000  0.293       0.125  0.395      0.200\n V6 V1  0.018  0.006  0.105       0.177  0.113      0.212\n V6 V2  0.722  0.758  0.014       0.180 -0.063      0.232\n V6 V3  0.000  0.000 -0.249       0.148 -0.233      0.159\n V6 V4  0.956  0.834 -0.005       0.144  0.014      0.187\n V6 V5  0.977  0.943  0.001       0.154  0.077      0.181\n V7 V1  0.000  0.000  0.230       0.139  0.103      0.180\n V7 V2  0.000  0.000  0.412       0.126  0.406      0.172\n V7 V3  0.177  0.222 -0.050       0.156  0.101      0.220\n V7 V4  0.000  0.000 -0.240       0.184 -0.286      0.203\n V7 V5  0.983  0.760  0.007       0.183 -0.102      0.239\n V7 V6  0.830  0.641  0.004       0.133  0.016      0.205\n V8 V1  0.000  0.000 -0.222       0.184 -0.301      0.210\n V8 V2  0.616  0.806 -0.014       0.136  0.169      0.206\n V8 V3  0.000  0.000  0.227       0.154  0.312      0.203\n V8 V4  0.000  0.000 -0.162       0.071 -0.288      0.170\n V8 V5  0.120  0.062 -0.064       0.136 -0.288      0.214\n V8 V6  0.000  0.000  0.199       0.145  0.097      0.185\n V8 V7  0.269  0.291  0.040       0.140  0.093      0.235\n\n\nBetween-subject effects:\n v1 v2 P 1-&gt;2 P 1&lt;-2   pcor    cor\n V2 V1  0.515  0.686 -0.015  0.310\n V3 V1  0.183  0.091 -0.193 -0.352\n V3 V2  0.196  0.908  0.076 -0.090\n V4 V1  0.050  0.136  0.212  0.314\n V4 V2  0.640  0.766  0.049  0.308\n V4 V3  0.398  0.539 -0.020 -0.050\n V5 V1  0.101  0.150 -0.194 -0.271\n V5 V2  0.026  0.019 -0.288 -0.377\n V5 V3  0.031  0.339 -0.198 -0.117\n V5 V4  0.131  0.025 -0.229 -0.330\n V6 V1  0.434  0.296  0.114  0.358\n V6 V2  0.511  0.517  0.083  0.185\n V6 V3  0.000  0.000 -0.503 -0.586\n V6 V4  0.759  0.887 -0.026  0.002\n V6 V5  0.768  0.968 -0.016 -0.017\n V7 V1  0.957  0.923  0.003  0.210\n V7 V2  0.054  0.003  0.310  0.445\n V7 V3  0.528  0.342 -0.101 -0.077\n V7 V4  0.001  0.001  0.386  0.464\n V7 V5  0.135  0.662  0.122 -0.143\n V7 V6  0.008  0.380 -0.213 -0.049\n V8 V1  0.003  0.166  0.267  0.453\n V8 V2  0.001  0.001  0.395  0.528\n V8 V3  0.895  0.251 -0.062 -0.316\n V8 V4  0.253  0.421 -0.120  0.141\n V8 V5  0.906  0.737  0.029 -0.169\n V8 V6  0.048  0.102  0.217  0.407\n V8 V7  0.447  0.204  0.126  0.287\n\n\n上面给出了大量的信息。值得注意的是，mlVAR包会输出3种效应：Temporal effects、Contemporaneous effects、Between-subject effects，分别对应时序网络、同期网络和个体间网络。\n\nTemporal effects（时间效应）：这是指变量在时间上对自身或其它变量的影响，这些效应通常是通过滞后回归权重来估计的，可以捕捉变量随时间的动态关系 。时序网络中的边是指变量在上个时间点t-1对下个时间点t的各节点的预测能力（控制了上个时间点t-1上的其他变量之后）。\nContemporaneous effects（同期效应）：这是指在相同时间点上变量之间的关系，可以是简单的相关关系或偏相关关系。这些关系通常是通过模型残差的相互关系来估计的，可以揭示在同一时间点上变量之间的直接联系 。\nBetween-subject effects（个体间效应）：这是指在不同个体之间（平均水平层面的）变量关系的差异，可以是相关关系或偏相关关系。这些效应反映了不同个体在变量关系上的差异，有助于理解不同个体在心理过程上的差异 。\n\n\n\n\n我们可以分别绘制这些网络图：\n\n# 同期网络\ncontemporaneous = plot(fit1, type = \"temporal\", title = \"Estimated temporal relationships\", \n     rule = \"and\",layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n# 时序网络\ntemporal=plot(fit1, type = \"contemporaneous\", rule = \"and\",\n     title = \"Estimated contemporaneous relationships\", layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n# 受试者间网络  必须取名between，否则报错\nbetween = plot(fit1, type = \"between\", rule = \"or\",\n     title = \"Estimated between relationships\", layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n\n\n可以跟横断面网络一样，计算或者开展后续一些常用的指标和检验，比如中心性，桥梁症状。\n\n# 计算中心性\ncentrality(contemporaneous)  \n\n$OutDegree\n       V1        V2        V3        V4        V5        V6        V7        V8 \n1.2310360 0.9352619 0.7562160 1.2468461 0.5061460 0.9630353 0.8354559 1.0755982 \n\n$InDegree\n       V1        V2        V3        V4        V5        V6        V7        V8 \n0.4463957 1.6081008 0.6663443 1.0120742 0.7868091 1.4220893 0.8491647 0.7586174 \n\n$Closeness\n        V1         V2         V3         V4         V5         V6         V7 \n0.02559268 0.02204294 0.01838540 0.02914117 0.01947031 0.02305854 0.02583793 \n        V8 \n0.02508483 \n\n$Betweenness\nV1 V2 V3 V4 V5 V6 V7 V8 \n 1  6  0 10  2  6  4  4 \n\n$InExpectedInfluence\n         V1          V2          V3          V4          V5          V6 \n-0.15270947  0.90738724 -0.66634427 -0.01955024 -0.04111442 -0.28137705 \n         V7          V8 \n 0.20998629  0.12554426 \n\n$OutExpectedInfluence\n        V1         V2         V3         V4         V5         V6         V7 \n 0.1703068  0.5155141  0.5177188 -1.2468461  0.5061460 -0.2506817 -0.8354559 \n        V8 \n 0.7051203 \n\n$ShortestPathLengths\n          V1       V2       V3       V4       V5       V6        V7        V8\nV1  0.000000 3.013903 7.778669 5.301742 7.157115 2.271092  8.003565  5.547590\nV2  6.809990 0.000000 4.764767 4.101207 6.636717 5.433680  7.230224 10.389417\nV3 10.409740 5.352331 0.000000 7.071428 7.474559 2.588536 10.200445 11.293942\nV4  3.338312 2.854233 3.605584 0.000000 9.490951 5.609404  3.129017  6.288210\nV5 10.902921 4.092931 8.857698 8.194138 0.000000 9.217816  6.275358  3.819384\nV6  7.821204 4.277679 5.582762 4.482892 4.886023 0.000000  7.611909  8.705407\nV7  6.754290 6.270211 7.021562 3.415978 7.660242 4.421308  0.000000  3.159193\nV8  9.210265 3.831146 8.595912 5.871953 4.501049 5.398433  2.455975  0.000000\n\n$ShortestPaths\n   V1   V2   V3   V4   V5   V6   V7   V8  \nV1 NULL NULL NULL NULL NULL NULL NULL NULL\nV2 NULL NULL NULL NULL NULL NULL NULL NULL\nV3 NULL NULL NULL NULL NULL NULL NULL NULL\nV4 NULL NULL NULL NULL NULL NULL NULL NULL\nV5 NULL NULL NULL NULL NULL NULL NULL NULL\nV6 NULL NULL NULL NULL NULL NULL NULL NULL\nV7 NULL NULL NULL NULL NULL NULL NULL NULL\nV8 NULL NULL NULL NULL NULL NULL NULL NULL\n\n\n可以将其绘制出来，下面的代码依次绘制同期网络、时序网络和个体间网络。\n\ncentralityPlot(contemporaneous) \n\n\n\n\n\ncentralityPlot(temporal)\n\n\n\n\n\ncentralityPlot(between)\n\n\n\n\n完全可以对绘图函数的参数做些个性化调整，这里不多展示了。\n\n\n\n先人为对模拟数据的节点进行分组：\n\ngroups=c(rep('A',4),rep('B',2),rep('C',2))\n\n计算桥梁中心性指标：\n\nb = bridge(contemporaneous, communities= groups, directed=F)\nb\n\n$`Bridge Strength`\n       V1        V2        V3        V4        V5        V6        V7        V8 \n0.7106230 0.3347142 0.5055674 0.3195892 0.5061460 0.7583699 0.5189194 0.6684279 \n\n$`Bridge Betweenness`\nV1 V2 V3 V4 V5 V6 V7 V8 \n 4  9  0  0  0  7  0  1 \n\n$`Bridge Closeness`\n        V1         V2         V3         V4         V5         V6         V7 \n0.10005173 0.11683895 0.08970762 0.08192253 0.09165914 0.12456028 0.06889218 \n        V8 \n0.10108382 \n\n$`Bridge Expected Influence (1-step)`\n         V1          V2          V3          V4          V5          V6 \n-0.35010611  0.33471423  0.26707023 -0.31958920  0.50614604 -0.04601629 \n         V7          V8 \n-0.51891935  0.29795000 \n\n$`Bridge Expected Influence (2-step)`\n         V1          V2          V3          V4          V5          V6 \n-0.20663225  0.17363848  0.24621148 -0.23260918  0.72526651  0.05131759 \n         V7          V8 \n-0.25740060  0.34461190 \n\n$communities\n[1] \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"\n\n\n简单绘图：\n\nplot(b, include=c(\"Bridge Expected Influence (2-step)\", \"Bridge Strength\", \"Bridge Closeness\"),\n     theme_bw=F, raw0 = T, signed=T) \n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n\n\n\n\n\n\n\n时间网络分析目前还不完善，上述流程并没有覆盖到之前我们做横断面网络的所有评估指标和检验方法，比如稳定性、精确性、差异性检验，我还没有找到合适的R包可以很方便地对其进行分析（估计得自己写重抽样代码）。\n此外，时间网络分析不同于CLPM网络分析，其对数据有一些要求，比如说测量次数多、满足多元正态分布、具备平稳性……\n你如果有一份生态瞬时数据或者密集追踪数据，且想要进行时间网络分析，建议在建模前检查下数据，包括正态性（不服从也可以做）、平稳性（KPSS平稳性检验，文献提到可以用R包tseries实现，要一个个做，所以代码有些复杂），等等。"
  },
  {
    "objectID": "时间网络分析.html#时间网络分析概述",
    "href": "时间网络分析.html#时间网络分析概述",
    "title": "时间网络分析",
    "section": "",
    "text": "首先，从测量次数角度，我们要注意区分几种数据类型：单一测量数据（每人一个测量）、面板数据（许多人测量了几次）、N = 1时间序列数据（一个人测量了多次）和N &gt; 1时间序列数据（几个人测量了多次）。\n\n\n\n时间网络分析（Temporal network analysis）是网络分析的最新进展之一，它将关系和时间维度结合到一个单一的分析框架中，即：时间网络，也称为时间序列网络、时变网络、动态网络或演化网络。\n时间网络分析是一种新颖而具有前景的方法，它比其他更常用的纵向建模技术[如交叉滞后面板模型(CLPM)，回归模型]具有优势。\n首先，时态网络分析中经常涉及到建立图形向量自回归(GVAR)模型，其允许估计考虑时间上个体内差异的有向网络，而CLPM没有分离个体内效应（within-person effects）和个体间效应（between-person effects），这可能导致变量之间因果关系的不正确结论。尽管后来发展起来的CLPM ——随机截距 CLPM可以将时间不变（time-invariant）、类似特质（trait-like）的个体间效应与个体内效应区分开来，但它需要更大的样本和更大的检验效能，特别是对于具有更多变量的更复杂的模型。\n{引用自WITH R NETWORK PSYCHOMETRICS=“” fig-align=“center”}\n其次，时间网络分析评估模型中每个变量的中心性，这可以识别网络中最重要的(或最有影响力的)节点。由于高度中心的节点影响网络中最多的变量，因此它们可能是干预的有用目标。\n\n\n\n时间网络分析还在发展之中，并不完善。对于N=1的时间序列网络分析，主要思想是通图形向量自回归模型（GVAR）进行处理；对于N&gt;1的时间序列，可能会更多地考虑多层VAR（mlVAR包实现了这种统计建模方法）。\n在VAR中，在连续的时间点之间使用线性回归来建模时间依赖关系，允许人们在控制了时间效应（同期效应）后，获得跨时间的关系（时间效应）和同一测量窗口中的关系的单独估计。VAR变体是这一部分的核心焦点是图形VAR（GVAR）模型，其中同时的效果被进一步建模为高斯图形模型。因此，GVAR模型返回两种网络结构：一个时间网络，这是一个时间关系的有向网络；一个同时网络，它是一个同时关系的无向网络。\n\n\n\n可以实现上述几种时间序列数据网络分析的R包有多种，目前来看并不统一，单是我在各类文献中看到的工具包就不少，比如，有用时间社会网络分析（tsna）的，有用多水平向量自回归(mlVAR包，Multi-Level Vector Autoregression)的，也有用时变向量自回归包（mgm包）以及psychonetrics包（面板GVAR模型）……\n虽然让人眼花缭乱，但底层逻辑是相似的，主要还是要看你的研究类型和目的。譬如，mlVAR会分离出以下三种网络：\n{引用自WITH R NETWORK PSYCHOMETRICS=“” fig-align=“center”}\n我在上述对应R包的名字上附上了具体文献或者代码仓库的超链接，你如果感兴趣的话，可以点进去看看这些文献对Temporal network analysis的具体实现方法。\n个人比较推荐使用mlVAR构建时间序列网络模型。\n\n\n\n\n\n为了避免版本兼容性问题，大家可以先跳转到文末看看我使用的R语言环境。\n先导入需要使用的程序包，没有安装的请先安装。\n本次我们用mlVAR包的mlVARsim函数模拟一份数据(实际是拟合也了一个时间网络模型)，为了减轻电脑的计算负担，设置受试者人数为50，节点数为8个，测量次数是30，阶数lag为1，其它都是默认设置。\n\nModel = mlVARsim(nPerson = 50,nNode = 8, nTime = 30, lag=1)\n\n查看数据：\n\nhead(Model$Data)\n\n         V1       V2        V3        V4        V5         V6         V7\n1 2.0335217 3.157925 -3.876432 -4.733132 -2.543258 -0.6276040  1.4945052\n2 2.2822126 3.732587 -4.179065 -1.685546 -2.404072  1.7619746 -0.1781815\n3 1.5409651 2.615361 -2.934132 -3.383525 -1.873246  2.5694409 -3.4722245\n4 0.6782198 3.847820 -1.470588 -5.984845 -2.705544  1.5355441 -0.9820712\n5 3.8371249 3.970785 -1.777491 -2.959565 -3.943941  0.5437959 -1.6252762\n6 3.0328899 1.786133 -1.560092 -1.860449 -2.511397  2.1500955  1.1310869\n         V8 ID\n1 -8.729056  1\n2 -7.772314  1\n3 -6.317016  1\n4 -6.868845  1\n5 -6.163121  1\n6 -5.477314  1\n\n\n查看节点名：\n\nModel$vars\n\n[1] \"V1\" \"V2\" \"V3\" \"V4\" \"V5\" \"V6\" \"V7\" \"V8\"\n\n\n查看受试者变量：\n\nModel$idvar\n\n[1] \"ID\"\n\n\n绘图：\n\nplot(Model)\n\n\n\n\n\n\n\n好戏开始：用mlVAR函数拟合时间网络模型！\n这里面的data、vars、idvar是必须写的，分别表示数据、要分析的变量名、代表受试者的变量。lags可以选用默认参数，estimator是估计器，具体的选项可以查看帮助文档，这里选择lmer；contemporaneous（同期网络）、temporal（时序网络）估计方法都采用”correlated”；nCores指定使用的cpu核心数，计算量不小，可以适当大一些。\n\nfit1 = mlVAR(data = Model$Data, \n            vars = Model$vars, \n            idvar = Model$idvar, \n            lags = 1, \n            estimator = \"lmer\",\n            temporal = \"correlated\",\n            contemporaneous = \"correlated\",\n            nCores = 8,\n            verbose =F\n )\n\n总结模型：\n\nsummary(fit1)\n\n\nmlVAR estimation completed. Input was:\n    - Variables: V1 V2 V3 V4 V5 V6 V7 V8 \n    - Lags: 1 \n    - Estimator: lmer \n    - Temporal: correlated\n\nInformation indices:\n var      aic      bic\n  V1 3199.817 3527.135\n  V2 2934.493 3261.810\n  V3 3112.823 3440.141\n  V4 2840.875 3168.193\n  V5 2705.464 3032.781\n  V6 2985.371 3312.689\n  V7 3090.526 3417.844\n  V8 2959.122 3286.440\n\n\nTemporal effects:\n from to lag  fixed    SE     P ran_SD\n   V1 V1   1  0.116 0.029 0.000  0.078\n   V1 V2   1  0.175 0.027 0.000  0.090\n   V1 V3   1 -0.515 0.041 0.000  0.216\n   V1 V4   1 -0.441 0.030 0.000  0.120\n   V1 V5   1  0.005 0.033 0.890  0.162\n   V1 V6   1  0.362 0.028 0.000  0.083\n   V1 V7   1  0.269 0.030 0.000  0.102\n   V1 V8   1  0.035 0.041 0.394  0.229\n   V2 V1   1  0.032 0.042 0.449  0.242\n   V2 V2   1  0.132 0.036 0.000  0.199\n   V2 V3   1  0.309 0.032 0.000  0.154\n   V2 V4   1  0.140 0.031 0.000  0.154\n   V2 V5   1  0.037 0.032 0.250  0.174\n   V2 V6   1 -0.384 0.039 0.000  0.229\n   V2 V7   1 -0.285 0.036 0.000  0.196\n   V2 V8   1  0.048 0.034 0.154  0.182\n   V3 V1   1  0.027 0.030 0.372  0.102\n   V3 V2   1  0.004 0.027 0.886  0.084\n   V3 V3   1  0.117 0.032 0.000  0.134\n   V3 V4   1  0.167 0.035 0.000  0.178\n   V3 V5   1 -0.265 0.025 0.000  0.082\n   V3 V6   1 -0.023 0.029 0.425  0.105\n   V3 V7   1 -0.038 0.027 0.159  0.064\n   V3 V8   1  0.332 0.029 0.000  0.109\n   V4 V1   1  0.050 0.036 0.168  0.180\n   V4 V2   1 -0.181 0.036 0.000  0.198\n   V4 V3   1 -0.022 0.039 0.573  0.208\n   V4 V4   1  0.255 0.039 0.000  0.224\n   V4 V5   1  0.184 0.038 0.000  0.219\n   V4 V6   1  0.161 0.038 0.000  0.208\n   V4 V7   1 -0.239 0.043 0.000  0.248\n   V4 V8   1  0.138 0.038 0.000  0.208\n   V5 V1   1 -0.022 0.029 0.448  0.106\n   V5 V2   1  0.392 0.026 0.000  0.077\n   V5 V3   1 -0.131 0.029 0.000  0.101\n   V5 V4   1 -0.024 0.026 0.351  0.088\n   V5 V5   1  0.055 0.028 0.049  0.122\n   V5 V6   1  0.027 0.030 0.369  0.129\n   V5 V7   1  0.043 0.031 0.162  0.134\n   V5 V8   1 -0.041 0.025 0.092  0.053\n   V6 V1   1 -0.023 0.033 0.492  0.141\n   V6 V2   1 -0.039 0.046 0.394  0.271\n   V6 V3   1  0.098 0.038 0.009  0.187\n   V6 V4   1 -0.066 0.034 0.055  0.170\n   V6 V5   1  0.167 0.040 0.000  0.227\n   V6 V6   1  0.009 0.040 0.820  0.212\n   V6 V7   1 -0.105 0.039 0.007  0.201\n   V6 V8   1 -0.018 0.039 0.639  0.211\n   V7 V1   1 -0.012 0.034 0.731  0.155\n   V7 V2   1 -0.016 0.027 0.554  0.092\n   V7 V3   1  0.019 0.035 0.582  0.168\n   V7 V4   1  0.251 0.029 0.000  0.119\n   V7 V5   1  0.183 0.026 0.000  0.097\n   V7 V6   1 -0.042 0.027 0.126  0.094\n   V7 V7   1  0.031 0.027 0.253  0.071\n   V7 V8   1  0.253 0.026 0.000  0.071\n   V8 V1   1 -0.072 0.042 0.087  0.226\n   V8 V2   1 -0.432 0.037 0.000  0.192\n   V8 V3   1  0.138 0.042 0.001  0.232\n   V8 V4   1 -0.027 0.040 0.493  0.219\n   V8 V5   1  0.219 0.038 0.000  0.216\n   V8 V6   1 -0.033 0.039 0.393  0.211\n   V8 V7   1  0.202 0.038 0.000  0.197\n   V8 V8   1  0.137 0.040 0.001  0.220\n\n\nContemporaneous effects (posthoc estimated):\n v1 v2 P 1-&gt;2 P 1&lt;-2   pcor ran_SD_pcor    cor ran_SD_cor\n V2 V1  0.000  0.000 -0.255       0.218 -0.237      0.243\n V3 V1  0.761  0.999 -0.006       0.171 -0.031      0.186\n V3 V2  0.351  0.302  0.042       0.184 -0.116      0.185\n V4 V1  0.000  0.000  0.224       0.169  0.263      0.232\n V4 V2  0.771  0.861  0.009       0.172 -0.039      0.218\n V4 V3  0.451  0.683 -0.022       0.141 -0.063      0.204\n V5 V1  0.013  0.002 -0.124       0.209 -0.060      0.236\n V5 V2  0.000  0.000  0.194       0.203  0.275      0.217\n V5 V3  0.000  0.000 -0.264       0.189 -0.335      0.219\n V5 V4  0.000  0.000  0.182       0.239  0.193      0.286\n V6 V1  0.000  0.000  0.177       0.084  0.060      0.172\n V6 V2  0.000  0.000  0.287       0.215  0.306      0.212\n V6 V3  0.000  0.000 -0.270       0.140 -0.321      0.146\n V6 V4  0.000  0.001 -0.147       0.165 -0.108      0.234\n V6 V5  0.038  0.005  0.089       0.131  0.214      0.188\n V7 V1  0.104  0.161  0.063       0.173  0.204      0.165\n V7 V2  0.610  0.653  0.020       0.171 -0.017      0.239\n V7 V3  0.738  0.273 -0.026       0.137 -0.059      0.206\n V7 V4  0.000  0.000  0.310       0.169  0.404      0.200\n V7 V5  0.847  0.588 -0.006       0.156  0.131      0.267\n V7 V6  0.008  0.013 -0.090       0.117 -0.078      0.157\n V8 V1  0.000  0.000  0.166       0.146  0.220      0.171\n V8 V2  0.406  0.858  0.023       0.189  0.047      0.284\n V8 V3  0.954  0.405 -0.015       0.142 -0.124      0.216\n V8 V4  0.586  0.979  0.010       0.123  0.230      0.206\n V8 V5  0.000  0.000  0.202       0.125  0.260      0.207\n V8 V6  0.311  0.312  0.039       0.153  0.075      0.227\n V8 V7  0.000  0.000  0.344       0.149  0.414      0.163\n\n\nBetween-subject effects:\n v1 v2 P 1-&gt;2 P 1&lt;-2   pcor    cor\n V2 V1  0.282  0.811  0.080  0.155\n V3 V1  0.038  0.067  0.240  0.251\n V3 V2  0.958  0.467 -0.042  0.047\n V4 V1  0.122  0.295  0.164  0.126\n V4 V2  0.707  0.322  0.091  0.172\n V4 V3  0.418  0.238 -0.131 -0.117\n V5 V1  0.264  0.142 -0.161 -0.047\n V5 V2  0.085  0.001  0.306  0.185\n V5 V3  0.276  0.252  0.142  0.155\n V5 V4  0.121  0.187 -0.187 -0.345\n V6 V1  0.003  0.001  0.370  0.317\n V6 V2  0.128  0.713  0.122  0.057\n V6 V3  0.312  0.756  0.044  0.161\n V6 V4  0.311  0.704 -0.091 -0.244\n V6 V5  0.240  0.120  0.172  0.304\n V7 V1  0.132  0.183 -0.179 -0.121\n V7 V2  0.396  0.486  0.100  0.083\n V7 V3  0.334  0.764  0.081 -0.038\n V7 V4  0.036  0.036  0.261  0.349\n V7 V5  0.177  0.072 -0.198 -0.280\n V7 V6  0.290  0.685 -0.039 -0.215\n V8 V1  0.312  0.134  0.148  0.139\n V8 V2  0.001  0.001  0.378  0.362\n V8 V3  0.326  0.624  0.090  0.027\n V8 V4  0.121  0.029  0.225  0.407\n V8 V5  0.127  0.399 -0.146 -0.239\n V8 V6  0.000  0.017 -0.340 -0.344\n V8 V7  0.902  0.974 -0.006  0.188\n\n\n上面给出了大量的信息。值得注意的是，mlVAR包会输出3种效应：Temporal effects、Contemporaneous effects、Between-subject effects，分别对应时序网络、同期网络和个体间网络。\n\nTemporal effects（时间效应）：这是指变量在时间上对自身或其它变量的影响，这些效应通常是通过滞后回归权重来估计的，可以捕捉变量随时间的动态关系 。时序网络中的边是指变量在上个时间点t-1对下个时间点t的各节点的预测能力（控制了上个时间点t-1上的其他变量之后）。\nContemporaneous effects（同期效应）：这是指在相同时间点上变量之间的关系，可以是简单的相关关系或偏相关关系。这些关系通常是通过模型残差的相互关系来估计的，可以揭示在同一时间点上变量之间的直接联系 。\nBetween-subject effects（个体间效应）：这是指在不同个体之间（平均水平层面的）变量关系的差异，可以是相关关系或偏相关关系。这些效应反映了不同个体在变量关系上的差异，有助于理解不同个体在心理过程上的差异 。\n\n\n\n\n我们可以分别绘制这些网络图：\n\n# 同期网络\ncontemporaneous = plot(fit1, type = \"temporal\", title = \"Estimated temporal relationships\", \n     rule = \"and\",layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n# 时序网络\ntemporal=plot(fit1, type = \"contemporaneous\", rule = \"and\",\n     title = \"Estimated contemporaneous relationships\", layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n# 受试者间网络  必须取名between，否则报错\nbetween = plot(fit1, type = \"between\", rule = \"or\",\n     title = \"Estimated between relationships\", layout = \"circle\")\n\n'nonsig' argument set to: 'hide'\n\n\n\n\n\n\n\n\n可以跟横断面网络一样，计算或者开展后续一些常用的指标和检验，比如中心性，桥梁症状。\n\n# 计算中心性\ncentrality(contemporaneous)  \n\n$OutDegree\n       V1        V2        V3        V4        V5        V6        V7        V8 \n1.7626296 1.1175046 0.7645637 0.9034969 0.5231023 0.3698123 0.6865014 0.9912068 \n\n$InDegree\n       V1        V2        V3        V4        V5        V6        V7        V8 \n0.0000000 1.1805817 1.1909310 0.9991603 1.0172301 0.9069345 1.1013387 0.7226413 \n\n$Closeness\n        V1         V2         V3         V4         V5         V6         V7 \n0.03696362 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 \n        V8 \n0.00000000 \n\n$Betweenness\nV1 V2 V3 V4 V5 V6 V7 V8 \n 0 11  6  0  1  0  2  6 \n\n$InExpectedInfluence\n         V1          V2          V3          V4          V5          V6 \n 0.00000000 -0.04617963 -0.10094765  0.11654432  0.48700373  0.13880776 \n         V7          V8 \n-0.15752989  0.72264128 \n\n$OutExpectedInfluence\n         V1          V2          V3          V4          V5          V6 \n-0.14918637 -0.22089092  0.23433731  0.06198312  0.26042372  0.16018255 \n         V7          V8 \n 0.68650135  0.12698916 \n\n$ShortestPathLengths\n    V1       V2        V3        V4       V5       V6       V7        V8\nV1   0 5.700019  1.943257  2.265991 5.715231 2.763749 3.711177  4.954201\nV2 Inf 0.000000  3.238940  7.165181 7.010914 2.603737 3.507118  6.249884\nV3 Inf 5.325176  0.000000  5.976258 3.771974 7.928913 7.950482  3.010944\nV4 Inf 5.516577  8.755517  0.000000 5.430191 6.209490 4.175626  7.270580\nV5 Inf 2.552564  5.791503  9.717744 0.000000 5.156301 6.059682  8.802448\nV6 Inf 8.558272 10.153397 13.525333 6.005709 0.000000 9.540629 13.164342\nV7 Inf 6.267130  9.506069  3.984703 5.477571 8.870867 0.000000  3.952898\nV8 Inf 2.314232  5.553172  8.924241 4.568496 4.917969 4.939537  0.000000\n\n$ShortestPaths\n   V1   V2   V3   V4   V5   V6   V7   V8  \nV1 NULL NULL NULL NULL NULL NULL NULL NULL\nV2 NULL NULL NULL NULL NULL NULL NULL NULL\nV3 NULL NULL NULL NULL NULL NULL NULL NULL\nV4 NULL NULL NULL NULL NULL NULL NULL NULL\nV5 NULL NULL NULL NULL NULL NULL NULL NULL\nV6 NULL NULL NULL NULL NULL NULL NULL NULL\nV7 NULL NULL NULL NULL NULL NULL NULL NULL\nV8 NULL NULL NULL NULL NULL NULL NULL NULL\n\n\n可以将其绘制出来，下面的代码依次绘制同期网络、时序网络和个体间网络。\n\ncentralityPlot(contemporaneous) \n\n\n\n\n\ncentralityPlot(temporal)\n\n\n\n\n\ncentralityPlot(between)\n\n\n\n\n完全可以对绘图函数的参数做些个性化调整，这里不多展示了。\n\n\n\n先人为对模拟数据的节点进行分组：\n\ngroups=c(rep('A',4),rep('B',2),rep('C',2))\n\n计算桥梁中心性指标：\n\nb = bridge(contemporaneous, communities= groups, directed=F)\nb\n\n$`Bridge Strength`\n       V1        V2        V3        V4        V5        V6        V7        V8 \n0.6312836 0.6691977 0.5972349 0.7222251 0.5231023 0.2033041 0.4335224 0.7887587 \n\n$`Bridge Betweenness`\nV1 V2 V3 V4 V5 V6 V7 V8 \n 5  1  1  5  0  1  2  3 \n\n$`Bridge Closeness`\n        V1         V2         V3         V4         V5         V6         V7 \n0.14014223 0.10893181 0.12090457 0.13274157 0.08197854 0.13031448 0.11021654 \n        V8 \n0.12678535 \n\n$`Bridge Expected Influence (1-step)`\n          V1           V2           V3           V4           V5           V6 \n 0.631283628 -0.669197749  0.067008531  0.243254960  0.260423716 -0.006325689 \n          V7           V8 \n 0.433522386 -0.075458952 \n\n$`Bridge Expected Influence (2-step)`\n         V1          V2          V3          V4          V5          V6 \n 0.51172975 -0.76244179  0.24764776  0.32814244  0.25875117  0.03340721 \n         V7          V8 \n 0.50311573  0.02808020 \n\n$communities\n[1] \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"\n\n\n简单绘图：\n\nplot(b, include=c(\"Bridge Expected Influence (2-step)\", \"Bridge Strength\", \"Bridge Closeness\"),\n     theme_bw=F, raw0 = T, signed=T) \n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n\n\n\n\n\n\n\n时间网络分析目前还不完善，上述流程并没有覆盖到之前我们做横断面网络的所有评估指标和检验方法，比如稳定性、精确性、差异性检验，我还没有找到合适的R包可以很方便地对其进行分析（估计得自己写重抽样代码）。\n此外，时间网络分析不同于CLPM网络分析，其对数据有一些要求，比如说测量次数多、满足多元正态分布、具备平稳性……\n你如果有一份生态瞬时数据或者密集追踪数据，且想要进行时间网络分析，建议在建模前检查下数据，包括正态性（不服从也可以做）、平稳性（KPSS平稳性检验，文献提到可以用R包tseries实现，要一个个做，所以代码有些复杂），等等。\n\n\n{r}\nsessionInfo()}"
  },
  {
    "objectID": "交叉滞后网络.html#交叉滞后模型简介",
    "href": "交叉滞后网络.html#交叉滞后模型简介",
    "title": "交叉滞后网络",
    "section": "1 交叉滞后模型简介",
    "text": "1 交叉滞后模型简介\n交叉滞后模型（Cross-Lagged Panel Model，简称 CLPM）是一种用于分析时间序列数据中多个变量之间的因果关系的统计方法。它主要用于分析多个时间点上同一组变量的相互影响，特别是不同变量在不同时间点之间的滞后效应（即某个变量在先前时间点的变化对另一个变量在后续时间点的影响）。\n\n1.1 CLPM的核心思想\n\n自回归效应（Autoregressive Effects）：模型中的每个变量都会在自己的时间点上预测下一个时间点的值。这意味着变量会表现出一种时间上的稳定性或持续性。比如，X1_T2 ~ X1_T1 表示变量 X1 在时间点 T2 的值由 X1 在时间点 T1 的值预测。\n交叉滞后效应（Cross-Lagged Effects）：模型中的某些变量不仅仅影响自己的未来值，还可以影响其他变量在未来的值。比如，X2_T2 ~ X1_T1 表示 X1 在时间点 T1 对 X2 在时间点 T2 的影响。\n同时相关性（Concurrent Correlation）：同一时间点上的不同变量之间可能会存在相关性，但这不是 CLPM 研究的主要焦点，CLPM 更加关注滞后的因果关系。\n\n\n\n1.2 CLPM的优点\n\n因果推断：CLPM 允许对多个时间点上的数据进行分析，帮助理解一个变量的变化是否会导致另一个变量在未来的变化。\n双向分析：CLPM 可以同时研究两个变量之间的双向影响，例如研究 A 对 B 的影响，同时也能分析 B 对 A 的影响。\n控制自相关：CLPM 控制了变量本身的时间序列自相关性，减少了混淆因果关系的可能性。\n\n\n\n1.3 CLPM模型示例\n假设我们有两个变量 X 和 Y，在两个时间点 T1 和 T2 上进行测量，CLPM 模型会如下描述：\n\nX_T2 ~ X_T1：表示 X 在时间点 T1 对时间点 T2 的预测。\nY_T2 ~ Y_T1：表示 Y 在时间点 T1 对时间点 T2 的预测。\nX_T2 ~ Y_T1：表示 Y 在时间点 T1 对 X 在时间点 T2 的预测（交叉滞后效应）。\nY_T2 ~ X_T1：表示 X 在时间点 T1 对 Y 在时间点 T2 的预测（交叉滞后效应）。\n\n我们可以使用 lavaan 包来拟合交叉滞后面板模型，当然也可以用其他软件。"
  },
  {
    "objectID": "交叉滞后网络.html#交叉滞后网络分析",
    "href": "交叉滞后网络.html#交叉滞后网络分析",
    "title": "交叉滞后网络",
    "section": "2 交叉滞后网络分析",
    "text": "2 交叉滞后网络分析\n\n2.1 核心概念\n交叉滞后网络分析通过网络图直观地展示各个变量在不同时间点上的相互作用，强调变量之间的双向影响（即滞后影响）。该方法有助于研究不同时间点上的变量如何相互作用，并能够捕捉变量之间的交叉滞后效应。\n\n自回归效应（Autoregressive Effects）：描述同一变量在不同时间点之间的关系。例如，某一变量在 T1 时间点的状态对该变量在 T2 时间点的状态的影响。\n交叉滞后效应（Cross-Lagged Effects）：描述一个变量在 T1 时间点的状态如何影响另一个变量在 T2 时间点的状态。这可以揭示两个变量之间的滞后因果关系。\n网络结构：在网络图中，节点代表不同的变量，边表示这些变量之间的相互关系。边的方向表示因果顺序（如 T1 的一个变量影响 T2 的另一个变量），边的粗细或颜色可以表示影响的强度或显著性。\n\n\n\n2.2 主要步骤\n\n数据准备：你需要时间序列数据，其中包括多个变量在至少两个时间点的观测。例如，8 个变量在两个时间点上的测量数据，表示为 X1_T1, X1_T2, ..., X8_T1, X8_T2。\n拟合模型：采用交叉滞后模型（CLPM），估计变量之间的滞后效应和自回归效应。\n构建网络：基于模型的参数估计，构建反映各个变量之间关系的网络图。可以将滞后效应和自回归效应表示为不同的边，边的方向和权重根据估计的系数确定。\n网络分析与可视化：使用网络分析工具（如 qgraph）来绘制网络图并分析变量之间的关系。可以通过网络图直观地观察哪些变量在时间上对其他变量有较强的影响\n\n\n\n3 R语言实现\n一些文献作者和博主将这块内容写得比较复杂，是因为他们做了很多全面或细节的工作，在这里，我只关注核心的部分。通俗点说，就是干了三件事：估计交叉滞后关系；拟合网络模型；计算中心性。其他的没有展示，如果你确实有需要，可以联系我，也可以查阅其他资料。我的运行环境见文末，可以先看看，避免因版本问题出现不兼容现象。\n\n3.1 加载包和数据集\n加载包，glmnet是本次估计交叉滞后模型的核心工具，qgraph用于估计和可视化网络模型，没有安装的请先安装。\n加载数据集：本次使用的数据来自mplus，是一份在线公开的数据，我对其变量进行了微调，处理后的数据包含4个变量，每个变量共测量两次。\n\nmyData = read.table('https://www.statmodel.com/usersguide/chap9/ex9.36.dat',col.names = c(\n  \"x1_T1\", \"x2_T1\", \"x3_T1\", \"x4_T1\",  \n  \"x1_T2\", \"x2_T2\", \"x3_T2\", \"x4_T2\",'other'))\nmyData = myData[1:500,1:8]\nhead(myData)\n\n      x1_T1    x2_T1     x3_T1     x4_T1     x1_T2     x2_T2     x3_T2\n1  0.788084 1.591209  0.511102  0.914914  1.936940 -0.107719 -0.101231\n2 -0.009034 1.469638 -0.233090 -0.876846  0.024599 -1.161630 -0.762810\n3 -1.175985 0.475876 -0.499924 -0.724097 -0.349644  1.623638  0.842133\n4  2.051786 0.676110  0.156716 -1.030892 -2.032910 -0.161885 -1.555111\n5  0.286151 1.511453  0.558715 -1.031686  2.632008  1.591209  2.891134\n6  0.609619 0.854681 -0.011676 -0.690153 -0.574647  0.516570  0.097766\n      x4_T2\n1  0.325695\n2  0.505980\n3 -0.597006\n4 -0.585915\n5  2.949251\n6 -0.409471\n\n\n\n\n3.2 使用glmnet估计交叉滞后模型\n这是关键点，先上代码，然后再解释为何可以这样做。\n\n# 指定变量个数\nk = 4\n# 构建空白矩阵，等下要用它来填补glmnet回归获得的系数\ninput = matrix(0, k, k) \n\n# 自建for循环\n# 以前一时间点测量的所有变量数据为自变量，分别对下一个时间点的变量进行正则化回归，然后提取每个回归方程的回归系数，放入我们构建好的空白矩阵input\nfor (i in 1:k){\n  set.seed(666)\n  cv_fit = cv.glmnet(as.matrix(myData[,1:k]), myData[,(k+i)], alpha = 1, standardize=T)\n  best_lambda = cv_fit$lambda.min\n  input[1:k,i] = coef(cv_fit, s = best_lambda, exact = F)[2:(k+1)]\n  print(best_lambda)\n}\n\n[1] 0.03487359\n[1] 0.02511449\n[1] 0.004689684\n[1] 0.004742094\n\ninput\n\n           [,1]       [,2]       [,3]       [,4]\n[1,] 0.06398311 0.25796633 0.22294470 0.18612493\n[2,] 0.31186373 0.04148868 0.08349683 0.15845230\n[3,] 0.01052138 0.15513120 0.19572806 0.08433666\n[4,] 0.00000000 0.06457500 0.04788886 0.14437457\n\n\n3.3 拟合网络模型\n\ng1 = qgraph(input,layout = \"spring\",details = T) #也可以自己调整颜色，如color=\"gold\",edge.color='pink')\n\n\n\n\n\n\n3.4 去除自回归\n如果你不想要展示自回归，可以设置输入矩阵的对角线（自回归）为0。\n\n# 去除自回归效应\n# copy一份矩阵\nnoauotreg_input= input\n\n# 将矩阵的对角线元素设置为0\ndiag(noauotreg_input) = 0\n\n# 查看新矩阵\nnoauotreg_input\n\n           [,1]      [,2]       [,3]       [,4]\n[1,] 0.00000000 0.2579663 0.22294470 0.18612493\n[2,] 0.31186373 0.0000000 0.08349683 0.15845230\n[3,] 0.01052138 0.1551312 0.00000000 0.08433666\n[4,] 0.00000000 0.0645750 0.04788886 0.00000000\n\n\n估计新模型：\n\ng2 = qgraph(noauotreg_input,layout = \"spring\",details = T,color=\"gold\")\n\n\n\n\n\n\n3.5 计算中心性\n\ncentrality(g1)\n\n$OutDegree\n        1         2         3         4 \n0.6670360 0.5538129 0.2499892 0.1124639 \n\n$InDegree\n        1         2         3         4 \n0.3223851 0.4776725 0.3543304 0.4289139 \n\n$Closeness\n         1          2          3          4 \n0.07280867 0.05810737 0.03577039 0.01816202 \n\n$Betweenness\n1 2 3 4 \n1 2 0 0 \n\n$InExpectedInfluence\n        1         2         3         4 \n0.3223851 0.4776725 0.3543304 0.4289139 \n\n$OutExpectedInfluence\n        1         2         3         4 \n0.6670360 0.5538129 0.2499892 0.1124639 \n\n$ShortestPathLengths\n          1         2         3         4\n1  0.000000  3.876475  4.485417  5.372735\n2  3.206529  0.000000  7.691946  6.311048\n3  9.652685  6.446156  0.000000 11.857240\n4 18.692398 15.485869 20.881681  0.000000\n\n$ShortestPaths\n  1    2    3    4   \n1 NULL NULL NULL NULL\n2 NULL NULL NULL NULL\n3 NULL NULL NULL NULL\n4 NULL NULL NULL NULL\n\n\n可视化：\n\ncentralityPlot(g1, include=c(\"OutStrength\", \"InStrength\", \n                             \"Betweenness\",\"Closeness\"))\n\n\n\n\n是不是非常简单？哈哈，毕竟错失了很多细节部分，所以会显得很简单。解释一下这个原理：\n前面以前说过了，交叉滞后模型的核心就是自回归和交叉滞后效应，这是通过多次回归实现的，常规思路是使用lavaan包处理（如果你用R的话），但网络分析一般是在复杂场景中进行了，变量数较多，所以通常会使用正则化的回归技术来计算这几种核心的效应值。\n正如我在代码注释中提到的，以前一个时间点的所有变量为x，分别以下一个时间点的变量为y（一个个来），依次建立回归模型，为了避免模型过于复杂，也为了减轻网络效应值很小的”虚假”的边，我们可以用L1正则化（lasso）技术来将一些比较小的系数给压缩为0，这样可以实现网络的稀疏化。\n然后，我们可以把得到的各回归系数存储在矩阵内，然后将其输入qgraph函数（也可以是别的）。\n\n\n\n4 小结与建议\n交叉滞后网络模型是最常见的纵向网络分析方法之一，但一般不适用于重复次数非常多的场景，比如生态瞬时数据或者密集追踪数据，这个就需要应用到一种叫做向量自回归（VAR及其变体）的技术了，这些会在后续介绍。\n本次仅做了一个非常简单的建模演示，如果你想要更进一步了解此类模型，建议掌握其中的原理，这样后续想继续做点什么就方便很多了。兴趣是最好的老师，高质量文献是最好的学习途径，辅助使用一些人工智能工具，往往可以事半功倍。欢迎关注我们的公众号：护理统计随笔，会不定期更新一些新的进展。\n最后，交叉滞后网络分析中是可以加入协变量的，就在glmnet循环部分加入，计算其系数，后面可以再剔除。\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] qgraph_1.9.8 glmnet_4.1-8 Matrix_1.6-5\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      shape_1.4.6       xfun_0.41         ggplot2_3.5.0    \n [5] htmlwidgets_1.6.2 psych_2.3.9       lattice_0.21-9    quadprog_1.5-8   \n [9] vctrs_0.6.4       tools_4.3.2       generics_0.1.3    stats4_4.3.2     \n[13] parallel_4.3.2    tibble_3.2.1      fansi_1.0.5       cluster_2.1.4    \n[17] pkgconfig_2.0.3   data.table_1.15.4 checkmate_2.3.0   lifecycle_1.0.4  \n[21] farver_2.1.1      compiler_4.3.2    stringr_1.5.1     munsell_0.5.0    \n[25] mnormt_2.1.1      codetools_0.2-19  htmltools_0.5.7   glasso_1.11      \n[29] fdrtool_1.2.17    yaml_2.3.7        htmlTable_2.4.2   Formula_1.2-5    \n[33] pillar_1.9.0      Hmisc_5.1-1       iterators_1.0.14  abind_1.4-5      \n[37] rpart_4.1.21      foreach_1.5.2     nlme_3.1-163      lavaan_0.6-17    \n[41] gtools_3.9.5      tidyselect_1.2.0  digest_0.6.33     stringi_1.8.1    \n[45] dplyr_1.1.4       reshape2_1.4.4    labeling_0.4.3    splines_4.3.2    \n[49] fastmap_1.1.1     grid_4.3.2        colorspace_2.1-0  cli_3.6.2        \n[53] magrittr_2.0.3    base64enc_0.1-3   survival_3.5-7    utf8_1.2.4       \n[57] pbivnorm_0.6.0    withr_2.5.2       foreign_0.8-85    corpcor_1.6.10   \n[61] scales_1.3.0      backports_1.4.1   rmarkdown_2.25    jpeg_0.1-10      \n[65] igraph_2.0.1.1    nnet_7.3-19       gridExtra_2.3     png_0.1-8        \n[69] pbapply_1.7-2     evaluate_0.23     knitr_1.45        rlang_1.1.3      \n[73] Rcpp_1.0.11       glue_1.6.2        rstudioapi_0.16.0 jsonlite_1.8.7   \n[77] R6_2.5.1          plyr_1.8.9"
  },
  {
    "objectID": "混合变量网络分析.html",
    "href": "混合变量网络分析.html",
    "title": "混合变量网络分析",
    "section": "",
    "text": "1 简介\n如果你想要开展一项基于混合类型数据（即包含连续变量、二分类变量、多分类变量等不同类型数据）的网络分析，通常需要使用混合图模型（Mixed Graphical Models, MGM）进行分析。\n混合图模型是一种统计模型，用于处理具有不同数据类型的网络结构。它通过组合不同类型的概率分布，来描述连续、二分类、多分类等不同类型的变量之间的相互关系。MGM 在网络分析中非常有用，因为它能够统一处理多种数据类型，并建立它们之间的条件依赖结构。\n\n连续变量：通常假设服从正态分布，适用于数据类型为实数的数据。\n二分类变量：常见于0/1变量，适用于存在两种可能结果的情况。\n多分类变量：用于处理多个类别（如”红”、“绿”、“蓝”等）的数据。\n\nMGM 的目标是通过正则化技术（如 Lasso）来学习网络中节点之间的稀疏关系，使得网络结构更加清晰并具有解释性。\n\n\n2 R语言实现\nR软件包mgm可以轻松搞定混合图模型，这里给个简单的建模演示，并提供一个稳定性检验的思路。\n\n2.1 导入包和数据\n导入包：\n导入数据：这里使用一份mgm自带的数据集，具体含义请?查看帮助文档。\n\nhead(autism_data$data) #数据\n\n     Gender   IQ Integration in Society No of Comorbidities Type of Housing\n[1,]      1 6.00                      1                   1               1\n[2,]      2 6.00                      2                   1               1\n[3,]      1 5.00                      2                   0               1\n[4,]      1 6.00                      1                   0               1\n[5,]      1 5.00                      1                   1               1\n[6,]      1 4.49                      1                   1               1\n     Workinghours Satisfaction: Treatment\n[1,]            0                    3.00\n[2,]            0                    2.00\n[3,]            0                    4.00\n[4,]           10                    3.00\n[5,]            0                    1.00\n[6,]            0                    1.75\n\nautism_data$type  #变量类型\n\n[1] \"c\" \"g\" \"c\" \"p\" \"c\" \"g\" \"g\"\n\n\n\n\n2.2 建模\n\nfit_k2 = mgm(data = autism_data$data,  \n             type = autism_data$type, \n             level = autism_data$lev, \n             k = 2) \n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |----------                                                            |  14%\n  |                                                                            \n  |--------------------                                                  |  29%\n  |                                                                            \n  |------------------------------                                        |  43%\n  |                                                                            \n  |----------------------------------------                              |  57%\n  |                                                                            \n  |--------------------------------------------------                    |  71%\n  |                                                                            \n  |------------------------------------------------------------          |  86%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\nNote that the sign of parameter estimates is stored separately; see ?mgm\n\n\n提取领接矩阵：\n\nfit_k2$pairwise$wadj\n\n           [,1]       [,2]       [,3]       [,4]       [,5]       [,6]\n[1,] 0.00000000 0.05650110 0.01891638 0.17205785 0.37208064 0.02150960\n[2,] 0.05650110 0.00000000 0.22270593 0.21779243 0.50904041 0.00000000\n[3,] 0.01891638 0.22270593 0.00000000 0.33738414 0.09886023 0.24073935\n[4,] 0.17205785 0.21779243 0.33738414 0.00000000 0.00000000 0.00000000\n[5,] 0.37208064 0.50904041 0.09886023 0.00000000 0.00000000 0.34679957\n[6,] 0.02150960 0.00000000 0.24073935 0.00000000 0.34679957 0.00000000\n[7,] 0.04326794 0.05566156 0.32121423 0.07538601 0.06715508 0.04882564\n           [,7]\n[1,] 0.04326794\n[2,] 0.05566156\n[3,] 0.32121423\n[4,] 0.07538601\n[5,] 0.06715508\n[6,] 0.04882564\n[7,] 0.00000000\n\n\n绘制网络图：\n\nqgraph(fit_k2$pairwise$wadj,\n       edge.color = fit_k2$pairwise$edgecolor,\n       layout = \"spring\",\n       labels =  autism_data$colnames)\n\n\n\n\n\n\n2.3 计算中心性\n\ncentrality(fit_k2$pairwise$wadj)\n\n$OutDegree\n[1] 0.6843335 1.0617014 1.2398203 0.8026204 1.3939359 0.6578742 0.6115105\n\n$InDegree\n[1] 0.6843335 1.0617014 1.2398203 0.8026204 1.3939359 0.6578742 0.6115105\n\n$Closeness\n[1] 0.02538851 0.03552435 0.03338681 0.03019457 0.03320694 0.03140568 0.02196939\n\n$Betweenness\n[1]  0  6 12  4  6  0  0\n\n$InExpectedInfluence\n[1] 0.6843335 1.0617014 1.2398203 0.8026204 1.3939359 0.6578742 0.6115105\n\n$OutExpectedInfluence\n[1] 0.6843335 1.0617014 1.2398203 0.8026204 1.3939359 0.6578742 0.6115105\n\n$ShortestPathLengths\n          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]      [,7]\n[1,]  0.000000 4.652070 8.775979 5.811999 2.687589 5.571099 11.889166\n[2,]  4.652070 0.000000 4.490226 4.591528 1.964481 4.847991  7.603413\n[3,]  8.775979 4.490226 0.000000 2.963980 6.454707 4.153870  3.113187\n[4,]  5.811999 4.591528 2.963980 0.000000 6.556008 7.117851  6.077168\n[5,]  2.687589 1.964481 6.454707 6.556008 0.000000 2.883510  9.567894\n[6,]  5.571099 4.847991 4.153870 7.117851 2.883510 0.000000  7.267057\n[7,] 11.889166 7.603413 3.113187 6.077168 9.567894 7.267057  0.000000\n\n$ShortestPaths\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,] NULL NULL NULL NULL NULL NULL NULL\n[2,] NULL NULL NULL NULL NULL NULL NULL\n[3,] NULL NULL NULL NULL NULL NULL NULL\n[4,] NULL NULL NULL NULL NULL NULL NULL\n[5,] NULL NULL NULL NULL NULL NULL NULL\n[6,] NULL NULL NULL NULL NULL NULL NULL\n[7,] NULL NULL NULL NULL NULL NULL NULL\n\n\n\ncentralityPlot(fit_k2$pairwise$wadj)\n\n\n\n\n\n\n2.4 边缘精确性分析\n关于混合图网络模型到的精确性、差异性和稳定性检验，同样会用到bootnet包。bootnet包支持多种模型算法，但需要设置estimateNetwork封装，且需要设置default。\n\nmgm_net = estimateNetwork(autism_data$data,\n                          type = autism_data$type,\n                          level = autism_data$lev,\n                          default = 'mgm')\n\nEstimating Network. Using package::function:\n  - mgm::mgm for network computation\n    - Using glmnet::glmnet\n\n\nWarning in (function (data, type, level, tuning = 0.25, missing = c(\"listwise\",\n: Bootnet does not support unsigned edges and treats these as positive edges.\n\n\n\nprint(mgm_net)\n\n\n=== Estimated network ===\nNumber of nodes: 7 \nNumber of non-zero edges: 13 / 21 \nMean weight: 0.09694593 \nNetwork stored in mgm_net$graph \n \nDefault set used: mgm \n \nUse plot(mgm_net) to plot estimated network \nUse bootnet(mgm_net) to bootstrap edge weights and centrality indices \n\nRelevant references:\n\n    Jonas M. B. Haslbeck, Lourens J. Waldorp (2016). mgm: Structure Estimation for Time-Varying Mixed Graphical Models in high-dimensional Data arXiv preprint:1510.06871v2 URL http://arxiv.org/abs/1510.06871v2.\n    Epskamp, S., Borsboom, D., & Fried, E. I. (2016). Estimating psychological networks and their accuracy: a tutorial paper. arXiv preprint, arXiv:1604.08462.\n\n\n绘图：\n\nplot(mgm_net, layout = 'spring')\n\n\n\n\n\ncentralityPlot(mgm_net)\n\n\n\n\n重抽样，为了节约时间，这里仅抽样50次：\n\nset.seed(123)\nboot_results2 = bootnet(mgm_net, nBoots = 50,default = 'mgm',\n                         type = \"nonparametric\",nCores = 8)\n\nNote: bootnet will store only the following statistics:  edge, strength, outStrength, inStrength\n\n\nBootstrapping...\n\n\nComputing statistics...\n\n\n可以把数据存储起来，代码可以这样写的save(boot_results2, file = “mgm_boot_results2_mgm.RData”)，我这里就不运行了。\n然后，可以通过画图看看边缘估计的精确性：\n\nplot(boot_results2, labels=FALSE, order=\"sample\")\n\n\n\n\n部分边缘的95%CI还是有些宽的（阴影部分）。\n\n\n2.5 差异性分析\n\n\n2.5.1 中心性指标\n一般会检验强度中心性（Strength），下面的代码检验了各节点的Strength是否有显著差异。\n\n#  节点差异性检验  输出数值\nlibrary(tidyverse)\nres2 = summary(boot_results2) %&gt;% \n  ungroup %&gt;% \n  filter(type == \"edge\") %&gt;% \n  arrange(-sample)\nres2\n\n# A tibble: 21 × 17\n   type  id        node1 node2 sample   mean     sd CIlower CIupper   q2.5 q97.5\n   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 edge  IQ--Type… IQ    Type… 0.494  0.500  0.0303  0.433    0.555 0.423  0.559\n 2 edge  Integrat… Inte… No o… 0.315  0.333  0.0438  0.228    0.403 0.204  0.433\n 3 edge  Integrat… Inte… Sati… 0.314  0.315  0.0260  0.262    0.366 0.260  0.374\n 4 edge  Type of … Type… Work… 0.306  0.327  0.0365  0.233    0.378 0.241  0.391\n 5 edge  Gender--… Gend… Type… 0.300  0.329  0.0530  0.194    0.407 0.225  0.502\n 6 edge  IQ--Inte… IQ    Inte… 0.207  0.199  0.0396  0.127    0.286 0.0978 0.265\n 7 edge  Gender--… Gend… No o… 0.152  0.156  0.0395  0.0727   0.231 0.0205 0.245\n 8 edge  Integrat… Inte… Work… 0.148  0.199  0.0424  0.0627   0.232 0.133  0.307\n 9 edge  Integrat… Inte… Type… 0.0825 0.101  0.0262  0.0301   0.135 0.0423 0.162\n10 edge  Type of … Type… Sati… 0.0605 0.0598 0.0383 -0.0161   0.137 0      0.141\n# ℹ 11 more rows\n# ℹ 6 more variables: q2.5_non0 &lt;dbl&gt;, mean_non0 &lt;dbl&gt;, q97.5_non0 &lt;dbl&gt;,\n#   var_non0 &lt;dbl&gt;, sd_non0 &lt;dbl&gt;, prop0 &lt;dbl&gt;\n\n\n可视化看看，结论会更清晰。\n\n# 节点的两两比较，黑色表示显著\nplot(boot_results2, statistics=\"Strength\", plot=\"difference\",order = \"mean\")\n\nExpected significance level given number of bootstrap samples is approximately: 0.049\n\n\n\n\n\n如果你对此图的含义还不清楚，可以回看前面的\"横断面网络\"一节。\n\n\n2.5.2 边缘比较\n\nplot(boot_results2, \"edge\", plot = \"difference\", \n     onlyNonZero = TRUE, order = \"sample\")\n\nExpected significance level given number of bootstrap samples is approximately: 0.05\n\n\n\n\n\n\n\n2.6 稳定性分析\n与普通网络分析的方法类似，可以采用案例剔除法+bootstrap进行稳定性分析。bootnet提供了一个好用的接口，但此处需要额外调整下default。\n\ndrop_res = bootnet(mgm_net, nBoots = 100, default = \"mgm\", \n                  type=\"case\", statistics=\"all\",nCores = 12) #减轻计算负担\n\nBootstrapping...\n\n\nComputing statistics...\n\n\n求稳定性相关系数：\n\n#计算相关稳定性系数\ncorStability(drop_res) \n\n=== Correlation Stability Analysis === \n\nSampling levels tested:\n   nPerson Drop%  n\n1      880  75.0 10\n2     1154  67.2  9\n3     1428  59.4  9\n4     1702  51.7  8\n5     1976  43.9  8\n6     2250  36.1 14\n7     2523  28.3  4\n8     2797  20.6  9\n9     3071  12.8 18\n10    3345   5.0 11\n\nMaximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:\n\nbetweenness: 0.517 \n  - For more accuracy, run bootnet(..., caseMin = 0.439, caseMax = 0.594) \n\ncloseness: 0.517 \n  - For more accuracy, run bootnet(..., caseMin = 0.439, caseMax = 0.594) \n\ndistance: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\nedge: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\neigenvector: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\nexpectedInfluence: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\nhybrid: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\nlength: 0 \n  - For more accuracy, run bootnet(..., caseMin = 0, caseMax = 0.05) \n\nrspbc: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\nstrength: 0.75 (CS-coefficient is highest level tested)\n  - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) \n\nAccuracy can also be increased by increasing both 'nBoots' and 'caseN'.\n\n\n可以看到，几个重要的指标（强度、预期影响等）的相关稳定性系数都大于0.25，部分指标系数高达0.75，符合最低要求。\n绘图可能更为直观一点：\n\nplot(drop_res, statistics=\"all\")\n\n\n\n\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4    \n [5] purrr_1.0.2     readr_2.1.4     tidyr_1.3.1     tibble_3.2.1   \n [9] tidyverse_2.0.0 bootnet_1.6     ggplot2_3.5.0   qgraph_1.9.8   \n[13] mgm_1.2-14     \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3   rstudioapi_0.16.0    jsonlite_1.8.7      \n  [4] shape_1.4.6          magrittr_2.0.3       jomo_2.7-6          \n  [7] farver_2.1.1         nloptr_2.0.3         rmarkdown_2.25      \n [10] vctrs_0.6.4          minqa_1.2.6          heplots_1.6.0       \n [13] base64enc_0.1-3      htmltools_0.5.7      polynom_1.4-1       \n [16] plotrix_3.8-4        weights_1.0.4        broom_1.0.5         \n [19] Formula_1.2-5        mitml_0.4-5          htmlwidgets_1.6.2   \n [22] plyr_1.8.9           igraph_2.0.1.1       lifecycle_1.0.4     \n [25] iterators_1.0.14     pkgconfig_2.0.3      Matrix_1.6-5        \n [28] R6_2.5.1             fastmap_1.1.1        digest_0.6.33       \n [31] fdrtool_1.2.17       colorspace_2.1-0     Hmisc_5.1-1         \n [34] ellipse_0.5.0        labeling_0.4.3       fansi_1.0.5         \n [37] nnls_1.5             timechange_0.2.0     gdata_3.0.0         \n [40] abind_1.4-5          IsingSampler_0.2.3   compiler_4.3.2      \n [43] proxy_0.4-27         withr_2.5.2          doParallel_1.0.17   \n [46] glasso_1.11          htmlTable_2.4.2      backports_1.4.1     \n [49] carData_3.0-5        psych_2.3.9          R.utils_2.12.3      \n [52] pan_1.9              MASS_7.3-60          corpcor_1.6.10      \n [55] gtools_3.9.5         tools_4.3.2          pbivnorm_0.6.0      \n [58] foreign_0.8-85       nnet_7.3-19          R.oo_1.25.0         \n [61] glue_1.6.2           quadprog_1.5-8       NetworkToolbox_1.4.2\n [64] nlme_3.1-163         grid_4.3.2           checkmate_2.3.0     \n [67] cluster_2.1.4        reshape2_1.4.4       generics_0.1.3      \n [70] snow_0.4-4           gtable_0.3.4         tzdb_0.4.0          \n [73] R.methodsS3_1.8.2    class_7.3-22         data.table_1.15.4   \n [76] hms_1.1.3            car_3.1-2            utf8_1.2.4          \n [79] foreach_1.5.2        pillar_1.9.0         splines_4.3.2       \n [82] smacof_2.1-5         networktools_1.5.1   lattice_0.21-9      \n [85] survival_3.5-7       tidyselect_1.2.0     pbapply_1.7-2       \n [88] knitr_1.45           gridExtra_2.3        IsingFit_0.4        \n [91] stats4_4.3.2         xfun_0.41            stringi_1.8.1       \n [94] yaml_2.3.7           boot_1.3-28.1        evaluate_0.23       \n [97] codetools_0.2-19     wordcloud_2.6        cli_3.6.2           \n[100] rpart_4.1.21         munsell_0.5.0        lavaan_0.6-17       \n[103] candisc_0.8-6        Rcpp_1.0.11          png_0.1-8           \n[106] parallel_4.3.2       rgl_1.2.1            jpeg_0.1-10         \n[109] lme4_1.1-35.1        glmnet_4.1-8         mvtnorm_1.2-3       \n[112] scales_1.3.0         e1071_1.7-13         eigenmodel_1.11     \n[115] rlang_1.1.3          mnormt_2.1.1         mice_3.16.0"
  },
  {
    "objectID": "二分类变量网络分析.html",
    "href": "二分类变量网络分析.html",
    "title": "二分类变量的网络分析",
    "section": "",
    "text": "1 简介\n如果网络分析的对象是二元分类变量，那么就需要使用到一个叫做Ising的模型。Ising模型是描述由二分类变量组成的系统的一种概率模型。它假设系统中的每个节点（变量）只能取二值状态（例如，-1 或 +1，对应于我们常见的 0/1 编码），并通过一种邻接结构来描述这些变量的相互作用。\n\n节点（variables）：表示二分类变量，如某个人在某一特定时间点上的情绪是否为积极或消极，某一疾病症状是否存在，等等。\n边（edges）：表示两个二分类变量之间的相互作用，通常由条件依赖关系建模。\n配合外部场（external field）：描述每个变量单独的偏好或倾向。\n\nIsing模型的目标是捕捉这些变量之间的相互影响，并揭示它们的网络结构。\n说起来比较复杂，为了方便理解，你可以将其理解成一组logistic回归模型。\n\n\n2 R语言示例\n在 R 中，可以使用 IsingFit 或 mgm 包来拟合 Ising 模型，并分析二分类变量的网络结构。\n\n2.1 使用 IsingFit\n先导入包\n模拟一份数据，用于拟合网络模型。\n\nmyData = read.table('https://www.statmodel.com/usersguide/chap7/ex7.4.dat',col.names = c(\"x1\", \"x2\", \"x3\", \"x4\",\"other\"))\ndata = myData[,1:4]\nhead(data)\n\n  x1 x2 x3 x4\n1  0  1  0  1\n2  1  0  1  0\n3  0  0  1  1\n4  1  1  1  0\n5  1  1  1  0\n6  0  1  1  0\n\n\n拟合模型：\n\n# 拟合 Ising 模型\nfit = IsingFit(data, family = \"binomial\",plot = T)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n\n# 查看拟合结果\nprint(fit)\n\nEstimated network:\n      x1    x2    x3    x4\nx1  0.00  0.81 -0.74 -0.58\nx2  0.81  0.00 -0.50 -0.66\nx3 -0.74 -0.50  0.00  0.00\nx4 -0.58 -0.66  0.00  0.00\n\n\nEstimated Thresholds:\n       x1        x2        x3        x4 \n0.2732235 0.1802154 0.4938531 0.2786882 \n\n\n出来的图连线比较少，可能与随机模拟的数据本身有关。这个图与我们提取关系矩阵用qgraph画图是一样的\n\nqgraph(fit$weiadj,layout = 'spring')\n\n\n\n\n可以继续计算中心性：\n\ncentrality(fit$weiadj)\n\n$OutDegree\n      x1       x2       x3       x4 \n2.122048 1.963616 1.239084 1.233761 \n\n$InDegree\n      x1       x2       x3       x4 \n2.122048 1.963616 1.239084 1.233761 \n\n$Closeness\n       x1        x2        x3        x4 \n0.2310618 0.2099911 0.1552461 0.1576292 \n\n$Betweenness\nx1 x2 x3 x4 \n 2  0  0  0 \n\n$InExpectedInfluence\n        x1         x2         x3         x4 \n-0.5092286 -0.3507965 -1.2390835 -1.2337609 \n\n$OutExpectedInfluence\n        x1         x2         x3         x4 \n-0.5092286 -0.3507965 -1.2390835 -1.2337609 \n\n$ShortestPathLengths\n         x1       x2       x3       x4\nx1 0.000000 1.240065 1.352540 1.735242\nx2 1.240065 0.000000 2.001065 1.520977\nx3 1.352540 2.001065 0.000000 3.087782\nx4 1.735242 1.520977 3.087782 0.000000\n\n$ShortestPaths\n   x1   x2   x3   x4  \nx1 NULL NULL NULL NULL\nx2 NULL NULL NULL NULL\nx3 NULL NULL NULL NULL\nx4 NULL NULL NULL NULL\n\n\n绘制中心性图：\n\ncentralityPlot(fit$weiadj, \n               include=c(\"Strength\",'Closeness',\"Betweenness\"))\n\n\n\n\n\n\n2.2 使用mgm\n这个也是非常简单的，几行代码可以搞定：\n\n# 使用 mgm 包拟合 Ising 模型\n# 二分类变量用 type = \"c\" 表示 (category)\nfit_mgm = mgm(data = as.matrix(data), \n               type = rep(\"c\", 4), \n               level = rep(2, 4),  # 2 表示二分类变量\n               lambdaSel = \"EBIC\",  # 使用 EBIC 选择正则化参数\n               ruleReg = \"OR\")  # 使用 OR 规则连接\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |------------------                                                    |  25%\n  |                                                                            \n  |-----------------------------------                                   |  50%\n  |                                                                            \n  |----------------------------------------------------                  |  75%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\nNote that the sign of parameter estimates is stored separately; see ?mgm\n\n\n\n# 查看权重领接矩阵\nprint(fit_mgm$pairwise$wadj)\n\n          [,1]      [,2]       [,3]       [,4]\n[1,] 0.0000000 0.4032047 0.36967042 0.28814441\n[2,] 0.4032047 0.0000000 0.24986795 0.32873615\n[3,] 0.3696704 0.2498679 0.00000000 0.05342224\n[4,] 0.2881444 0.3287361 0.05342224 0.00000000\n\n\n可视化：\n\nqgraph(fit_mgm$pairwise$wadj,\n       edge.color = fit_mgm$pairwise$edgecolor,\n       layout = \"spring\",\n       labels =  autism_data$colnames)\n\nWarning in mapply(strwidth, s = labels, cex = ones): longer argument not a\nmultiple of length of shorter\n\n\nWarning in pmax(sapply(ones, function(x) strwidth(label.norm, cex = x)), : an\nargument will be fractionally recycled\n\n\nWarning in mapply(strheight, s = labels, cex = ones): longer argument not a\nmultiple of length of shorter\n\n\nWarning in pmax(sapply(ones, function(x) strheight(label.norm, cex = x)), : an\nargument will be fractionally recycled\n\n\nWarning in (VWidths * label.fill.horizontal)/LWidths: longer object length is\nnot a multiple of shorter object length\n\n\nWarning in (VHeights * label.fill.vertical)/LHeights: longer object length is\nnot a multiple of shorter object length\n\n\nWarning in label.cex * label.prop * pmin((VWidths *\nlabel.fill.horizontal)/LWidths, : longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n计算中心性：\n\ncentrality(fit_mgm$pairwise$wadj)\n\n$OutDegree\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$InDegree\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$Closeness\n[1] 0.11553048 0.10499573 0.07762275 0.07881444\n\n$Betweenness\n[1] 2 0 0 0\n\n$InExpectedInfluence\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$OutExpectedInfluence\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$ShortestPathLengths\n         [,1]     [,2]     [,3]     [,4]\n[1,] 0.000000 2.480130 2.705112 3.470482\n[2,] 2.480130 0.000000 4.002114 3.041953\n[3,] 2.705112 4.002114 0.000000 6.175594\n[4,] 3.470482 3.041953 6.175594 0.000000\n\n$ShortestPaths\n     [,1] [,2] [,3] [,4]\n[1,] NULL NULL NULL NULL\n[2,] NULL NULL NULL NULL\n[3,] NULL NULL NULL NULL\n[4,] NULL NULL NULL NULL\n\n\n绘制中心性：\n\ncentralityPlot(fit_mgm$pairwise$wadj,\n               include=c(\"Strength\",'ExpectedInfluence',\n                            'Closeness',\"Betweenness\"))\n\n\n\n\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] mgm_1.2-14   qgraph_1.9.8 IsingFit_0.4\n\nloaded via a namespace (and not attached):\n [1] shape_1.4.6       gtable_0.3.4      xfun_0.41         ggplot2_3.5.0    \n [5] htmlwidgets_1.6.2 psych_2.3.9       lattice_0.21-9    quadprog_1.5-8   \n [9] vctrs_0.6.4       tools_4.3.2       generics_0.1.3    stats4_4.3.2     \n[13] parallel_4.3.2    tibble_3.2.1      fansi_1.0.5       cluster_2.1.4    \n[17] pkgconfig_2.0.3   Matrix_1.6-5      data.table_1.15.4 checkmate_2.3.0  \n[21] lifecycle_1.0.4   farver_2.1.1      compiler_4.3.2    stringr_1.5.1    \n[25] munsell_0.5.0     mnormt_2.1.1      codetools_0.2-19  htmltools_0.5.7  \n[29] glasso_1.11       fdrtool_1.2.17    yaml_2.3.7        glmnet_4.1-8     \n[33] htmlTable_2.4.2   Formula_1.2-5     pillar_1.9.0      Hmisc_5.1-1      \n[37] iterators_1.0.14  rpart_4.1.21      abind_1.4-5       foreach_1.5.2    \n[41] nlme_3.1-163      lavaan_0.6-17     gtools_3.9.5      tidyselect_1.2.0 \n[45] digest_0.6.33     stringi_1.8.1     dplyr_1.1.4       reshape2_1.4.4   \n[49] labeling_0.4.3    splines_4.3.2     fastmap_1.1.1     grid_4.3.2       \n[53] colorspace_2.1-0  cli_3.6.2         magrittr_2.0.3    base64enc_0.1-3  \n[57] survival_3.5-7    utf8_1.2.4        pbivnorm_0.6.0    withr_2.5.2      \n[61] foreign_0.8-85    corpcor_1.6.10    scales_1.3.0      backports_1.4.1  \n[65] rmarkdown_2.25    jpeg_0.1-10       igraph_2.0.1.1    nnet_7.3-19      \n[69] gridExtra_2.3     png_0.1-8         pbapply_1.7-2     evaluate_0.23    \n[73] knitr_1.45        rlang_1.1.3       Rcpp_1.0.11       glue_1.6.2       \n[77] rstudioapi_0.16.0 jsonlite_1.8.7    R6_2.5.1          plyr_1.8.9"
  },
  {
    "objectID": "二分类变量网络分析.html#简介",
    "href": "二分类变量网络分析.html#简介",
    "title": "二分类变量的网络分析",
    "section": "",
    "text": "如果网络分析的对象是二元分类变量，那么就需要使用到一个叫做Ising的模型。Ising模型是描述由二分类变量组成的系统的一种概率模型。它假设系统中的每个节点（变量）只能取二值状态（例如，-1 或 +1，对应于我们常见的 0/1 编码），并通过一种邻接结构来描述这些变量的相互作用。\n\n节点（variables）：表示二分类变量，如某个人在某一特定时间点上的情绪是否为积极或消极，某一疾病症状是否存在，等等。\n边（edges）：表示两个二分类变量之间的相互作用，通常由条件依赖关系建模。\n配合外部场（external field）：描述每个变量单独的偏好或倾向。\n\nIsing模型的目标是捕捉这些变量之间的相互影响，并揭示它们的网络结构。\n说起来比较复杂，为了方便理解，你可以将其理解成一组logistic回归模型。"
  },
  {
    "objectID": "二分类变量网络分析.html#r语言示例",
    "href": "二分类变量网络分析.html#r语言示例",
    "title": "二分类变量的网络分析",
    "section": "2 R语言示例",
    "text": "2 R语言示例\n在 R 中，可以使用 IsingFit 或 mgm 包来拟合 Ising 模型，并分析二分类变量的网络结构。\n\n2.1 使用 IsingFit\n先导入包\n模拟一份数据，用于拟合网络模型。\n\nmyData = read.table('https://www.statmodel.com/usersguide/chap7/ex7.4.dat',col.names = c(\"x1\", \"x2\", \"x3\", \"x4\",\"other\"))\ndata = myData[,1:4]\nhead(data)\n\n  x1 x2 x3 x4\n1  0  1  0  1\n2  1  0  1  0\n3  0  0  1  1\n4  1  1  1  0\n5  1  1  1  0\n6  0  1  1  0\n\n\n拟合模型：\n\n# 拟合 Ising 模型\nfit = IsingFit(data, family = \"binomial\",plot = T)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n\n# 查看拟合结果\nprint(fit)\n\nEstimated network:\n      x1    x2    x3    x4\nx1  0.00  0.81 -0.74 -0.58\nx2  0.81  0.00 -0.50 -0.66\nx3 -0.74 -0.50  0.00  0.00\nx4 -0.58 -0.66  0.00  0.00\n\n\nEstimated Thresholds:\n       x1        x2        x3        x4 \n0.2732235 0.1802154 0.4938531 0.2786882 \n\n\n出来的图连线比较少，可能与随机模拟的数据本身有关。这个图与我们提取关系矩阵用qgraph画图是一样的\n\nqgraph(fit$weiadj,layout = 'spring')\n\n\n\n\n可以继续计算中心性：\n\ncentrality(fit$weiadj)\n\n$OutDegree\n      x1       x2       x3       x4 \n2.122048 1.963616 1.239084 1.233761 \n\n$InDegree\n      x1       x2       x3       x4 \n2.122048 1.963616 1.239084 1.233761 \n\n$Closeness\n       x1        x2        x3        x4 \n0.2310618 0.2099911 0.1552461 0.1576292 \n\n$Betweenness\nx1 x2 x3 x4 \n 2  0  0  0 \n\n$InExpectedInfluence\n        x1         x2         x3         x4 \n-0.5092286 -0.3507965 -1.2390835 -1.2337609 \n\n$OutExpectedInfluence\n        x1         x2         x3         x4 \n-0.5092286 -0.3507965 -1.2390835 -1.2337609 \n\n$ShortestPathLengths\n         x1       x2       x3       x4\nx1 0.000000 1.240065 1.352540 1.735242\nx2 1.240065 0.000000 2.001065 1.520977\nx3 1.352540 2.001065 0.000000 3.087782\nx4 1.735242 1.520977 3.087782 0.000000\n\n$ShortestPaths\n   x1   x2   x3   x4  \nx1 NULL NULL NULL NULL\nx2 NULL NULL NULL NULL\nx3 NULL NULL NULL NULL\nx4 NULL NULL NULL NULL\n\n\n绘制中心性图：\n\ncentralityPlot(fit$weiadj, \n               include=c(\"Strength\",'Closeness',\"Betweenness\"))\n\n\n\n\n\n\n2.2 使用mgm\n这个也是非常简单的，几行代码可以搞定：\n\n# 使用 mgm 包拟合 Ising 模型\n# 二分类变量用 type = \"c\" 表示 (category)\nfit_mgm = mgm(data = as.matrix(data), \n               type = rep(\"c\", 4), \n               level = rep(2, 4),  # 2 表示二分类变量\n               lambdaSel = \"EBIC\",  # 使用 EBIC 选择正则化参数\n               ruleReg = \"OR\")  # 使用 OR 规则连接\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |------------------                                                    |  25%\n  |                                                                            \n  |-----------------------------------                                   |  50%\n  |                                                                            \n  |----------------------------------------------------                  |  75%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\nNote that the sign of parameter estimates is stored separately; see ?mgm\n\n\n\n# 查看权重领接矩阵\nprint(fit_mgm$pairwise$wadj)\n\n          [,1]      [,2]       [,3]       [,4]\n[1,] 0.0000000 0.4032047 0.36967042 0.28814441\n[2,] 0.4032047 0.0000000 0.24986795 0.32873615\n[3,] 0.3696704 0.2498679 0.00000000 0.05342224\n[4,] 0.2881444 0.3287361 0.05342224 0.00000000\n\n\n可视化：\n\nqgraph(fit_mgm$pairwise$wadj,\n       edge.color = fit_mgm$pairwise$edgecolor,\n       layout = \"spring\",\n       labels =  autism_data$colnames)\n\nWarning in mapply(strwidth, s = labels, cex = ones): longer argument not a\nmultiple of length of shorter\n\n\nWarning in pmax(sapply(ones, function(x) strwidth(label.norm, cex = x)), : an\nargument will be fractionally recycled\n\n\nWarning in mapply(strheight, s = labels, cex = ones): longer argument not a\nmultiple of length of shorter\n\n\nWarning in pmax(sapply(ones, function(x) strheight(label.norm, cex = x)), : an\nargument will be fractionally recycled\n\n\nWarning in (VWidths * label.fill.horizontal)/LWidths: longer object length is\nnot a multiple of shorter object length\n\n\nWarning in (VHeights * label.fill.vertical)/LHeights: longer object length is\nnot a multiple of shorter object length\n\n\nWarning in label.cex * label.prop * pmin((VWidths *\nlabel.fill.horizontal)/LWidths, : longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n计算中心性：\n\ncentrality(fit_mgm$pairwise$wadj)\n\n$OutDegree\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$InDegree\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$Closeness\n[1] 0.11553048 0.10499573 0.07762275 0.07881444\n\n$Betweenness\n[1] 2 0 0 0\n\n$InExpectedInfluence\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$OutExpectedInfluence\n[1] 1.0610195 0.9818088 0.6729606 0.6703028\n\n$ShortestPathLengths\n         [,1]     [,2]     [,3]     [,4]\n[1,] 0.000000 2.480130 2.705112 3.470482\n[2,] 2.480130 0.000000 4.002114 3.041953\n[3,] 2.705112 4.002114 0.000000 6.175594\n[4,] 3.470482 3.041953 6.175594 0.000000\n\n$ShortestPaths\n     [,1] [,2] [,3] [,4]\n[1,] NULL NULL NULL NULL\n[2,] NULL NULL NULL NULL\n[3,] NULL NULL NULL NULL\n[4,] NULL NULL NULL NULL\n\n\n绘制中心性：\n\ncentralityPlot(fit_mgm$pairwise$wadj,\n               include=c(\"Strength\",'ExpectedInfluence',\n                            'Closeness',\"Betweenness\"))\n\n\n\n\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] mgm_1.2-14   qgraph_1.9.8 IsingFit_0.4\n\nloaded via a namespace (and not attached):\n [1] shape_1.4.6       gtable_0.3.4      xfun_0.41         ggplot2_3.5.0    \n [5] htmlwidgets_1.6.2 psych_2.3.9       lattice_0.21-9    quadprog_1.5-8   \n [9] vctrs_0.6.4       tools_4.3.2       generics_0.1.3    stats4_4.3.2     \n[13] parallel_4.3.2    tibble_3.2.1      fansi_1.0.5       cluster_2.1.4    \n[17] pkgconfig_2.0.3   Matrix_1.6-5      data.table_1.15.4 checkmate_2.3.0  \n[21] lifecycle_1.0.4   farver_2.1.1      compiler_4.3.2    stringr_1.5.1    \n[25] munsell_0.5.0     mnormt_2.1.1      codetools_0.2-19  htmltools_0.5.7  \n[29] glasso_1.11       fdrtool_1.2.17    yaml_2.3.7        glmnet_4.1-8     \n[33] htmlTable_2.4.2   Formula_1.2-5     pillar_1.9.0      Hmisc_5.1-1      \n[37] iterators_1.0.14  rpart_4.1.21      abind_1.4-5       foreach_1.5.2    \n[41] nlme_3.1-163      lavaan_0.6-17     gtools_3.9.5      tidyselect_1.2.0 \n[45] digest_0.6.33     stringi_1.8.1     dplyr_1.1.4       reshape2_1.4.4   \n[49] labeling_0.4.3    splines_4.3.2     fastmap_1.1.1     grid_4.3.2       \n[53] colorspace_2.1-0  cli_3.6.2         magrittr_2.0.3    base64enc_0.1-3  \n[57] survival_3.5-7    utf8_1.2.4        pbivnorm_0.6.0    withr_2.5.2      \n[61] foreign_0.8-85    corpcor_1.6.10    scales_1.3.0      backports_1.4.1  \n[65] rmarkdown_2.25    jpeg_0.1-10       igraph_2.0.1.1    nnet_7.3-19      \n[69] gridExtra_2.3     png_0.1-8         pbapply_1.7-2     evaluate_0.23    \n[73] knitr_1.45        rlang_1.1.3       Rcpp_1.0.11       glue_1.6.2       \n[77] rstudioapi_0.16.0 jsonlite_1.8.7    R6_2.5.1          plyr_1.8.9"
  },
  {
    "objectID": "网络分析基础及指标.html",
    "href": "网络分析基础及指标.html",
    "title": "网络分析基础及指标",
    "section": "",
    "text": "1 症状管理与症状科学\n症状管理是如今护理研究领域的热点之一，随着研究的深入，研究者对症状管理的关注点从既往的单一症状（symptom）、症状群（symptom cluster），逐渐转移到了症状网络层面。一些学者在此基础上提出了症状科学的概念，并进行了完善和补充。\n症状科学是一种新兴的方法，深入探索复杂症状及症状网络、表型特征、生物标志物，以及患者结局背后的生物学、病理生理学和／或基因组学的机制，可以帮助医护工作者更好地了解患者症状的相互作用机制，从而更好地制定更精准的干预。有关症状科学更为全面、准确的阐述，可以看看复旦大学胡雁教授的文章《症状科学的发展及研究趋势》。\n需要注意的是，症状网络分析只是症状科学研究的第一个环节。\n\n\n2 症状网络\n通俗理解症状网络，就是利用一种被称为网络分析的技术对诸多症状的关系（或者交互作用）进行计算并可视化。它通过计算一系列指标，让我们了解这些症状的成对关系，寻找核心症状，以便于后续对核心症状进行精准管理和控制。\n症状网络听起来有些”高大上”，但实则也只是网络分析在症状科学中的一种应用，这就意味着，症状网络并不局限于对症状进行分析，任何你感兴趣的研究变量（甚至量表条目），其实都可以将其加入网络，只不过是研究领域有所差异，比如症状网络倾向于分析症状（生理、心理），其他的可能是分析一些社会属性（社会网络分析）。\n所以说，如果你想要对症状网络有个更本质的了解，还需要从网络分析的相关知识学起，而不是拘泥于”症状”本身。\n\n\n3 网络分析基础\n\n\n3.1 网络结构\n节点（node）、边（edge）是最基础的网络结构。\n节点就是我们想要分析的变量，也可以是量表的条目，代入症状科学研究场景，每一个节点代表了每一种”症状”。\n边是两个节点之间的关系，连线越粗，关系越密切；颜色表示方向，一般是红色表示负向关系，蓝色表示正向关系，当然这个颜色是可以自己调节的。边分为有向和无向两种，下面就是一张用人格问卷数据拟合的横向网络图，其中的节点是人格问卷的条目，由于是横断面研究数据，所以这里的连线（边）是没有方向的。\n有的网络图还会有一个代表每个节点的可预测性的环，这个我们会在实战中进行演示。\n\n\n\n\n\n\n\n3.2 网络估计方法\n网络估计算法常根据数据的类型来选择，连续变量采用高斯图模型（GMM），二分类变量采用Ising 模型，不同数据类型混合的话采用混合图模型（MGM）。\n高斯图模型是最常见的图模型，是一种连续的概率图模型，要求数据服从多元正态分布，高斯图的称呼比较多且不统一，看文献时要根据实际情况去判断。\nIsing 模型本质是logistic回归，我看了些资料，发现其只能处理二分类变量，如果是多分类变量，则要使用mgm去估计。\n还有个需要注意的地方，就是我们需要指定数据的输入，即估计相关网络，还是偏相关网络。两者的区别可以通过百度查看，相关就是字面意思，偏相关是指控制了其他变量之后，两个变量之间的关系，在一些场景下，用后者可能更好，尤其是想要做因果推断的时候。\n个人认为，不同类型的网络的最大区别点就在于这个输入数据上面，比如大部分论文作者或者博主推荐使用的网络分析可视化函数（qgraph），是可以接受多种类型数据的。可以这么说，玩懂了这个输入数据，常用的网络分析方法差不多可以通吃了。\n\n\n3.3 相关指标\n做症状网络研究或者其他领域的网络分析，除了想要了解不同节点之间的关系之外，通常想要计算出哪些节点的影响力最大或者最重要。\n一些常用的算法会将比较重要的节点或者关联比较密切的节点对放在网络比较中心的位置，但不同算法下节点的位置可能有不同的含义，不能仅仅根据图的位置来判断重要的节点，所以需要结合一些特异性指标来判断，例如节点指标（中心性）、网络层面指标，以及准确性、稳定性、差异性分析等。\n3.3.1 节点指标\n节点指标包括中心性、预期影响系数、可预测性等。\n①中心性指标可以用于量化节点的重要程度，数值越大代表节点在整个网络中的重要性越高，包括强度（strength）、紧密性（closeness） 、 中介（betweenness）三种。\n强度中心性：与一个节点相连所有边的权重之和，是最重要的中心性指标。\n紧密中心性：一个节点到达网络中所有其他节点的最短路径的平均长度的倒数，这个用得不多。\n中介中心性：一个节点在网络中所有最短路径中出现的频率，这个用得不多。\n②预期影响系数：是一种类似强度中心性的量化节点影响力的指标，同时考虑正负相关，这个用得多。\n③可预测性：节点受其他节点影响的程度，本质是回归分析中的R2，这个用得多。\n3.3.2 准确性、稳定性、差异性分析\n仅一次网络估计是很难说得到的网络是否科学的，所以需要通过bootstrap（自助重抽样）方法对其进行准确性、稳定性检验，根据研究目的可能还会对各节点和边进行差异性分析。\n①准确性分析通常是针对边（edge）权重的，通过计算95%CI来判断其准确性，当然这里不是通过是否包含0来判断，而是根据其CI是”宽”还是”窄”来判断。bootstrap法分为参数bootstrap或者非参数bootstrap，顾名思义，前者是对估计出来的参数进行重抽样，后者是对原数据进行重抽样。在网络分析中，通常选择非参数bootstrap。\n②稳定性分析有点类似于我们做临床研究时的敏感性分析，这里通常会采用剔除法评估中心性指标的稳定性，包括case剔除以及node剔除。通常不会选择节点剔除，因为我们不知道哪个节点是重要的。case剔除就是减少样本量，通过不断重复计算中心性，然后估计相关稳定性系数（CS系数，即保留70%相关性时最大可以剔除的案例比例）来评估稳定程度。一般要求CS&gt;0.5，最小不能低于0.25。\n③差异性分析：得到一份准确、稳定的网络之后，我们可能对一些核心节点（症状）、边进行比较，同样的是采用bootstrap法，通过重抽样构建指标的置信区间（与0比较）进行判断。\n值得注意的是，不同的网络也是可以比较的，比如要分析性别对某个症状网络的影响，除了把它当做协变量纳入之外，还可以尝试分别构建男性网络和女性网络，然后采用统计检验的方法进行比较（NCT）。NCT分别检验了3种假设：结构不变性、强度不变性和边不变性。这个同样会在后续的内容中进行实战演示。\n3.3.3 网络层面指标\n包括网络密度（density）和连通性（Connectivity）。\n①网络密度代表了网络中实际存在的连接（边）与所有可能的连接（边）之间的比例。网络密度可以被视为网络的”紧密程度”或”联结程度”的指标。范围是0-1，单一使用的作用一般不大。\n②网络连通性描述了网络中节点之间的相互连接程度，在症状网络中，高连通性意味着症状彼此容易影响。\n\n\n3.4 症状网络常见分类\n分类是需要参照物的，当考虑的角度不同时，可能会有多种不同的分类方法。所以症状网络的类型说不准的。\n按照复旦大学朱政教授研究团队的分类：症状网络可以分为同期网络、动态网络、个体化网络（根据数据类型）。其提到同期网络用于横断面研究，但其实向量自回归模型也可以分解出同期网络模型来。动态网络定义也过于宽泛。\n我个人推荐根据研究设计和算法来分：横断面网络、纵向网络；纵向网络根据算法的不同可能还可以细分为交叉滞后网络模型、时变向量自回归网络，等等。这些模型采取的算法与前面提到的可能有些差异，会分散在实战中进行解释。\n\n\n4 建议\n症状网络对我们从生理学机制解读疾病症状、开展精准护理很有帮助，有助于理解多因多果，发展很快，从横向发展到了纵向。\n症状网络分析的本质是网络分析，通常涉及到数据类型、统计方法、相关指标的选择和计算。目前仅针对症状网络的教程不多，所以如果你有这方面的进阶需求，强烈建议从网络分析入手。"
  },
  {
    "objectID": "样本量估算.html",
    "href": "样本量估算.html",
    "title": "样本量估算",
    "section": "",
    "text": "敬请期待！"
  },
  {
    "objectID": "协变量处理方法.html",
    "href": "协变量处理方法.html",
    "title": "协变量处理方法",
    "section": "",
    "text": "敬请期待！"
  },
  {
    "objectID": "横断面网络完整版.html",
    "href": "横断面网络完整版.html",
    "title": "横断面网络",
    "section": "",
    "text": "从这节开始，将分段演示如何采用R软件进行各种网络分析建模，主要内容请见右上角的目录。\n为避免出现版本兼容性问题，大家可以先看看我使用的编程环境（见文末）。\n\n1 导入工具包\n依次导入下面六个包，第一个和第六个包是辅助包，提供了一些不错的工具；第二个是本期分析主要使用的包，第三个包提供了一些本次会用到的数据，第四个第五个是非常关键的包，包括但不限于用于计算稳定性和可预测性。\n如果你还没安装，请先执行被注释掉的”install.packages”语句。\n\n\n2 整理数据\n这里使用的是bfi人格问卷数据，这份数据是R语言内置的公开数据集。具体细节请使用?psych::bfi查询。\n网络分析比较吃硬件资源，所以这次我们仅选取少量数据进行分析：500x15，即500人，15个条目。\n\nmd = bfi[1:500,1:15] \nstr(md)\n\n'data.frame':   500 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 4 2 ...\n $ A2: int  4 4 4 4 3 6 5 3 3 5 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 6 ...\n $ A4: int  4 2 4 5 4 6 3 5 3 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 3 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 6 ...\n $ C2: int  3 4 5 4 4 6 4 2 6 5 ...\n $ C3: int  3 4 4 3 5 6 4 4 3 6 ...\n $ C4: int  4 3 2 5 3 1 2 2 4 2 ...\n $ C5: int  4 4 5 5 2 3 3 4 5 1 ...\n $ E1: int  3 1 2 5 2 2 4 3 5 2 ...\n $ E2: int  3 1 4 3 2 1 3 6 3 2 ...\n $ E3: int  3 6 4 4 5 6 4 4 NA 4 ...\n $ E4: int  4 4 4 4 4 5 5 2 4 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 3 5 ...\n\nhead(md)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6\n\n\n由于横断面网络分析不能有缺失值，所以来个简单处理：剔除有缺失值的行。\n\nmd=na.omit(md)\nstr(md)\n\n'data.frame':   468 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 2 4 ...\n $ A2: int  4 4 4 4 3 6 5 3 5 4 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 5 ...\n $ A4: int  4 2 4 5 4 6 3 5 6 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 5 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 4 ...\n $ C2: int  3 4 5 4 4 6 4 2 5 3 ...\n $ C3: int  3 4 4 3 5 6 4 4 6 5 ...\n $ C4: int  4 3 2 5 3 1 2 2 2 3 ...\n $ C5: int  4 4 5 5 2 3 3 4 1 2 ...\n $ E1: int  3 1 2 5 2 2 4 3 2 1 ...\n $ E2: int  3 1 4 3 2 1 3 6 2 3 ...\n $ E3: int  3 6 4 4 5 6 4 4 4 2 ...\n $ E4: int  4 4 4 4 4 5 5 2 5 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 5 4 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:32] 9 63 66 72 90 107 112 130 133 168 ...\n  ..- attr(*, \"names\")= chr [1:32] \"61630\" \"61754\" \"61759\" \"61772\" ...\n\n\n\n\n3 可视化网络模型\n一般有如下几个步骤：计算相关或者偏相关矩阵；分配组（可以是症状群，可以不用）；建模并可视化。\n\n# 计算相关矩阵\nCorMat=cor_auto(md)\n\nVariables detected as ordinal: A1; A2; A3; A4; A5; C1; C2; C3; C4; C5; E1; E2; E3; E4; E5\n\n# 模拟分组向量，具体请根据自己的研究来\ngroups=c(rep('A',5),rep('C',5),rep('E',5))\n\n# 默认参数建模\nq = qgraph(CorMat,#相关矩阵\n           layout = \"spring\",#图形布局算法\n           groups=groups, #分组信息\n           details = TRUE, #显示细节\n           theme='colorblind'#主题\n           ) \n\n\n\n\n也可以不分组，看看效果。\n\nq1 = qgraph(CorMat,#相关矩阵\n           layout = \"spring\",#图形布局算法\n           details = TRUE, #显示细节\n           theme='colorblind'#主题\n           ) \n\n\n\n\n你觉得图形不好看，自己根据函数的帮助文档自己调整参数。\n\n\n4 另一种建模方法\n发现了吗？横断面网络模型（同期网络）的建模和可视化是非常简单的，我一般喜欢用bootnet建模，当然了，由于设置的算法不同，这两者所得网络是有区别的，择其一即可。\n这里我们使用强大的bootnet包，等下我们做稳定性、准确性分析都会用到它。\n建模一行代码搞定，用默认参数问题不大。\n\n# Estimate network\n# 这里输入的是原始数据，采用EBICglasso算法计算输入矩阵\nNetwork = estimateNetwork(md, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\n# plot network\nplot(Network, layout = 'spring')\n\n\n\n\n\n\n5 计算中心性指标\n计算第一个网络模型的中心性指标，很轻松。\n\ncentrality(q)\n\n$OutDegree\n      A1       A2       A3       A4       A5       C1       C2       C3 \n1.736067 4.136744 4.185174 3.459108 4.588298 3.147499 3.386425 2.647192 \n      C4       C5       E1       E2       E3       E4       E5 \n3.196841 3.106400 3.266836 4.002216 3.672419 4.181569 4.352452 \n\n$InDegree\n      A1       A2       A3       A4       A5       C1       C2       C3 \n1.736067 4.136744 4.185174 3.459108 4.588298 3.147499 3.386425 2.647192 \n      C4       C5       E1       E2       E3       E4       E5 \n3.196841 3.106400 3.266836 4.002216 3.672419 4.181569 4.352452 \n\n$Closeness\n        A1         A2         A3         A4         A5         C1         C2 \n0.01208905 0.01777845 0.01795918 0.01719543 0.01914391 0.01475588 0.01595325 \n        C3         C4         C5         E1         E2         E3         E4 \n0.01410542 0.01470529 0.01454764 0.01626079 0.01859869 0.01815438 0.01818626 \n        E5 \n0.02126792 \n\n$Betweenness\nA1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 \n 0 18  0  2  2  0  4  0  0  0  0  2  0  2 42 \n\n$InExpectedInfluence\n        A1         A2         A3         A4         A5         C1         C2 \n-1.0911530  1.6851506  1.9382873  1.6382411  1.9301633  0.8583539  1.4462001 \n        C3         C4         C5         E1         E2         E3         E4 \n 1.1753135 -1.2361655 -1.3086316 -1.6998553 -1.9861568  1.5919209  1.5421715 \n        E5 \n 1.4202353 \n\n$OutExpectedInfluence\n        A1         A2         A3         A4         A5         C1         C2 \n-1.0911530  1.6851506  1.9382873  1.6382411  1.9301633  0.8583539  1.4462001 \n        C3         C4         C5         E1         E2         E3         E4 \n 1.1753135 -1.2361655 -1.3086316 -1.6998553 -1.9861568  1.5919209  1.5421715 \n        E5 \n 1.4202353 \n\n$ShortestPathLengths\n         A1       A2       A3       A4       A5       C1       C2       C3\nA1 0.000000 2.192380 3.519328 4.767491 4.025087 7.422075 8.220801 7.501337\nA2 2.192380 0.000000 1.821282 2.575111 2.114002 5.229695 6.028421 5.308957\nA3 3.519328 1.821282 0.000000 2.729549 1.723567 5.757156 5.666207 5.070742\nA4 4.767491 2.575111 2.729549 0.000000 2.514570 5.766440 3.539533 5.569323\nA5 4.025087 2.114002 1.723567 2.514570 0.000000 6.398416 5.521765 6.701127\nC1 7.422075 5.229695 5.757156 5.766440 6.398416 0.000000 2.226907 2.892613\nC2 8.220801 6.028421 5.666207 3.539533 5.521765 2.226907 0.000000 2.236184\nC3 7.501337 5.308957 5.070742 5.569323 6.701127 2.892613 2.236184 0.000000\nC4 7.325279 6.213435 6.957908 5.724084 6.002827 2.455908 2.184551 3.045985\nC5 8.878911 6.859716 6.005458 4.284605 4.853824 3.886195 3.328085 2.940947\nE1 6.292386 4.100005 4.166015 5.008539 3.107798 6.214881 5.338229 6.517591\nE2 6.476632 4.284251 3.228590 4.074237 2.484376 4.568518 4.887529 6.066891\nE3 5.225746 3.033365 2.739891 4.427392 2.241199 5.879803 5.003151 6.182513\nE4 5.051349 2.858969 2.619437 2.938715 1.825769 5.394177 5.701641 6.881003\nE5 5.820650 3.628270 3.676697 4.235405 2.721615 3.676801 2.800149 3.979511\n         C4       C5       E1       E2       E3       E4       E5\nA1 7.325279 8.878911 6.292386 6.476632 5.225746 5.051349 5.820650\nA2 6.213435 6.859716 4.100005 4.284251 3.033365 2.858969 3.628270\nA3 6.957908 6.005458 4.166015 3.228590 2.739891 2.619437 3.676697\nA4 5.724084 4.284605 5.008539 4.074237 4.427392 2.938715 4.235405\nA5 6.002827 4.853824 3.107798 2.484376 2.241199 1.825769 2.721615\nC1 2.455908 3.886195 6.214881 4.568518 5.879803 5.394177 3.676801\nC2 2.184551 3.328085 5.338229 4.887529 5.003151 5.701641 2.800149\nC3 3.045985 2.940947 6.517591 6.066891 6.182513 6.881003 3.979511\nC4 0.000000 1.956734 5.819291 5.368590 5.484213 6.182702 3.281211\nC5 1.956734 0.000000 6.006993 4.300280 5.671915 6.297076 3.468913\nE1 5.819291 6.006993 0.000000 1.768919 2.549088 2.069824 2.538080\nE2 5.368590 4.300280 1.768919 0.000000 2.174253 1.996796 2.087379\nE3 5.484213 5.671915 2.549088 2.174253 0.000000 2.267609 2.203002\nE4 6.182702 6.297076 2.069824 1.996796 2.267609 0.000000 2.901491\nE5 3.281211 3.468913 2.538080 2.087379 2.203002 2.901491 0.000000\n\n$ShortestPaths\n   A1   A2   A3   A4   A5   C1   C2   C3   C4   C5   E1   E2   E3   E4   E5  \nA1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA2 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA3 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA4 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nA5 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC2 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC3 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC4 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nC5 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE2 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE3 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE4 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\nE5 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL\n\n\n强度中心性报告了OutDegree与InDegree，但由于是横断面网络模型，所以它们是一样的，在有向图模型中，它们就会有差异了。\n可视化中心性指标：\n\ncentralityPlot(q, include=c(\"Strength\",\n                            'ExpectedInfluence',\n                            'Closeness',\n                            \"Betweenness\"))\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n由于没有进行标准化处理，所以有些指标的x轴刻度范围有些大。可以加一个scale参数进行控制。\n\ncentralityPlot(q, include=c(\"Strength\",\n                            'ExpectedInfluence',\n                            'Closeness',\n                            \"Betweenness\"),\n                            scale = \"z-scores\")\n\nNote: z-scores are shown on x-axis rather than raw centrality indices.\n\n\n\n\n\n\n\n6 桥梁节点分析\n在网络分析中，桥梁节点（Bridge Node）是指那些在不同社区或群组之间起到连接作用的节点。它们在网络中扮演着沟通不同群体的关键角色。桥梁节点的概念有助于识别那些在网络中可能对信息流通和群体间联系至关重要的节点。\n桥梁节点（桥梁症状）的识别通常涉及到计算所谓的”桥梁中心性”（Bridge Centrality），这是一种网络分析中用来识别节点在不同社区或群体间重要性的指标，同样包括3种：桥梁强度、桥梁紧密度、桥梁中介性。桥梁中心性可以通过不同的方法来计算，这里就不展开描述了。\n桥梁中心性的计算用代码很容易搞定：\n\nbridge(CorMat, communities= groups, directed=FALSE)\n\n$`Bridge Strength`\n       A1        A2        A3        A4        A5        C1        C2        C3 \n0.6192786 2.2701858 2.4054126 2.1786558 2.8889458 1.6882345 1.7319479 1.1859660 \n       C4        C5        E1        E2        E3        E4        E5 \n1.4925433 1.6975235 1.4320906 1.9970992 1.9252748 2.4119903 2.6808076 \n\n$`Bridge Betweenness`\nA1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 \n28  0  0  0  0  0  1  0 24  0  0  1  0  0 39 \n\n$`Bridge Closeness`\n        A1         A2         A3         A4         A5         C1         C2 \n0.06040055 0.06449706 0.06464877 0.06334587 0.06633877 0.07740360 0.08148539 \n        C3         C4         C5         E1         E2         E3         E4 \n0.07593488 0.04662243 0.04377595 0.03678090 0.03806534 0.09428918 0.09357638 \n        E5 \n0.10564254 \n\n$`Bridge Expected Influence (1-step)`\n         A1          A2          A3          A4          A5          C1 \n 0.02563498  0.73084283  0.72681593  0.61394087  0.72769426  0.72809473 \n         C2          C3          C4          C5          E1          E2 \n 1.30818928  1.05074235 -0.55397879 -0.92186642 -0.99574380 -1.11167378 \n         E3          E4          E5 \n 1.54922696  1.74046318  1.49472703 \n\n$`Bridge Expected Influence (2-step)`\n       A1        A2        A3        A4        A5        C1        C2        C3 \n-1.003904  2.697975  2.833111  2.472744  2.982608  4.686390  5.172403  4.114575 \n       C4        C5        E1        E2        E3        E4        E5 \n-4.503411 -4.723141 -5.295025 -6.277542  6.184953  6.796393  6.512929 \n\n$communities\n [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"C\" \"C\" \"C\" \"C\" \"C\" \"E\" \"E\" \"E\" \"E\" \"E\"\n\n\n不但给出了3个桥梁中心性指标，还给出了预期影响（一步法、两步法都有）。可视化也是很容易的：\n\n#可视化桥梁症状网络\nb = bridge(CorMat, communities= groups, directed=F) \nplot(b, \n     include=c(\"Bridge Expected Influence (2-step)\", \"Bridge Strength\", \"Bridge Closeness\"), #选择要呈现的指标\n     theme_bw=F, \n     raw0 = T, \n     signed=T,\n     zscore=T,     #标准化\n     order=\"value\"  #排序\n     ) \n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\nVectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\nVectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n\n\n\n看到一些研究者在文献中推荐用桥梁强度最大的节点作为桥梁节点，但也有文献认为应使用第80百分位数的桥梁强度/预期影响截止值选择桥梁症状。这里演示下如何用桥梁强度查询符合条件的节点。\n\nchoose_set = b$`Bridge Strength`&gt;quantile(b$`Bridge Strength`,\n                             probs = 0.8,\n                             na.rm = T)\nnode_name = b$`Bridge Strength`[choose_set]\nnode_name\n\n      A5       E4       E5 \n2.888946 2.411990 2.680808 \n\n\n可以看到，15个症状节点里面，有3个症状符合条件。如果你需要对其进行可视化，可以先标记出来，然后将其传入qgraph函数的groups参数。\n\n\n7 计算可预测性\n有些学者不推荐在同期/横断面网络分析中计算可预测性，但个人认为这是个不错的指标，相当于做了很多次回归分析，可以分析其他变量对节点的影响。计算方法其实很简单，这里演示下如何进行计算并对其进行可视化。\n用mgm包建模：\n\n# mgm需要输入矩阵形式的数据，所以先做转换\nmat_data = as.matrix(md)\n\n# 建模，参数调整的细节请看帮助文档，在后续的混合建模中也会讲到\npre_mod = mgm(data = mat_data,\n                   type = rep('g',15),\n                   level = rep(1,15),\n                   lambdaSel = \"CV\",\n                   ruleReg = \"AND\", \n                   # pbar = T, \n                   overparameterize = F, \n                   signInfo = F)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |-----                                                                 |   7%\n  |                                                                            \n  |---------                                                             |  13%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |-------------------                                                   |  27%\n  |                                                                            \n  |-----------------------                                               |  33%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |---------------------------------                                     |  47%\n  |                                                                            \n  |-------------------------------------                                 |  53%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |-----------------------------------------------                       |  67%\n  |                                                                            \n  |---------------------------------------------------                   |  73%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |-------------------------------------------------------------         |  87%\n  |                                                                            \n  |-----------------------------------------------------------------     |  93%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\n\n\n速度是很快的，建模后通过预测函数提取可预测性值：\n\npred_mgm = predict(object = pre_mod, \n                    data = mat_data,\n                    errorCon = c(\"R2\"))\npred_mgm$errors\n\n   Variable    R2\n1        A1 0.198\n2        A2 0.402\n3        A3 0.378\n4        A4 0.228\n5        A5 0.444\n6        C1 0.243\n7        C2 0.356\n8        C3 0.262\n9        C4 0.350\n10       C5 0.280\n11       E1 0.334\n12       E2 0.420\n13       E3 0.328\n14       E4 0.405\n15       E5 0.357\n\n\n有兴趣的话，你也可以对这个值进行排序。由于本节内容很多，就不展示具体操作了。\n接下来，建立网络模型并绘制带有可预测性值的网络图：\n\nNetwork2 = estimateNetwork(mat_data, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\nplot(Network2,\n     layout = \"spring\",\n     pie=pred_mgm$errors[,2]\n     )\n\n\n\n\n\n\n8 精确性、稳定性、差异性分析\nok，接下来就该进行精确性、稳定性以及差异性分析了，由于涉及到重抽样，这个步骤需要花费一些时间，具体看你的电脑配置，演示时会尽量减少抽样次数。\n我们继续用bootnet包进行分析：\n\nbaseboot = bootnet(md, \n                  default = \"EBICglasso\", \n                  threshold = FALSE,\n                  type=\"nonparametric\", #选择非参数自举法\n                  nCores = 8, #8线程，根据自己电脑配置来\n                  statistics=\"all\",\n                  nBoots=500 \n) \n\nEstimating sample network...\n\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\n\nBootstrapping...\n\n\nComputing statistics...\n\n\n\n注意：nBoots默认为1000，为提高速度，这里减少了次数，真实研究至少1000次以上。\n\n绘制边缘权重精确性分析图：\n\nplot(baseboot, labels=FALSE, order=\"sample\") #默认绘制的统计量是edge\n\n\n\n\n这个置信区间（阴影部分）还是有些宽的。绘制边缘权重差异性分析图：\n\nplot(baseboot,\n     statistics='edge',\n     plot = \"difference\", \n     onlyNonZero = T, \n     order = \"sample\")\n\nExpected significance level given number of bootstrap samples is approximately: 0.05\n\n\n\n\n\n你是否会困惑：怎么看这幅图？答案是看黑格子数，黑色方格表示的是有两条边之间有显著差异，由于上面已经写了排序的代码，所以直接看y轴就可以了，越高的位置表示此edge与越多的其余edge有显著差异。这个例子，C4-C5与和E1-E2的边缘权重与其他有显著差别。\n同样，可以检验不同节点中心性之间的差异：\n\nplot(baseboot, statistics=\"Strength\", plot=\"difference\",order = \"mean\")\n\nExpected significance level given number of bootstrap samples is approximately: 0.049\n\n\n\n\n\n解释方法同前。上面是图形展示，当然是可以直接计算数值的，这里就不展示了，有需求的话，可以通过护理统计随笔公众号或者微信留言，会考虑通过更新的方式进行补充。\n中心性指标的稳定性也是可以通过bootnet进行计算：\n\n# 采用剔除案例法\ncaseboot = bootnet(md, \n                   nBoots = 500, \n                   nCores = 12, \n                   threshold = FALSE, \n                   default = \"EBICglasso\", \n                   type=\"case\", \n                   statistics=\"all\",\n                   verbose = F)\n\n\n注意：nBoots默认为1000，为提高速度，这里减少了次数，真实研究至少1000次以上。\n\n计算相关稳定性系数CS：\n\ncorStability(caseboot) \n\n=== Correlation Stability Analysis === \n\nSampling levels tested:\n   nPerson Drop%  n\n1      117  75.0 60\n2      153  67.3 47\n3      190  59.4 54\n4      226  51.7 44\n5      263  43.8 50\n6      299  36.1 52\n7      335  28.4 63\n8      372  20.5 34\n9      408  12.8 51\n10     445   4.9 45\n\nMaximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:\n\nbetweenness: 0.205 \n  - For more accuracy, run bootnet(..., caseMin = 0.128, caseMax = 0.284) \n\ncloseness: 0.284 \n  - For more accuracy, run bootnet(..., caseMin = 0.205, caseMax = 0.361) \n\ndistance: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nedge: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\neigenvector: 0.517 \n  - For more accuracy, run bootnet(..., caseMin = 0.438, caseMax = 0.594) \n\nexpectedInfluence: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nhybrid: 0.438 \n  - For more accuracy, run bootnet(..., caseMin = 0.361, caseMax = 0.517) \n\nlength: 0 \n  - For more accuracy, run bootnet(..., caseMin = 0, caseMax = 0.049) \n\nrspbc: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nstrength: 0.594 \n  - For more accuracy, run bootnet(..., caseMin = 0.517, caseMax = 0.673) \n\nAccuracy can also be increased by increasing both 'nBoots' and 'caseN'.\n\n\n绘图:\n\nplot(caseboot, statistics=\"all\")\n\n\n\n\n选几个指标来绘图：\n\nplot(caseboot, statistics = c(\"Strength\",\"Closeness\",\n                             \"expectedInfluence\"))\n\n\n\n\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] networktools_1.5.1 mgm_1.2-14         bootnet_1.6        ggplot2_3.5.0     \n[5] psych_2.3.9        qgraph_1.9.8       psychTools_2.4.3  \n\nloaded via a namespace (and not attached):\n  [1] mnormt_2.1.1         pbapply_1.7-2        polynom_1.4-1       \n  [4] gridExtra_2.3        fdrtool_1.2.17       rlang_1.1.3         \n  [7] magrittr_2.0.3       e1071_1.7-13         compiler_4.3.2      \n [10] gdata_3.0.0          IsingSampler_0.2.3   png_0.1-8           \n [13] vctrs_0.6.4          reshape2_1.4.4       quadprog_1.5-8      \n [16] stringr_1.5.1        pkgconfig_2.0.3      shape_1.4.6         \n [19] fastmap_1.1.1        backports_1.4.1      labeling_0.4.3      \n [22] pbivnorm_0.6.0       utf8_1.2.4           rmarkdown_2.25      \n [25] NetworkToolbox_1.4.2 heplots_1.6.0        nloptr_2.0.3        \n [28] purrr_1.0.2          xfun_0.41            glmnet_4.1-8        \n [31] jomo_2.7-6           jsonlite_1.8.7       pan_1.9             \n [34] jpeg_0.1-10          broom_1.0.5          parallel_4.3.2      \n [37] lavaan_0.6-17        cluster_2.1.4        R6_2.5.1            \n [40] stringi_1.8.1        RColorBrewer_1.1-3   smacof_2.1-5        \n [43] car_3.1-2            boot_1.3-28.1        rpart_4.1.21        \n [46] Rcpp_1.0.11          iterators_1.0.14     knitr_1.45          \n [49] snow_0.4-4           base64enc_0.1-3      R.utils_2.12.3      \n [52] weights_1.0.4        Matrix_1.6-5         nnls_1.5            \n [55] splines_4.3.2        nnet_7.3-19          igraph_2.0.1.1      \n [58] tidyselect_1.2.0     rstudioapi_0.16.0    abind_1.4-5         \n [61] yaml_2.3.7           doParallel_1.0.17    codetools_0.2-19    \n [64] lattice_0.21-9       tibble_3.2.1         plyr_1.8.9          \n [67] withr_2.5.2          evaluate_0.23        foreign_0.8-85      \n [70] survival_3.5-7       proxy_0.4-27         pillar_1.9.0        \n [73] carData_3.0-5        mice_3.16.0          checkmate_2.3.0     \n [76] foreach_1.5.2        rtf_0.4-14.1         stats4_4.3.2        \n [79] IsingFit_0.4         ellipse_0.5.0        generics_0.1.3      \n [82] candisc_0.8-6        munsell_0.5.0        scales_1.3.0        \n [85] minqa_1.2.6          gtools_3.9.5         class_7.3-22        \n [88] glue_1.6.2           Hmisc_5.1-1          tools_4.3.2         \n [91] data.table_1.15.4    lme4_1.1-35.1        mvtnorm_1.2-3       \n [94] rgl_1.2.1            grid_4.3.2           plotrix_3.8-4       \n [97] tidyr_1.3.1          colorspace_2.1-0     nlme_3.1-163        \n[100] htmlTable_2.4.2      eigenmodel_1.11      Formula_1.2-5       \n[103] cli_3.6.2            fansi_1.0.5          dplyr_1.1.4         \n[106] corpcor_1.6.10       glasso_1.11          gtable_0.3.4        \n[109] R.methodsS3_1.8.2    digest_0.6.33        wordcloud_2.6       \n[112] farver_2.1.1         htmlwidgets_1.6.2    htmltools_0.5.7     \n[115] R.oo_1.25.0          lifecycle_1.0.4      mitml_0.4-5         \n[118] MASS_7.3-60"
  },
  {
    "objectID": "不同网络比较.html",
    "href": "不同网络比较.html",
    "title": "网络比较",
    "section": "",
    "text": "这节内容不多，介绍并演示如何采用R软件进行不同网络的比较，主要内容请见右上角的目录。\n为避免出现版本兼容性问题，大家可以先看看我使用的编程环境（见文末）。\n\n1 导入工具包\n分别需要以下R包，没有安装的请先安装，安装方法见上一节。\n\n\n2 整理数据\n这里使用的是bfi人格问卷数据，这份数据是R语言内置的公开数据集。具体细节请使用?psych::bfi查询。\n网络分析比较吃硬件资源，所以这次我们仅选取少量数据进行分析：500x15，即500人，15个条目。\n\nmd = bfi[1:500,1:15] \nstr(md)\n\n'data.frame':   500 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 4 2 ...\n $ A2: int  4 4 4 4 3 6 5 3 3 5 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 6 ...\n $ A4: int  4 2 4 5 4 6 3 5 3 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 3 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 6 ...\n $ C2: int  3 4 5 4 4 6 4 2 6 5 ...\n $ C3: int  3 4 4 3 5 6 4 4 3 6 ...\n $ C4: int  4 3 2 5 3 1 2 2 4 2 ...\n $ C5: int  4 4 5 5 2 3 3 4 5 1 ...\n $ E1: int  3 1 2 5 2 2 4 3 5 2 ...\n $ E2: int  3 1 4 3 2 1 3 6 3 2 ...\n $ E3: int  3 6 4 4 5 6 4 4 NA 4 ...\n $ E4: int  4 4 4 4 4 5 5 2 4 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 3 5 ...\n\nhead(md)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6\n\n\n由于横断面网络分析不能有缺失值，所以剔除有缺失值的行。\n\nmd=na.omit(md) \nstr(md)\n\n'data.frame':   468 obs. of  15 variables:\n $ A1: int  2 2 5 4 2 6 2 4 2 4 ...\n $ A2: int  4 4 4 4 3 6 5 3 5 4 ...\n $ A3: int  3 5 5 6 3 5 5 1 6 5 ...\n $ A4: int  4 2 4 5 4 6 3 5 6 6 ...\n $ A5: int  4 5 4 5 5 5 5 1 5 5 ...\n $ C1: int  2 5 4 4 4 6 5 3 6 4 ...\n $ C2: int  3 4 5 4 4 6 4 2 5 3 ...\n $ C3: int  3 4 4 3 5 6 4 4 6 5 ...\n $ C4: int  4 3 2 5 3 1 2 2 2 3 ...\n $ C5: int  4 4 5 5 2 3 3 4 1 2 ...\n $ E1: int  3 1 2 5 2 2 4 3 2 1 ...\n $ E2: int  3 1 4 3 2 1 3 6 2 3 ...\n $ E3: int  3 6 4 4 5 6 4 4 4 2 ...\n $ E4: int  4 4 4 4 4 5 5 2 5 5 ...\n $ E5: int  4 3 5 4 5 6 5 1 5 4 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:32] 9 63 66 72 90 107 112 130 133 168 ...\n  ..- attr(*, \"names\")= chr [1:32] \"61630\" \"61754\" \"61759\" \"61772\" ...\n\n\n为这份选用的内置数据集添加一个分组变量sex（模拟）：\n\n#设置随机数种子\nset.seed(123) \n\n#模拟抽样\nmd$sex = sample(c(1, 2), size = 468, replace = TRUE)\n\n根据sex对数据进行分组：\n\nmale_data= as.matrix(md %&gt;% filter(sex == 1))[,-16]\nfemale_data= as.matrix(md %&gt;% filter(sex== 2))[,-16]\n\n\n\n3 建模并计算可预测性\n\n3.1 “男性”网络\n\nmale_pre_mod = mgm(data = male_data,\n              type = rep('g',15),\n              level = rep(1,15),\n              lambdaSel = \"CV\",\n              ruleReg = \"AND\",\n              # pbar = TRUE, \n              overparameterize = FALSE, \n              signInfo = FALSE)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |-----                                                                 |   7%\n  |                                                                            \n  |---------                                                             |  13%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |-------------------                                                   |  27%\n  |                                                                            \n  |-----------------------                                               |  33%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |---------------------------------                                     |  47%\n  |                                                                            \n  |-------------------------------------                                 |  53%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |-----------------------------------------------                       |  67%\n  |                                                                            \n  |---------------------------------------------------                   |  73%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |-------------------------------------------------------------         |  87%\n  |                                                                            \n  |-----------------------------------------------------------------     |  93%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\n\n\n计算可预测性值：\n\nmale_pred_mgm = predict(object = male_pre_mod , \n                   data = male_data,\n                   errorCon = c(\"R2\"))\n\n排序看看效果：\n\nmale_pred_mgm$errors %&gt;% arrange(desc(R2))\n\n   Variable    R2\n1        A5 0.479\n2        A3 0.449\n3        A2 0.412\n4        E2 0.406\n5        C2 0.385\n6        E4 0.382\n7        E5 0.360\n8        C4 0.355\n9        E1 0.329\n10       E3 0.316\n11       C5 0.290\n12       A4 0.266\n13       C3 0.252\n14       C1 0.237\n15       A1 0.221\n\n\n接下来，用bootnet包绘制带有可预测性值的网络图，先估计网络：\n\nNetwork_male = estimateNetwork(male_data, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\n\n再绘图，把male_pred_mgm$errors塞进去：\n\nplot(Network_male,layout = \"spring\",\n     pie=male_pred_mgm$errors[,2]\n)\n\n\n\n\n\n\n3.2 “女性”网络\n同样的做法：\n\n# 计算女性网络\nfemale_pre_mod = mgm(data = female_data,\n                   type = rep('g',15),\n                   level = rep(1,15),\n                   lambdaSel = \"CV\",\n                   ruleReg = \"AND\",\n                   # pbar = TRUE, \n                   overparameterize = FALSE, \n                   signInfo = FALSE)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |-----                                                                 |   7%\n  |                                                                            \n  |---------                                                             |  13%\n  |                                                                            \n  |--------------                                                        |  20%\n  |                                                                            \n  |-------------------                                                   |  27%\n  |                                                                            \n  |-----------------------                                               |  33%\n  |                                                                            \n  |----------------------------                                          |  40%\n  |                                                                            \n  |---------------------------------                                     |  47%\n  |                                                                            \n  |-------------------------------------                                 |  53%\n  |                                                                            \n  |------------------------------------------                            |  60%\n  |                                                                            \n  |-----------------------------------------------                       |  67%\n  |                                                                            \n  |---------------------------------------------------                   |  73%\n  |                                                                            \n  |--------------------------------------------------------              |  80%\n  |                                                                            \n  |-------------------------------------------------------------         |  87%\n  |                                                                            \n  |-----------------------------------------------------------------     |  93%\n  |                                                                            \n  |----------------------------------------------------------------------| 100%\n\nfemale_pred_mgm = predict(object = female_pre_mod , \n                        data = female_data,\n                        errorCon = c(\"R2\"))\nfemale_pred_mgm$errors %&gt;% arrange(desc(R2))\n\n   Variable    R2\n1        E2 0.488\n2        A5 0.460\n3        E4 0.442\n4        A2 0.416\n5        E1 0.393\n6        E5 0.372\n7        C4 0.365\n8        C2 0.361\n9        A3 0.340\n10       C3 0.311\n11       C5 0.308\n12       E3 0.291\n13       C1 0.272\n14       A1 0.197\n15       A4 0.197\n\n# 可视化（带有可预测值的网络图）\nlibrary(bootnet)\nNetwork_female = estimateNetwork(female_data, default = \"EBICglasso\")\n\nEstimating Network. Using package::function:\n  - qgraph::EBICglasso for EBIC model selection\n    - using glasso::glasso\n\nplot(Network_female,layout = \"spring\",\n     pie=female_pred_mgm$errors[,2]\n)\n\n\n\n\n\n\n\n4 网络比较\n\nnct_res=NCT(Network_male, \n              Network_female, \n              gamma=0.5,\n              it = 100, \n              test.edges=T,\n              test.centrality =T,\n              centrality = c(\"strength\",\"expectedInfluence\"),\n              p.adjust.methods = 'BH' #Bonferroni-Holm校正\n              ) \n\nNote: Input is a bootnetResult object, argument 'gamma' is ignored.\n\n\nNote: estimateNetwork object used - estimation method has possibly not been validated.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n\n\nWarning in EBICglassoCore(S = S, n = n, gamma = gamma, penalize.diagonal =\npenalize.diagonal, : A dense regularized network was selected (lambda &lt; 0.1 *\nlambda.max). Recent work indicates a possible drop in specificity. Interpret\nthe presence of the smallest edges with care. Setting threshold = TRUE will\nenforce higher specificity, at the cost of sensitivity.\n\n\n\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n注意：为节省时间，本例调小了 iteration，实际研究可以设为1000次，\n\n查看比较结果：\n\nsummary(nct_res)\n\n INDEPENDENT GROUPS GAUSSIAN NETWORK COMPARISON TEST \n\n P-VALUE CORRECTION: BH \n\n NETWORK INVARIANCE TEST \n Test statistic M: 0.1676208 \n p-value 0.7425743 \n\n GLOBAL STRENGTH INVARIANCE TEST \n Global strength per group:  5.562555 5.089144 \n Test statistic S:  0.4734111 \n p-value 0.5742574\n\n EDGE INVARIANCE TEST \n    Var1 Var2  p-value Test statistic E\n16    A1   A2 1.000000       0.10615517\n31    A1   A3 1.000000       0.01237609\n32    A2   A3 1.000000       0.01127489\n46    A1   A4 1.000000       0.00000000\n47    A2   A4 1.000000       0.08596382\n48    A3   A4 0.984888       0.11086448\n61    A1   A5 1.000000       0.00000000\n62    A2   A5 1.000000       0.00499569\n63    A3   A5 0.984888       0.11312876\n64    A4   A5 1.000000       0.06577270\n76    A1   C1 1.000000       0.00000000\n77    A2   C1 1.000000       0.01488558\n78    A3   C1 1.000000       0.01412830\n79    A4   C1 1.000000       0.00000000\n80    A5   C1 1.000000       0.00000000\n91    A1   C2 1.000000       0.00000000\n92    A2   C2 1.000000       0.00000000\n93    A3   C2 1.000000       0.00000000\n94    A4   C2 1.000000       0.04108561\n95    A5   C2 1.000000       0.00000000\n96    C1   C2 1.000000       0.07496657\n106   A1   C3 1.000000       0.00000000\n107   A2   C3 1.000000       0.02744867\n108   A3   C3 0.984888       0.08828290\n109   A4   C3 0.984888       0.02020913\n110   A5   C3 1.000000       0.00000000\n111   C1   C3 1.000000       0.05339232\n112   C2   C3 1.000000       0.02400531\n121   A1   C4 0.984888       0.10427325\n122   A2   C4 0.984888       0.00835040\n123   A3   C4 1.000000       0.00000000\n124   A4   C4 1.000000       0.00000000\n125   A5   C4 1.000000       0.00000000\n126   C1   C4 1.000000       0.04099892\n127   C2   C4 1.000000       0.04963448\n128   C3   C4 1.000000       0.07389777\n136   A1   C5 0.984888       0.02146873\n137   A2   C5 1.000000       0.00000000\n138   A3   C5 1.000000       0.00146984\n139   A4   C5 0.984888       0.09117639\n140   A5   C5 1.000000       0.00627621\n141   C1   C5 1.000000       0.01867252\n142   C2   C5 1.000000       0.00074883\n143   C3   C5 1.000000       0.07700686\n144   C4   C5 1.000000       0.10472963\n151   A1   E1 1.000000       0.00000000\n152   A2   E1 1.000000       0.02608205\n153   A3   E1 1.000000       0.00000000\n154   A4   E1 1.000000       0.00000000\n155   A5   E1 0.984888       0.09226009\n156   C1   E1 0.984888       0.01426443\n157   C2   E1 1.000000       0.00000000\n158   C3   E1 1.000000       0.00000000\n159   C4   E1 0.984888       0.05423056\n160   C5   E1 1.000000       0.00000000\n166   A1   E2 1.000000       0.00000000\n167   A2   E2 1.000000       0.00000000\n168   A3   E2 0.984888       0.05956537\n169   A4   E2 1.000000       0.01340442\n170   A5   E2 1.000000       0.06475690\n171   C1   E2 1.000000       0.02032345\n172   C2   E2 1.000000       0.00000000\n173   C3   E2 1.000000       0.00000000\n174   C4   E2 0.984888       0.01661791\n175   C5   E2 1.000000       0.02469459\n176   E1   E2 0.984888       0.16762076\n181   A1   E3 1.000000       0.00000000\n182   A2   E3 1.000000       0.10080111\n183   A3   E3 1.000000       0.05829463\n184   A4   E3 1.000000       0.00343567\n185   A5   E3 0.984888       0.10894307\n186   C1   E3 1.000000       0.00000000\n187   C2   E3 1.000000       0.00000000\n188   C3   E3 1.000000       0.00000000\n189   C4   E3 1.000000       0.00000000\n190   C5   E3 1.000000       0.00000000\n191   E1   E3 1.000000       0.03019699\n192   E2   E3 1.000000       0.12410464\n196   A1   E4 1.000000       0.00000000\n197   A2   E4 1.000000       0.01339703\n198   A3   E4 0.984888       0.09636629\n199   A4   E4 1.000000       0.02392767\n200   A5   E4 0.984888       0.11141297\n201   C1   E4 1.000000       0.06128627\n202   C2   E4 1.000000       0.00000000\n203   C3   E4 1.000000       0.00000000\n204   C4   E4 1.000000       0.00000000\n205   C5   E4 0.984888       0.01782709\n206   E1   E4 1.000000       0.08184600\n207   E2   E4 1.000000       0.10924500\n208   E3   E4 1.000000       0.06110927\n211   A1   E5 1.000000       0.02892689\n212   A2   E5 0.984888       0.07951405\n213   A3   E5 1.000000       0.00000000\n214   A4   E5 1.000000       0.02207959\n215   A5   E5 1.000000       0.05169003\n216   C1   E5 1.000000       0.05735957\n217   C2   E5 1.000000       0.04823892\n218   C3   E5 1.000000       0.06983841\n219   C4   E5 1.000000       0.01234043\n220   C5   E5 1.000000       0.02373487\n221   E1   E5 1.000000       0.00436893\n222   E2   E5 1.000000       0.09707638\n223   E3   E5 1.000000       0.04389252\n224   E4   E5 1.000000       0.00461165\n\n\n CENTRALITY INVARIANCE TEST \n Nodes tested: A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 \n Centralities tested: strength expectedInfluence\n Test statistics C: \n       strength expectedInfluence\nA1  0.036137609       0.273200114\nA2  0.072080703       0.215526141\nA3  0.225294525       0.127976286\nA4  0.217718255       0.008556629\nA5  0.062591855      -0.238889701\nC1 -0.080319204      -0.055796218\nC2  0.142201888       0.041435265\nC3 -0.029364145      -0.331173409\nC4  0.113917146      -0.256526846\nC5  0.092794640      -0.209927273\nE1 -0.001361695      -0.442340943\nE2  0.069795182      -0.388883349\nE3  0.108517464      -0.200085787\nE4 -0.075592078       0.014860103\nE5 -0.007589970      -0.282631195\n\n p-values: \n    strength expectedInfluence\nA1 0.9900990         0.6930693\nA2 0.9900990         0.8415842\nA3 0.8415842         0.9900990\nA4 0.8415842         0.9900990\nA5 0.9900990         0.8415842\nC1 0.9900990         0.9900990\nC2 0.9900990         0.9900990\nC3 0.9900990         0.8415842\nC4 0.9900990         0.8415842\nC5 0.9900990         0.8415842\nE1 0.9900990         0.6930693\nE2 0.9900990         0.6930693\nE3 0.9900990         0.8415842\nE4 0.9900990         0.9900990\nE5 0.9900990         0.8415842\n\n\nNETWORK INVARIANCE TEST是网络不变性检验，GLOBAL STRENGTH INVARIANCE TEST是全局强度不变性检验，EDGE INVARIANCE TEST是边缘不变性检验，CENTRALITY INVARIANCE TEST是中心性不变性检验。\n运行环境：\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8 \n[2] LC_CTYPE=Chinese (Simplified)_China.utf8   \n[3] LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                               \n[5] LC_TIME=Chinese (Simplified)_China.utf8    \n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] psych_2.3.9                 dplyr_1.1.4                \n[3] mgm_1.2-14                  NetworkComparisonTest_2.2.2\n[5] bootnet_1.6                 ggplot2_3.5.0              \n\nloaded via a namespace (and not attached):\n  [1] mnormt_2.1.1         pbapply_1.7-2        polynom_1.4-1       \n  [4] gridExtra_2.3        fdrtool_1.2.17       rlang_1.1.3         \n  [7] magrittr_2.0.3       e1071_1.7-13         compiler_4.3.2      \n [10] gdata_3.0.0          IsingSampler_0.2.3   reshape2_1.4.4      \n [13] png_0.1-8            vctrs_0.6.4          quadprog_1.5-8      \n [16] stringr_1.5.1        pkgconfig_2.0.3      shape_1.4.6         \n [19] fastmap_1.1.1        backports_1.4.1      pbivnorm_0.6.0      \n [22] utf8_1.2.4           rmarkdown_2.25       NetworkToolbox_1.4.2\n [25] heplots_1.6.0        nloptr_2.0.3         purrr_1.0.2         \n [28] xfun_0.41            glmnet_4.1-8         jomo_2.7-6          \n [31] jsonlite_1.8.7       pan_1.9              jpeg_0.1-10         \n [34] lavaan_0.6-17        broom_1.0.5          parallel_4.3.2      \n [37] cluster_2.1.4        R6_2.5.1             stringi_1.8.1       \n [40] RColorBrewer_1.1-3   smacof_2.1-5         car_3.1-2           \n [43] boot_1.3-28.1        rpart_4.1.21         Rcpp_1.0.11         \n [46] iterators_1.0.14     knitr_1.45           snow_0.4-4          \n [49] base64enc_0.1-3      R.utils_2.12.3       weights_1.0.4       \n [52] Matrix_1.6-5         nnls_1.5             splines_4.3.2       \n [55] nnet_7.3-19          igraph_2.0.1.1       tidyselect_1.2.0    \n [58] rstudioapi_0.16.0    abind_1.4-5          yaml_2.3.7          \n [61] doParallel_1.0.17    codetools_0.2-19     qgraph_1.9.8        \n [64] plyr_1.8.9           lattice_0.21-9       tibble_3.2.1        \n [67] withr_2.5.2          evaluate_0.23        networktools_1.5.1  \n [70] foreign_0.8-85       survival_3.5-7       proxy_0.4-27        \n [73] pillar_1.9.0         carData_3.0-5        mice_3.16.0         \n [76] stats4_4.3.2         checkmate_2.3.0      foreach_1.5.2       \n [79] IsingFit_0.4         ellipse_0.5.0        generics_0.1.3      \n [82] munsell_0.5.0        candisc_0.8-6        scales_1.3.0        \n [85] minqa_1.2.6          gtools_3.9.5         class_7.3-22        \n [88] glue_1.6.2           Hmisc_5.1-1          tools_4.3.2         \n [91] data.table_1.15.4    lme4_1.1-35.1        mvtnorm_1.2-3       \n [94] rgl_1.2.1            grid_4.3.2           plotrix_3.8-4       \n [97] tidyr_1.3.1          colorspace_2.1-0     nlme_3.1-163        \n[100] htmlTable_2.4.2      eigenmodel_1.11      Formula_1.2-5       \n[103] cli_3.6.2            fansi_1.0.5          glasso_1.11         \n[106] corpcor_1.6.10       gtable_0.3.4         R.methodsS3_1.8.2   \n[109] digest_0.6.33        wordcloud_2.6        htmlwidgets_1.6.2   \n[112] htmltools_0.5.7      R.oo_1.25.0          lifecycle_1.0.4     \n[115] mitml_0.4-5          MASS_7.3-60"
  },
  {
    "objectID": "参考文献.html",
    "href": "参考文献.html",
    "title": "参考文献",
    "section": "",
    "text": "参考文献（不分先后）：\nEpskamp S, Borsboom D, Fried EI. Estimating psychological networks and their accuracy: A tutorial paper. Behav Res Methods. 2018 Feb;50(1):195-212. doi: 10.3758/s13428-017-0862-1. \nNETWORK PSYCHOMETRICSWITH R A Guide for Behavioral and Social Scientists\nZhu Z, Sun Y, Kuang Y, Yuan X, Gu H, Zhu J, Xing W. Contemporaneous symptom networks of multidimensional symptom experiences in cancer survivors: A network analysis. Cancer Med. 2023 Jan;12(1):663-673. doi: 10.1002/cam4.4904\nBellaert N, Morreale K, Tseng WL. Peer functioning difficulties may exacerbate symptoms of attention-deficit/hyperactivity disorder and irritability over time: a temporal network analysis. J Child Psychol Psychiatry. 2024 Jun;65(6):809-821. doi: 10.1111/jcpp.13911\nContreras A, Valiente C, Heeren A, Bentall R. A Temporal Network Approach to Paranoia: A Pilot Study. Front Psychol. 2020 Sep 18;11:544565. doi: 10.3389/fpsyg.2020.544565\nTao Y, Tang Q, Wang S, Zou X, Ma Z, Zhang L, Liu G, Liu X. The impact of long-term online learning on social anxiety and problematic smartphone use symptoms among secondary school students with different levels of fear of missing out: Evidence from a symptom network and longitudinal panel network analysis. J Behav Addict. 2024 Jan 9;13(1):102-119.\nHaslbeck JMB, Borsboom D, Waldorp LJ. Moderated Network Models. Multivariate Behav Res. 2021 Mar-Apr;56(2):256-287. doi: 10.1080/00273171.2019.1677207\nHaslbeck JMB, Bringmann LF, Waldorp LJ. A Tutorial on Estimating Time-Varying Vector Autoregressive Models. Multivariate Behav Res. 2021 Jan-Feb;56(1):120-149. doi: 10.1080/00273171.2020.1743630\nBorsboom D, Cramer AO. Network analysis: an integrative approach to the structure of psychopathology. Annu Rev Clin Psychol. 2013;9:91-121. doi: 10.1146/annurev-clinpsy-050212-185608\nEpskamp S, Waldorp LJ, Mõttus R, Borsboom D. The Gaussian Graphical Model in Cross-Sectional and Time-Series Data. Multivariate Behav Res. 2018 Jul-Aug;53(4):453-480. doi: 10.1080/00273171.2018.1454823\n胡雁. 症状科学的发展及研究趋势[J]. 护士进修杂志,2023,38(24):2209-2213. DOI:10.16821/j.cnki.hsjx.2023.24.001.\n朱政,胡天天,金依霖,等. 症状网络的基本概念及其在症状管理中的应用[J]. 护士进修杂志,2023,38(24):2214-2218,2224. DOI:10.16821/j.cnki.hsjx.2023.24.002.\n杨中方,金依霖,何加敏,等. 基于数据类型的症状网络分类:同期网络动态网络和个体化网络[J]. 护士进修杂志,2023,38(24):2219-2224. DOI:10.16821/j.cnki.hsjx.2023.24.003.\n朱政,胡天天,金依霖,等. 症状多层网络的类型和应用[J]. 护士进修杂志,2023,38(24):2225-2228. DOI:10.16821/j.cnki.hsjx.2023.24.004.\n余骏雯,朱政,胡天天,等. 症状网络的特异性指标[J]. 护士进修杂志,2023,38(24):2229-2234,2245. DOI:10.16821/j.cnki.hsjx.2023.24.005.\n朱政,余骏雯,杨中方,等. 症状同期网络的分析方法介绍及R软件实现[J]. 护士进修杂志,2023,38(24):2235-2239. DOI:10.16821/j.cnki.hsjx.2023.24.006.\n余骏雯,胡天天,杨中方,等. 症状动态网络的分析方法介绍及R软件实现[J]. 护士进修杂志,2023,38(24):2240-2245. DOI:10.16821/j.cnki.hsjx.2023.24.007.\n胡天天,余骏雯,何加敏,等. 个体化症状网络的应用方法及实现[J]. 护士进修杂志,2023,38(24):2246-2249. DOI:10.16821/j.cnki.hsjx.2023.24.008.\n余骏雯,杨中方,何加敏,等. 症状网络研究的报告规范[J]. 护士进修杂志,2023,38(24):2250-2254,2261. DOI:10.16821/j.cnki.hsjx.2023.24.009.\n蔡玉清,董书阳,袁帅,等. 变量间的网络分析模型及其应用[J]. 心理科学进展,2020,28(1):178-190. DOI:10.3724/SP.J.1042.2020.00178.\nRobinaugh DJ, Hoekstra RHA, Toner ER, Borsboom D. The network approach to psychopathology: a review of the literature 2008-2018 and an agenda for future research. Psychol Med. 2020 Feb;50(3):353-366. doi: 10.1017/S0033291719003404\nHevey D. Network analysis: a brief overview and tutorial. Health Psychol Behav Med. 2018 Sep 25;6(1):301-328. doi: 10.1080/21642850.2018.1521283\nFreichel R. Symptom Network Analysis Tools for Applied Researchers With Cross-Sectional and Panel Data - A Brief Overview and Multiverse Analysis. Psychol Rep. 2023 Nov 9:332941231213649. doi: 10.1177/00332941231213649."
  }
]